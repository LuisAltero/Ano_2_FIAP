{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[DL] Redes_Neurais_parte_2.ipynb","provenance":[],"authorship_tag":"ABX9TyPrpvEDc3UyCPKXT8xs/A6S"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Utilizando Pybrain"],"metadata":{"id":"aSZz1FLj9mRw"}},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZhQpvW62dJpr","executionInfo":{"status":"ok","timestamp":1651531162516,"user_tz":180,"elapsed":6048,"user":{"displayName":"luis henrique caldas altero","userId":"05313197258994103975"}},"outputId":"9c9944f6-2c4a-4482-fe4e-8c9b5ec90865"},"outputs":[{"output_type":"stream","name":"stdout","text":["Processing /home/pybrain-0.3.3.zip\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from PyBrain==0.3.1) (1.4.1)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->PyBrain==0.3.1) (1.21.6)\n","Building wheels for collected packages: PyBrain\n","  Building wheel for PyBrain (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for PyBrain: filename=PyBrain-0.3.1-py3-none-any.whl size=468244 sha256=a425a5a6637bcb9b6031c5c270f156bf4370997401ca766577b279ec9d15a350\n","  Stored in directory: /root/.cache/pip/wheels/1d/40/c0/ff3ed1ed26aea410adf50c2b539620dc66c905a35876acaea1\n","Successfully built PyBrain\n","Installing collected packages: PyBrain\n","  Attempting uninstall: PyBrain\n","    Found existing installation: PyBrain 0.3\n","    Uninstalling PyBrain-0.3:\n","      Successfully uninstalled PyBrain-0.3\n","Successfully installed PyBrain-0.3.1\n"]}],"source":["!pip install \"/home/pybrain-0.3.3.zip\""]},{"cell_type":"code","source":["from pybrain.tools.shortcuts import buildNetwork\n","from pybrain.datasets import SupervisedDataSet\n","from pybrain.supervised.trainers import BackpropTrainer\n","from pybrain.structure.modules import SoftmaxLayer\n","from pybrain.structure.modules import SigmoidLayer"],"metadata":{"id":"PoJ_CUYkdMwk","executionInfo":{"status":"ok","timestamp":1651531177426,"user_tz":180,"elapsed":680,"user":{"displayName":"luis henrique caldas altero","userId":"05313197258994103975"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["rede = buildNetwork(2,3,1, hiddenclass=SigmoidLayer, bias=False)#outclass=Softmaxlayer"],"metadata":{"id":"4xSDBGnBdM07","executionInfo":{"status":"ok","timestamp":1651531177807,"user_tz":180,"elapsed":2,"user":{"displayName":"luis henrique caldas altero","userId":"05313197258994103975"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["print(rede['in'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7RTy0y_6dM47","executionInfo":{"status":"ok","timestamp":1651531178191,"user_tz":180,"elapsed":15,"user":{"displayName":"luis henrique caldas altero","userId":"05313197258994103975"}},"outputId":"d1b15c1f-c468-4e6a-acae-577a9b6e04c1"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["<LinearLayer 'in'>\n"]}]},{"cell_type":"code","source":["print(rede['hidden0'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LMBAtgxjdM9D","executionInfo":{"status":"ok","timestamp":1651531178191,"user_tz":180,"elapsed":13,"user":{"displayName":"luis henrique caldas altero","userId":"05313197258994103975"}},"outputId":"a5dea34e-ac17-4a23-afb6-c62dc09134f6"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["<SigmoidLayer 'hidden0'>\n"]}]},{"cell_type":"code","source":["print(rede['out'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xTczLtlDnnce","executionInfo":{"status":"ok","timestamp":1651531178191,"user_tz":180,"elapsed":12,"user":{"displayName":"luis henrique caldas altero","userId":"05313197258994103975"}},"outputId":"d11da07d-7df6-480e-b168-caa1df9e42f1"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["<LinearLayer 'out'>\n"]}]},{"cell_type":"code","source":["print(rede['bias'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UcMaaIDMnnhk","executionInfo":{"status":"ok","timestamp":1651531178192,"user_tz":180,"elapsed":11,"user":{"displayName":"luis henrique caldas altero","userId":"05313197258994103975"}},"outputId":"d36e41be-a163-4447-f7fc-598723173594"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["None\n"]}]},{"cell_type":"code","source":["dados = SupervisedDataSet(2,1)\n","dados.addSample((0,0), (0))\n","dados.addSample((0,1), (1))\n","dados.addSample((1,0), (1))\n","dados.addSample((1,1), (0))"],"metadata":{"id":"srroybhspOfU","executionInfo":{"status":"ok","timestamp":1651531178192,"user_tz":180,"elapsed":10,"user":{"displayName":"luis henrique caldas altero","userId":"05313197258994103975"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["print(dados['input'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7EyanYLidNBL","executionInfo":{"status":"ok","timestamp":1651531178192,"user_tz":180,"elapsed":9,"user":{"displayName":"luis henrique caldas altero","userId":"05313197258994103975"}},"outputId":"4065dc00-be2f-4671-b35f-74045d959a5d"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0. 0.]\n"," [0. 1.]\n"," [1. 0.]\n"," [1. 1.]]\n"]}]},{"cell_type":"code","source":["dados['target']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K-aPW17znvex","executionInfo":{"status":"ok","timestamp":1651531178193,"user_tz":180,"elapsed":9,"user":{"displayName":"luis henrique caldas altero","userId":"05313197258994103975"}},"outputId":"ad363d60-650c-4ee3-8040-8888c0e1a91a"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.],\n","       [1.],\n","       [1.],\n","       [0.]])"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["treinamento = BackpropTrainer(rede, dataset=dados, learningrate=0.01, momentum=0.06)"],"metadata":{"id":"R4oS77L9nvj5","executionInfo":{"status":"ok","timestamp":1651531178193,"user_tz":180,"elapsed":7,"user":{"displayName":"luis henrique caldas altero","userId":"05313197258994103975"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["erro=0\n","for i in range(50000):\n","  erro = treinamento.train()\n","  #if i % 1000 == 0:\n","    #print(\"Erro:\", erro)\n","print(\"Erro:\", erro)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C3EyJQ8dpoT-","executionInfo":{"status":"ok","timestamp":1651531279894,"user_tz":180,"elapsed":101707,"user":{"displayName":"luis henrique caldas altero","userId":"05313197258994103975"}},"outputId":"e2fb3b18-ab75-4f51-c924-bb0fde7685af"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Erro: 0.00018553106167173346\n"]}]},{"cell_type":"code","source":["val1 = rede.activate([0,0])\n","val1 = round(val1[0])\n","print(val1)\n","\n","val2 = rede.activate([0,1])\n","val2 = round(val2[0])\n","print(val2)\n","\n","val3 = rede.activate([1,0])\n","val3 = round(val3[0])\n","print(val3)\n","\n","val4 = rede.activate([1,1])\n","val4 = round(val4[0])\n","print(val4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EbMvFJeapoX3","executionInfo":{"status":"ok","timestamp":1651531279895,"user_tz":180,"elapsed":10,"user":{"displayName":"luis henrique caldas altero","userId":"05313197258994103975"}},"outputId":"66757836-17bd-4026-9f0c-132acafbdf9e"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","1\n","1\n","0\n"]}]},{"cell_type":"markdown","source":["# Utilizando Sklearn"],"metadata":{"id":"iGO5t5OZpobm"}},{"cell_type":"code","source":["from sklearn.neural_network import MLPClassifier\n","from sklearn import datasets\n","\n","iris = datasets.load_iris()"],"metadata":{"id":"RQFCbAxHtfLu","executionInfo":{"status":"ok","timestamp":1651531642987,"user_tz":180,"elapsed":246,"user":{"displayName":"luis henrique caldas altero","userId":"05313197258994103975"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["entradas = iris.data\n","saidas = iris.target"],"metadata":{"id":"tszSG-qqtfQc","executionInfo":{"status":"ok","timestamp":1651531678450,"user_tz":180,"elapsed":245,"user":{"displayName":"luis henrique caldas altero","userId":"05313197258994103975"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["redeneural = MLPClassifier(verbose=True,\n","                           max_iter=10000,\n","                           tol=0.000001,\n","                           activation='relu',\n","                           #hidden_layer_sizes=(30,30,30),\n","                           learning_rate_init=0.0001)"],"metadata":{"id":"UdXEwzE-9P35","executionInfo":{"status":"ok","timestamp":1651532195971,"user_tz":180,"elapsed":238,"user":{"displayName":"luis henrique caldas altero","userId":"05313197258994103975"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["redeneural.fit(entradas, saidas)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_0xBZey49P8I","executionInfo":{"status":"ok","timestamp":1651532233111,"user_tz":180,"elapsed":19818,"user":{"displayName":"luis henrique caldas altero","userId":"05313197258994103975"}},"outputId":"c9d2cd54-5b9a-4f10-9f22-ddd08dfb605e"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mA saída de streaming foi truncada nas últimas 5000 linhas.\u001b[0m\n","Iteration 5001, loss = 0.05796155\n","Iteration 5002, loss = 0.05795151\n","Iteration 5003, loss = 0.05794148\n","Iteration 5004, loss = 0.05793145\n","Iteration 5005, loss = 0.05792142\n","Iteration 5006, loss = 0.05791140\n","Iteration 5007, loss = 0.05790139\n","Iteration 5008, loss = 0.05789138\n","Iteration 5009, loss = 0.05788138\n","Iteration 5010, loss = 0.05787140\n","Iteration 5011, loss = 0.05786141\n","Iteration 5012, loss = 0.05785157\n","Iteration 5013, loss = 0.05784151\n","Iteration 5014, loss = 0.05783158\n","Iteration 5015, loss = 0.05782166\n","Iteration 5016, loss = 0.05781173\n","Iteration 5017, loss = 0.05780182\n","Iteration 5018, loss = 0.05779191\n","Iteration 5019, loss = 0.05778201\n","Iteration 5020, loss = 0.05777211\n","Iteration 5021, loss = 0.05776230\n","Iteration 5022, loss = 0.05775237\n","Iteration 5023, loss = 0.05774253\n","Iteration 5024, loss = 0.05773269\n","Iteration 5025, loss = 0.05772286\n","Iteration 5026, loss = 0.05771303\n","Iteration 5027, loss = 0.05770320\n","Iteration 5028, loss = 0.05769338\n","Iteration 5029, loss = 0.05768356\n","Iteration 5030, loss = 0.05767378\n","Iteration 5031, loss = 0.05766399\n","Iteration 5032, loss = 0.05765423\n","Iteration 5033, loss = 0.05764447\n","Iteration 5034, loss = 0.05763472\n","Iteration 5035, loss = 0.05762496\n","Iteration 5036, loss = 0.05761521\n","Iteration 5037, loss = 0.05760547\n","Iteration 5038, loss = 0.05759576\n","Iteration 5039, loss = 0.05758603\n","Iteration 5040, loss = 0.05757635\n","Iteration 5041, loss = 0.05756666\n","Iteration 5042, loss = 0.05755698\n","Iteration 5043, loss = 0.05754729\n","Iteration 5044, loss = 0.05753761\n","Iteration 5045, loss = 0.05752793\n","Iteration 5046, loss = 0.05751840\n","Iteration 5047, loss = 0.05750864\n","Iteration 5048, loss = 0.05749902\n","Iteration 5049, loss = 0.05748940\n","Iteration 5050, loss = 0.05747978\n","Iteration 5051, loss = 0.05747017\n","Iteration 5052, loss = 0.05746063\n","Iteration 5053, loss = 0.05745099\n","Iteration 5054, loss = 0.05744144\n","Iteration 5055, loss = 0.05743188\n","Iteration 5056, loss = 0.05742232\n","Iteration 5057, loss = 0.05741275\n","Iteration 5058, loss = 0.05740319\n","Iteration 5059, loss = 0.05739364\n","Iteration 5060, loss = 0.05738413\n","Iteration 5061, loss = 0.05737463\n","Iteration 5062, loss = 0.05736512\n","Iteration 5063, loss = 0.05735562\n","Iteration 5064, loss = 0.05734611\n","Iteration 5065, loss = 0.05733660\n","Iteration 5066, loss = 0.05732729\n","Iteration 5067, loss = 0.05731770\n","Iteration 5068, loss = 0.05730827\n","Iteration 5069, loss = 0.05729888\n","Iteration 5070, loss = 0.05728948\n","Iteration 5071, loss = 0.05728007\n","Iteration 5072, loss = 0.05727066\n","Iteration 5073, loss = 0.05726125\n","Iteration 5074, loss = 0.05725183\n","Iteration 5075, loss = 0.05724241\n","Iteration 5076, loss = 0.05723299\n","Iteration 5077, loss = 0.05722357\n","Iteration 5078, loss = 0.05721414\n","Iteration 5079, loss = 0.05720478\n","Iteration 5080, loss = 0.05719541\n","Iteration 5081, loss = 0.05718608\n","Iteration 5082, loss = 0.05717679\n","Iteration 5083, loss = 0.05716748\n","Iteration 5084, loss = 0.05715817\n","Iteration 5085, loss = 0.05714885\n","Iteration 5086, loss = 0.05713953\n","Iteration 5087, loss = 0.05713020\n","Iteration 5088, loss = 0.05712087\n","Iteration 5089, loss = 0.05711163\n","Iteration 5090, loss = 0.05710230\n","Iteration 5091, loss = 0.05709309\n","Iteration 5092, loss = 0.05708388\n","Iteration 5093, loss = 0.05707467\n","Iteration 5094, loss = 0.05706544\n","Iteration 5095, loss = 0.05705621\n","Iteration 5096, loss = 0.05704696\n","Iteration 5097, loss = 0.05703772\n","Iteration 5098, loss = 0.05702847\n","Iteration 5099, loss = 0.05701921\n","Iteration 5100, loss = 0.05701028\n","Iteration 5101, loss = 0.05700110\n","Iteration 5102, loss = 0.05699169\n","Iteration 5103, loss = 0.05698262\n","Iteration 5104, loss = 0.05697355\n","Iteration 5105, loss = 0.05696447\n","Iteration 5106, loss = 0.05695538\n","Iteration 5107, loss = 0.05694627\n","Iteration 5108, loss = 0.05693714\n","Iteration 5109, loss = 0.05692801\n","Iteration 5110, loss = 0.05691887\n","Iteration 5111, loss = 0.05690973\n","Iteration 5112, loss = 0.05690057\n","Iteration 5113, loss = 0.05689142\n","Iteration 5114, loss = 0.05688226\n","Iteration 5115, loss = 0.05687345\n","Iteration 5116, loss = 0.05686447\n","Iteration 5117, loss = 0.05685527\n","Iteration 5118, loss = 0.05684607\n","Iteration 5119, loss = 0.05683711\n","Iteration 5120, loss = 0.05682813\n","Iteration 5121, loss = 0.05681914\n","Iteration 5122, loss = 0.05681013\n","Iteration 5123, loss = 0.05680111\n","Iteration 5124, loss = 0.05679208\n","Iteration 5125, loss = 0.05678304\n","Iteration 5126, loss = 0.05677399\n","Iteration 5127, loss = 0.05676520\n","Iteration 5128, loss = 0.05675627\n","Iteration 5129, loss = 0.05674713\n","Iteration 5130, loss = 0.05673824\n","Iteration 5131, loss = 0.05672938\n","Iteration 5132, loss = 0.05672051\n","Iteration 5133, loss = 0.05671161\n","Iteration 5134, loss = 0.05670270\n","Iteration 5135, loss = 0.05669378\n","Iteration 5136, loss = 0.05668484\n","Iteration 5137, loss = 0.05667589\n","Iteration 5138, loss = 0.05666693\n","Iteration 5139, loss = 0.05665798\n","Iteration 5140, loss = 0.05664916\n","Iteration 5141, loss = 0.05664027\n","Iteration 5142, loss = 0.05663144\n","Iteration 5143, loss = 0.05662259\n","Iteration 5144, loss = 0.05661373\n","Iteration 5145, loss = 0.05660491\n","Iteration 5146, loss = 0.05659606\n","Iteration 5147, loss = 0.05658725\n","Iteration 5148, loss = 0.05657846\n","Iteration 5149, loss = 0.05656966\n","Iteration 5150, loss = 0.05656089\n","Iteration 5151, loss = 0.05655210\n","Iteration 5152, loss = 0.05654328\n","Iteration 5153, loss = 0.05653465\n","Iteration 5154, loss = 0.05652584\n","Iteration 5155, loss = 0.05651705\n","Iteration 5156, loss = 0.05650835\n","Iteration 5157, loss = 0.05649964\n","Iteration 5158, loss = 0.05649090\n","Iteration 5159, loss = 0.05648214\n","Iteration 5160, loss = 0.05647336\n","Iteration 5161, loss = 0.05646479\n","Iteration 5162, loss = 0.05645609\n","Iteration 5163, loss = 0.05644725\n","Iteration 5164, loss = 0.05643860\n","Iteration 5165, loss = 0.05642992\n","Iteration 5166, loss = 0.05642123\n","Iteration 5167, loss = 0.05641264\n","Iteration 5168, loss = 0.05640392\n","Iteration 5169, loss = 0.05639533\n","Iteration 5170, loss = 0.05638674\n","Iteration 5171, loss = 0.05637813\n","Iteration 5172, loss = 0.05636949\n","Iteration 5173, loss = 0.05636084\n","Iteration 5174, loss = 0.05635216\n","Iteration 5175, loss = 0.05634364\n","Iteration 5176, loss = 0.05633507\n","Iteration 5177, loss = 0.05632633\n","Iteration 5178, loss = 0.05631778\n","Iteration 5179, loss = 0.05630920\n","Iteration 5180, loss = 0.05630065\n","Iteration 5181, loss = 0.05629207\n","Iteration 5182, loss = 0.05628352\n","Iteration 5183, loss = 0.05627497\n","Iteration 5184, loss = 0.05626646\n","Iteration 5185, loss = 0.05625794\n","Iteration 5186, loss = 0.05624940\n","Iteration 5187, loss = 0.05624092\n","Iteration 5188, loss = 0.05623236\n","Iteration 5189, loss = 0.05622394\n","Iteration 5190, loss = 0.05621550\n","Iteration 5191, loss = 0.05620702\n","Iteration 5192, loss = 0.05619852\n","Iteration 5193, loss = 0.05619000\n","Iteration 5194, loss = 0.05618146\n","Iteration 5195, loss = 0.05617301\n","Iteration 5196, loss = 0.05616462\n","Iteration 5197, loss = 0.05615621\n","Iteration 5198, loss = 0.05614776\n","Iteration 5199, loss = 0.05613929\n","Iteration 5200, loss = 0.05613088\n","Iteration 5201, loss = 0.05612245\n","Iteration 5202, loss = 0.05611407\n","Iteration 5203, loss = 0.05610570\n","Iteration 5204, loss = 0.05609731\n","Iteration 5205, loss = 0.05608888\n","Iteration 5206, loss = 0.05608049\n","Iteration 5207, loss = 0.05607210\n","Iteration 5208, loss = 0.05606379\n","Iteration 5209, loss = 0.05605547\n","Iteration 5210, loss = 0.05604712\n","Iteration 5211, loss = 0.05603873\n","Iteration 5212, loss = 0.05603036\n","Iteration 5213, loss = 0.05602202\n","Iteration 5214, loss = 0.05601375\n","Iteration 5215, loss = 0.05600547\n","Iteration 5216, loss = 0.05599716\n","Iteration 5217, loss = 0.05598881\n","Iteration 5218, loss = 0.05598053\n","Iteration 5219, loss = 0.05597224\n","Iteration 5220, loss = 0.05596394\n","Iteration 5221, loss = 0.05595570\n","Iteration 5222, loss = 0.05594742\n","Iteration 5223, loss = 0.05593911\n","Iteration 5224, loss = 0.05593102\n","Iteration 5225, loss = 0.05592278\n","Iteration 5226, loss = 0.05591441\n","Iteration 5227, loss = 0.05590625\n","Iteration 5228, loss = 0.05589811\n","Iteration 5229, loss = 0.05588993\n","Iteration 5230, loss = 0.05588171\n","Iteration 5231, loss = 0.05587345\n","Iteration 5232, loss = 0.05586516\n","Iteration 5233, loss = 0.05585699\n","Iteration 5234, loss = 0.05584887\n","Iteration 5235, loss = 0.05584062\n","Iteration 5236, loss = 0.05583244\n","Iteration 5237, loss = 0.05582434\n","Iteration 5238, loss = 0.05581619\n","Iteration 5239, loss = 0.05580801\n","Iteration 5240, loss = 0.05579978\n","Iteration 5241, loss = 0.05579179\n","Iteration 5242, loss = 0.05578371\n","Iteration 5243, loss = 0.05577550\n","Iteration 5244, loss = 0.05576733\n","Iteration 5245, loss = 0.05575929\n","Iteration 5246, loss = 0.05575120\n","Iteration 5247, loss = 0.05574307\n","Iteration 5248, loss = 0.05573490\n","Iteration 5249, loss = 0.05572697\n","Iteration 5250, loss = 0.05571895\n","Iteration 5251, loss = 0.05571080\n","Iteration 5252, loss = 0.05570265\n","Iteration 5253, loss = 0.05569467\n","Iteration 5254, loss = 0.05568663\n","Iteration 5255, loss = 0.05567854\n","Iteration 5256, loss = 0.05567046\n","Iteration 5257, loss = 0.05566243\n","Iteration 5258, loss = 0.05565446\n","Iteration 5259, loss = 0.05564646\n","Iteration 5260, loss = 0.05563843\n","Iteration 5261, loss = 0.05563041\n","Iteration 5262, loss = 0.05562241\n","Iteration 5263, loss = 0.05561446\n","Iteration 5264, loss = 0.05560650\n","Iteration 5265, loss = 0.05559850\n","Iteration 5266, loss = 0.05559051\n","Iteration 5267, loss = 0.05558254\n","Iteration 5268, loss = 0.05557463\n","Iteration 5269, loss = 0.05556671\n","Iteration 5270, loss = 0.05555874\n","Iteration 5271, loss = 0.05555077\n","Iteration 5272, loss = 0.05554283\n","Iteration 5273, loss = 0.05553496\n","Iteration 5274, loss = 0.05552707\n","Iteration 5275, loss = 0.05551913\n","Iteration 5276, loss = 0.05551121\n","Iteration 5277, loss = 0.05550331\n","Iteration 5278, loss = 0.05549544\n","Iteration 5279, loss = 0.05548757\n","Iteration 5280, loss = 0.05547966\n","Iteration 5281, loss = 0.05547185\n","Iteration 5282, loss = 0.05546399\n","Iteration 5283, loss = 0.05545605\n","Iteration 5284, loss = 0.05544821\n","Iteration 5285, loss = 0.05544039\n","Iteration 5286, loss = 0.05543252\n","Iteration 5287, loss = 0.05542470\n","Iteration 5288, loss = 0.05541690\n","Iteration 5289, loss = 0.05540907\n","Iteration 5290, loss = 0.05540127\n","Iteration 5291, loss = 0.05539343\n","Iteration 5292, loss = 0.05538571\n","Iteration 5293, loss = 0.05537795\n","Iteration 5294, loss = 0.05537013\n","Iteration 5295, loss = 0.05536227\n","Iteration 5296, loss = 0.05535449\n","Iteration 5297, loss = 0.05534680\n","Iteration 5298, loss = 0.05533905\n","Iteration 5299, loss = 0.05533124\n","Iteration 5300, loss = 0.05532356\n","Iteration 5301, loss = 0.05531584\n","Iteration 5302, loss = 0.05530802\n","Iteration 5303, loss = 0.05530037\n","Iteration 5304, loss = 0.05529270\n","Iteration 5305, loss = 0.05528498\n","Iteration 5306, loss = 0.05527720\n","Iteration 5307, loss = 0.05526944\n","Iteration 5308, loss = 0.05526179\n","Iteration 5309, loss = 0.05525403\n","Iteration 5310, loss = 0.05524644\n","Iteration 5311, loss = 0.05523881\n","Iteration 5312, loss = 0.05523111\n","Iteration 5313, loss = 0.05522336\n","Iteration 5314, loss = 0.05521576\n","Iteration 5315, loss = 0.05520816\n","Iteration 5316, loss = 0.05520046\n","Iteration 5317, loss = 0.05519271\n","Iteration 5318, loss = 0.05518511\n","Iteration 5319, loss = 0.05517745\n","Iteration 5320, loss = 0.05516990\n","Iteration 5321, loss = 0.05516229\n","Iteration 5322, loss = 0.05515459\n","Iteration 5323, loss = 0.05514710\n","Iteration 5324, loss = 0.05513956\n","Iteration 5325, loss = 0.05513195\n","Iteration 5326, loss = 0.05512429\n","Iteration 5327, loss = 0.05511665\n","Iteration 5328, loss = 0.05510913\n","Iteration 5329, loss = 0.05510151\n","Iteration 5330, loss = 0.05509396\n","Iteration 5331, loss = 0.05508644\n","Iteration 5332, loss = 0.05507885\n","Iteration 5333, loss = 0.05507129\n","Iteration 5334, loss = 0.05506377\n","Iteration 5335, loss = 0.05505617\n","Iteration 5336, loss = 0.05504865\n","Iteration 5337, loss = 0.05504117\n","Iteration 5338, loss = 0.05503365\n","Iteration 5339, loss = 0.05502613\n","Iteration 5340, loss = 0.05501861\n","Iteration 5341, loss = 0.05501115\n","Iteration 5342, loss = 0.05500366\n","Iteration 5343, loss = 0.05499611\n","Iteration 5344, loss = 0.05498864\n","Iteration 5345, loss = 0.05498120\n","Iteration 5346, loss = 0.05497371\n","Iteration 5347, loss = 0.05496630\n","Iteration 5348, loss = 0.05495887\n","Iteration 5349, loss = 0.05495136\n","Iteration 5350, loss = 0.05494396\n","Iteration 5351, loss = 0.05493655\n","Iteration 5352, loss = 0.05492907\n","Iteration 5353, loss = 0.05492162\n","Iteration 5354, loss = 0.05491423\n","Iteration 5355, loss = 0.05490677\n","Iteration 5356, loss = 0.05489940\n","Iteration 5357, loss = 0.05489203\n","Iteration 5358, loss = 0.05488457\n","Iteration 5359, loss = 0.05487721\n","Iteration 5360, loss = 0.05486986\n","Iteration 5361, loss = 0.05486243\n","Iteration 5362, loss = 0.05485503\n","Iteration 5363, loss = 0.05484769\n","Iteration 5364, loss = 0.05484027\n","Iteration 5365, loss = 0.05483301\n","Iteration 5366, loss = 0.05482569\n","Iteration 5367, loss = 0.05481830\n","Iteration 5368, loss = 0.05481089\n","Iteration 5369, loss = 0.05480358\n","Iteration 5370, loss = 0.05479620\n","Iteration 5371, loss = 0.05478899\n","Iteration 5372, loss = 0.05478170\n","Iteration 5373, loss = 0.05477434\n","Iteration 5374, loss = 0.05476697\n","Iteration 5375, loss = 0.05475971\n","Iteration 5376, loss = 0.05475238\n","Iteration 5377, loss = 0.05474513\n","Iteration 5378, loss = 0.05473787\n","Iteration 5379, loss = 0.05473053\n","Iteration 5380, loss = 0.05472331\n","Iteration 5381, loss = 0.05471609\n","Iteration 5382, loss = 0.05470880\n","Iteration 5383, loss = 0.05470143\n","Iteration 5384, loss = 0.05469436\n","Iteration 5385, loss = 0.05468719\n","Iteration 5386, loss = 0.05467994\n","Iteration 5387, loss = 0.05467260\n","Iteration 5388, loss = 0.05466528\n","Iteration 5389, loss = 0.05465813\n","Iteration 5390, loss = 0.05465091\n","Iteration 5391, loss = 0.05464363\n","Iteration 5392, loss = 0.05463650\n","Iteration 5393, loss = 0.05462935\n","Iteration 5394, loss = 0.05462211\n","Iteration 5395, loss = 0.05461481\n","Iteration 5396, loss = 0.05460766\n","Iteration 5397, loss = 0.05460044\n","Iteration 5398, loss = 0.05459339\n","Iteration 5399, loss = 0.05458624\n","Iteration 5400, loss = 0.05457900\n","Iteration 5401, loss = 0.05457187\n","Iteration 5402, loss = 0.05456478\n","Iteration 5403, loss = 0.05455761\n","Iteration 5404, loss = 0.05455039\n","Iteration 5405, loss = 0.05454334\n","Iteration 5406, loss = 0.05453627\n","Iteration 5407, loss = 0.05452911\n","Iteration 5408, loss = 0.05452186\n","Iteration 5409, loss = 0.05451491\n","Iteration 5410, loss = 0.05450790\n","Iteration 5411, loss = 0.05450081\n","Iteration 5412, loss = 0.05449367\n","Iteration 5413, loss = 0.05448647\n","Iteration 5414, loss = 0.05447930\n","Iteration 5415, loss = 0.05447231\n","Iteration 5416, loss = 0.05446521\n","Iteration 5417, loss = 0.05445805\n","Iteration 5418, loss = 0.05445100\n","Iteration 5419, loss = 0.05444392\n","Iteration 5420, loss = 0.05443689\n","Iteration 5421, loss = 0.05442981\n","Iteration 5422, loss = 0.05442288\n","Iteration 5423, loss = 0.05441584\n","Iteration 5424, loss = 0.05440871\n","Iteration 5425, loss = 0.05440182\n","Iteration 5426, loss = 0.05439487\n","Iteration 5427, loss = 0.05438786\n","Iteration 5428, loss = 0.05438079\n","Iteration 5429, loss = 0.05437367\n","Iteration 5430, loss = 0.05436678\n","Iteration 5431, loss = 0.05435987\n","Iteration 5432, loss = 0.05435285\n","Iteration 5433, loss = 0.05434574\n","Iteration 5434, loss = 0.05433877\n","Iteration 5435, loss = 0.05433188\n","Iteration 5436, loss = 0.05432493\n","Iteration 5437, loss = 0.05431793\n","Iteration 5438, loss = 0.05431088\n","Iteration 5439, loss = 0.05430398\n","Iteration 5440, loss = 0.05429710\n","Iteration 5441, loss = 0.05429011\n","Iteration 5442, loss = 0.05428305\n","Iteration 5443, loss = 0.05427615\n","Iteration 5444, loss = 0.05426920\n","Iteration 5445, loss = 0.05426233\n","Iteration 5446, loss = 0.05425540\n","Iteration 5447, loss = 0.05424846\n","Iteration 5448, loss = 0.05424157\n","Iteration 5449, loss = 0.05423464\n","Iteration 5450, loss = 0.05422782\n","Iteration 5451, loss = 0.05422093\n","Iteration 5452, loss = 0.05421395\n","Iteration 5453, loss = 0.05420708\n","Iteration 5454, loss = 0.05420022\n","Iteration 5455, loss = 0.05419334\n","Iteration 5456, loss = 0.05418646\n","Iteration 5457, loss = 0.05417965\n","Iteration 5458, loss = 0.05417280\n","Iteration 5459, loss = 0.05416590\n","Iteration 5460, loss = 0.05415918\n","Iteration 5461, loss = 0.05415236\n","Iteration 5462, loss = 0.05414543\n","Iteration 5463, loss = 0.05413864\n","Iteration 5464, loss = 0.05413188\n","Iteration 5465, loss = 0.05412507\n","Iteration 5466, loss = 0.05411822\n","Iteration 5467, loss = 0.05411132\n","Iteration 5468, loss = 0.05410460\n","Iteration 5469, loss = 0.05409787\n","Iteration 5470, loss = 0.05409101\n","Iteration 5471, loss = 0.05408412\n","Iteration 5472, loss = 0.05407738\n","Iteration 5473, loss = 0.05407060\n","Iteration 5474, loss = 0.05406377\n","Iteration 5475, loss = 0.05405711\n","Iteration 5476, loss = 0.05405036\n","Iteration 5477, loss = 0.05404350\n","Iteration 5478, loss = 0.05403682\n","Iteration 5479, loss = 0.05403015\n","Iteration 5480, loss = 0.05402342\n","Iteration 5481, loss = 0.05401665\n","Iteration 5482, loss = 0.05400984\n","Iteration 5483, loss = 0.05400306\n","Iteration 5484, loss = 0.05399638\n","Iteration 5485, loss = 0.05398959\n","Iteration 5486, loss = 0.05398297\n","Iteration 5487, loss = 0.05397632\n","Iteration 5488, loss = 0.05396963\n","Iteration 5489, loss = 0.05396289\n","Iteration 5490, loss = 0.05395612\n","Iteration 5491, loss = 0.05394946\n","Iteration 5492, loss = 0.05394282\n","Iteration 5493, loss = 0.05393607\n","Iteration 5494, loss = 0.05392940\n","Iteration 5495, loss = 0.05392279\n","Iteration 5496, loss = 0.05391614\n","Iteration 5497, loss = 0.05390944\n","Iteration 5498, loss = 0.05390271\n","Iteration 5499, loss = 0.05389616\n","Iteration 5500, loss = 0.05388956\n","Iteration 5501, loss = 0.05388283\n","Iteration 5502, loss = 0.05387617\n","Iteration 5503, loss = 0.05386960\n","Iteration 5504, loss = 0.05386299\n","Iteration 5505, loss = 0.05385634\n","Iteration 5506, loss = 0.05384965\n","Iteration 5507, loss = 0.05384310\n","Iteration 5508, loss = 0.05383653\n","Iteration 5509, loss = 0.05382982\n","Iteration 5510, loss = 0.05382330\n","Iteration 5511, loss = 0.05381677\n","Iteration 5512, loss = 0.05381021\n","Iteration 5513, loss = 0.05380360\n","Iteration 5514, loss = 0.05379696\n","Iteration 5515, loss = 0.05379029\n","Iteration 5516, loss = 0.05378390\n","Iteration 5517, loss = 0.05377741\n","Iteration 5518, loss = 0.05377078\n","Iteration 5519, loss = 0.05376403\n","Iteration 5520, loss = 0.05375754\n","Iteration 5521, loss = 0.05375100\n","Iteration 5522, loss = 0.05374443\n","Iteration 5523, loss = 0.05373791\n","Iteration 5524, loss = 0.05373135\n","Iteration 5525, loss = 0.05372488\n","Iteration 5526, loss = 0.05371839\n","Iteration 5527, loss = 0.05371187\n","Iteration 5528, loss = 0.05370532\n","Iteration 5529, loss = 0.05369876\n","Iteration 5530, loss = 0.05369224\n","Iteration 5531, loss = 0.05368581\n","Iteration 5532, loss = 0.05367935\n","Iteration 5533, loss = 0.05367285\n","Iteration 5534, loss = 0.05366633\n","Iteration 5535, loss = 0.05365984\n","Iteration 5536, loss = 0.05365336\n","Iteration 5537, loss = 0.05364690\n","Iteration 5538, loss = 0.05364046\n","Iteration 5539, loss = 0.05363399\n","Iteration 5540, loss = 0.05362749\n","Iteration 5541, loss = 0.05362110\n","Iteration 5542, loss = 0.05361464\n","Iteration 5543, loss = 0.05360815\n","Iteration 5544, loss = 0.05360175\n","Iteration 5545, loss = 0.05359531\n","Iteration 5546, loss = 0.05358884\n","Iteration 5547, loss = 0.05358249\n","Iteration 5548, loss = 0.05357606\n","Iteration 5549, loss = 0.05356960\n","Iteration 5550, loss = 0.05356322\n","Iteration 5551, loss = 0.05355681\n","Iteration 5552, loss = 0.05355037\n","Iteration 5553, loss = 0.05354400\n","Iteration 5554, loss = 0.05353758\n","Iteration 5555, loss = 0.05353122\n","Iteration 5556, loss = 0.05352488\n","Iteration 5557, loss = 0.05351850\n","Iteration 5558, loss = 0.05351210\n","Iteration 5559, loss = 0.05350567\n","Iteration 5560, loss = 0.05349943\n","Iteration 5561, loss = 0.05349308\n","Iteration 5562, loss = 0.05348658\n","Iteration 5563, loss = 0.05348033\n","Iteration 5564, loss = 0.05347406\n","Iteration 5565, loss = 0.05346776\n","Iteration 5566, loss = 0.05346143\n","Iteration 5567, loss = 0.05345507\n","Iteration 5568, loss = 0.05344869\n","Iteration 5569, loss = 0.05344228\n","Iteration 5570, loss = 0.05343589\n","Iteration 5571, loss = 0.05342962\n","Iteration 5572, loss = 0.05342326\n","Iteration 5573, loss = 0.05341696\n","Iteration 5574, loss = 0.05341064\n","Iteration 5575, loss = 0.05340440\n","Iteration 5576, loss = 0.05339804\n","Iteration 5577, loss = 0.05339175\n","Iteration 5578, loss = 0.05338552\n","Iteration 5579, loss = 0.05337927\n","Iteration 5580, loss = 0.05337299\n","Iteration 5581, loss = 0.05336668\n","Iteration 5582, loss = 0.05336037\n","Iteration 5583, loss = 0.05335411\n","Iteration 5584, loss = 0.05334784\n","Iteration 5585, loss = 0.05334167\n","Iteration 5586, loss = 0.05333534\n","Iteration 5587, loss = 0.05332918\n","Iteration 5588, loss = 0.05332300\n","Iteration 5589, loss = 0.05331679\n","Iteration 5590, loss = 0.05331055\n","Iteration 5591, loss = 0.05330429\n","Iteration 5592, loss = 0.05329801\n","Iteration 5593, loss = 0.05329171\n","Iteration 5594, loss = 0.05328570\n","Iteration 5595, loss = 0.05327953\n","Iteration 5596, loss = 0.05327320\n","Iteration 5597, loss = 0.05326692\n","Iteration 5598, loss = 0.05326079\n","Iteration 5599, loss = 0.05325464\n","Iteration 5600, loss = 0.05324846\n","Iteration 5601, loss = 0.05324225\n","Iteration 5602, loss = 0.05323603\n","Iteration 5603, loss = 0.05322979\n","Iteration 5604, loss = 0.05322361\n","Iteration 5605, loss = 0.05321745\n","Iteration 5606, loss = 0.05321126\n","Iteration 5607, loss = 0.05320513\n","Iteration 5608, loss = 0.05319897\n","Iteration 5609, loss = 0.05319279\n","Iteration 5610, loss = 0.05318661\n","Iteration 5611, loss = 0.05318048\n","Iteration 5612, loss = 0.05317434\n","Iteration 5613, loss = 0.05316820\n","Iteration 5614, loss = 0.05316209\n","Iteration 5615, loss = 0.05315598\n","Iteration 5616, loss = 0.05314984\n","Iteration 5617, loss = 0.05314369\n","Iteration 5618, loss = 0.05313770\n","Iteration 5619, loss = 0.05313154\n","Iteration 5620, loss = 0.05312541\n","Iteration 5621, loss = 0.05311935\n","Iteration 5622, loss = 0.05311328\n","Iteration 5623, loss = 0.05310718\n","Iteration 5624, loss = 0.05310106\n","Iteration 5625, loss = 0.05309493\n","Iteration 5626, loss = 0.05308885\n","Iteration 5627, loss = 0.05308276\n","Iteration 5628, loss = 0.05307672\n","Iteration 5629, loss = 0.05307069\n","Iteration 5630, loss = 0.05306464\n","Iteration 5631, loss = 0.05305857\n","Iteration 5632, loss = 0.05305249\n","Iteration 5633, loss = 0.05304639\n","Iteration 5634, loss = 0.05304040\n","Iteration 5635, loss = 0.05303433\n","Iteration 5636, loss = 0.05302827\n","Iteration 5637, loss = 0.05302227\n","Iteration 5638, loss = 0.05301625\n","Iteration 5639, loss = 0.05301022\n","Iteration 5640, loss = 0.05300417\n","Iteration 5641, loss = 0.05299811\n","Iteration 5642, loss = 0.05299217\n","Iteration 5643, loss = 0.05298613\n","Iteration 5644, loss = 0.05298009\n","Iteration 5645, loss = 0.05297413\n","Iteration 5646, loss = 0.05296815\n","Iteration 5647, loss = 0.05296215\n","Iteration 5648, loss = 0.05295614\n","Iteration 5649, loss = 0.05295012\n","Iteration 5650, loss = 0.05294411\n","Iteration 5651, loss = 0.05293812\n","Iteration 5652, loss = 0.05293213\n","Iteration 5653, loss = 0.05292622\n","Iteration 5654, loss = 0.05292028\n","Iteration 5655, loss = 0.05291432\n","Iteration 5656, loss = 0.05290835\n","Iteration 5657, loss = 0.05290237\n","Iteration 5658, loss = 0.05289638\n","Iteration 5659, loss = 0.05289056\n","Iteration 5660, loss = 0.05288459\n","Iteration 5661, loss = 0.05287857\n","Iteration 5662, loss = 0.05287267\n","Iteration 5663, loss = 0.05286676\n","Iteration 5664, loss = 0.05286084\n","Iteration 5665, loss = 0.05285490\n","Iteration 5666, loss = 0.05284895\n","Iteration 5667, loss = 0.05284299\n","Iteration 5668, loss = 0.05283722\n","Iteration 5669, loss = 0.05283129\n","Iteration 5670, loss = 0.05282529\n","Iteration 5671, loss = 0.05281943\n","Iteration 5672, loss = 0.05281355\n","Iteration 5673, loss = 0.05280766\n","Iteration 5674, loss = 0.05280176\n","Iteration 5675, loss = 0.05279585\n","Iteration 5676, loss = 0.05278993\n","Iteration 5677, loss = 0.05278418\n","Iteration 5678, loss = 0.05277827\n","Iteration 5679, loss = 0.05277233\n","Iteration 5680, loss = 0.05276651\n","Iteration 5681, loss = 0.05276067\n","Iteration 5682, loss = 0.05275482\n","Iteration 5683, loss = 0.05274896\n","Iteration 5684, loss = 0.05274309\n","Iteration 5685, loss = 0.05273720\n","Iteration 5686, loss = 0.05273133\n","Iteration 5687, loss = 0.05272549\n","Iteration 5688, loss = 0.05271966\n","Iteration 5689, loss = 0.05271384\n","Iteration 5690, loss = 0.05270802\n","Iteration 5691, loss = 0.05270222\n","Iteration 5692, loss = 0.05269641\n","Iteration 5693, loss = 0.05269059\n","Iteration 5694, loss = 0.05268476\n","Iteration 5695, loss = 0.05267892\n","Iteration 5696, loss = 0.05267327\n","Iteration 5697, loss = 0.05266740\n","Iteration 5698, loss = 0.05266156\n","Iteration 5699, loss = 0.05265581\n","Iteration 5700, loss = 0.05265005\n","Iteration 5701, loss = 0.05264428\n","Iteration 5702, loss = 0.05263850\n","Iteration 5703, loss = 0.05263271\n","Iteration 5704, loss = 0.05262691\n","Iteration 5705, loss = 0.05262110\n","Iteration 5706, loss = 0.05261529\n","Iteration 5707, loss = 0.05260965\n","Iteration 5708, loss = 0.05260387\n","Iteration 5709, loss = 0.05259803\n","Iteration 5710, loss = 0.05259232\n","Iteration 5711, loss = 0.05258660\n","Iteration 5712, loss = 0.05258086\n","Iteration 5713, loss = 0.05257512\n","Iteration 5714, loss = 0.05256937\n","Iteration 5715, loss = 0.05256361\n","Iteration 5716, loss = 0.05255784\n","Iteration 5717, loss = 0.05255215\n","Iteration 5718, loss = 0.05254637\n","Iteration 5719, loss = 0.05254065\n","Iteration 5720, loss = 0.05253498\n","Iteration 5721, loss = 0.05252926\n","Iteration 5722, loss = 0.05252358\n","Iteration 5723, loss = 0.05251789\n","Iteration 5724, loss = 0.05251219\n","Iteration 5725, loss = 0.05250648\n","Iteration 5726, loss = 0.05250077\n","Iteration 5727, loss = 0.05249505\n","Iteration 5728, loss = 0.05248946\n","Iteration 5729, loss = 0.05248369\n","Iteration 5730, loss = 0.05247805\n","Iteration 5731, loss = 0.05247243\n","Iteration 5732, loss = 0.05246679\n","Iteration 5733, loss = 0.05246114\n","Iteration 5734, loss = 0.05245548\n","Iteration 5735, loss = 0.05244982\n","Iteration 5736, loss = 0.05244415\n","Iteration 5737, loss = 0.05243848\n","Iteration 5738, loss = 0.05243280\n","Iteration 5739, loss = 0.05242712\n","Iteration 5740, loss = 0.05242144\n","Iteration 5741, loss = 0.05241588\n","Iteration 5742, loss = 0.05241021\n","Iteration 5743, loss = 0.05240455\n","Iteration 5744, loss = 0.05239896\n","Iteration 5745, loss = 0.05239336\n","Iteration 5746, loss = 0.05238775\n","Iteration 5747, loss = 0.05238214\n","Iteration 5748, loss = 0.05237652\n","Iteration 5749, loss = 0.05237090\n","Iteration 5750, loss = 0.05236527\n","Iteration 5751, loss = 0.05235964\n","Iteration 5752, loss = 0.05235401\n","Iteration 5753, loss = 0.05234848\n","Iteration 5754, loss = 0.05234282\n","Iteration 5755, loss = 0.05233726\n","Iteration 5756, loss = 0.05233172\n","Iteration 5757, loss = 0.05232617\n","Iteration 5758, loss = 0.05232061\n","Iteration 5759, loss = 0.05231504\n","Iteration 5760, loss = 0.05230947\n","Iteration 5761, loss = 0.05230389\n","Iteration 5762, loss = 0.05229831\n","Iteration 5763, loss = 0.05229273\n","Iteration 5764, loss = 0.05228715\n","Iteration 5765, loss = 0.05228157\n","Iteration 5766, loss = 0.05227598\n","Iteration 5767, loss = 0.05227056\n","Iteration 5768, loss = 0.05226496\n","Iteration 5769, loss = 0.05225938\n","Iteration 5770, loss = 0.05225388\n","Iteration 5771, loss = 0.05224837\n","Iteration 5772, loss = 0.05224286\n","Iteration 5773, loss = 0.05223734\n","Iteration 5774, loss = 0.05223182\n","Iteration 5775, loss = 0.05222629\n","Iteration 5776, loss = 0.05222077\n","Iteration 5777, loss = 0.05221524\n","Iteration 5778, loss = 0.05220971\n","Iteration 5779, loss = 0.05220418\n","Iteration 5780, loss = 0.05219865\n","Iteration 5781, loss = 0.05219321\n","Iteration 5782, loss = 0.05218764\n","Iteration 5783, loss = 0.05218219\n","Iteration 5784, loss = 0.05217675\n","Iteration 5785, loss = 0.05217129\n","Iteration 5786, loss = 0.05216583\n","Iteration 5787, loss = 0.05216036\n","Iteration 5788, loss = 0.05215489\n","Iteration 5789, loss = 0.05214942\n","Iteration 5790, loss = 0.05214395\n","Iteration 5791, loss = 0.05213847\n","Iteration 5792, loss = 0.05213299\n","Iteration 5793, loss = 0.05212751\n","Iteration 5794, loss = 0.05212204\n","Iteration 5795, loss = 0.05211656\n","Iteration 5796, loss = 0.05211109\n","Iteration 5797, loss = 0.05210567\n","Iteration 5798, loss = 0.05210018\n","Iteration 5799, loss = 0.05209475\n","Iteration 5800, loss = 0.05208932\n","Iteration 5801, loss = 0.05208388\n","Iteration 5802, loss = 0.05207850\n","Iteration 5803, loss = 0.05207305\n","Iteration 5804, loss = 0.05206764\n","Iteration 5805, loss = 0.05206224\n","Iteration 5806, loss = 0.05205683\n","Iteration 5807, loss = 0.05205143\n","Iteration 5808, loss = 0.05204602\n","Iteration 5809, loss = 0.05204060\n","Iteration 5810, loss = 0.05203519\n","Iteration 5811, loss = 0.05202978\n","Iteration 5812, loss = 0.05202437\n","Iteration 5813, loss = 0.05201901\n","Iteration 5814, loss = 0.05201359\n","Iteration 5815, loss = 0.05200822\n","Iteration 5816, loss = 0.05200285\n","Iteration 5817, loss = 0.05199747\n","Iteration 5818, loss = 0.05199210\n","Iteration 5819, loss = 0.05198672\n","Iteration 5820, loss = 0.05198134\n","Iteration 5821, loss = 0.05197597\n","Iteration 5822, loss = 0.05197068\n","Iteration 5823, loss = 0.05196525\n","Iteration 5824, loss = 0.05195991\n","Iteration 5825, loss = 0.05195457\n","Iteration 5826, loss = 0.05194923\n","Iteration 5827, loss = 0.05194388\n","Iteration 5828, loss = 0.05193854\n","Iteration 5829, loss = 0.05193319\n","Iteration 5830, loss = 0.05192785\n","Iteration 5831, loss = 0.05192251\n","Iteration 5832, loss = 0.05191717\n","Iteration 5833, loss = 0.05191196\n","Iteration 5834, loss = 0.05190652\n","Iteration 5835, loss = 0.05190122\n","Iteration 5836, loss = 0.05189591\n","Iteration 5837, loss = 0.05189060\n","Iteration 5838, loss = 0.05188529\n","Iteration 5839, loss = 0.05187998\n","Iteration 5840, loss = 0.05187467\n","Iteration 5841, loss = 0.05186937\n","Iteration 5842, loss = 0.05186406\n","Iteration 5843, loss = 0.05185876\n","Iteration 5844, loss = 0.05185358\n","Iteration 5845, loss = 0.05184819\n","Iteration 5846, loss = 0.05184291\n","Iteration 5847, loss = 0.05183764\n","Iteration 5848, loss = 0.05183237\n","Iteration 5849, loss = 0.05182710\n","Iteration 5850, loss = 0.05182183\n","Iteration 5851, loss = 0.05181655\n","Iteration 5852, loss = 0.05181129\n","Iteration 5853, loss = 0.05180602\n","Iteration 5854, loss = 0.05180075\n","Iteration 5855, loss = 0.05179548\n","Iteration 5856, loss = 0.05179022\n","Iteration 5857, loss = 0.05178510\n","Iteration 5858, loss = 0.05177973\n","Iteration 5859, loss = 0.05177450\n","Iteration 5860, loss = 0.05176927\n","Iteration 5861, loss = 0.05176403\n","Iteration 5862, loss = 0.05175880\n","Iteration 5863, loss = 0.05175357\n","Iteration 5864, loss = 0.05174834\n","Iteration 5865, loss = 0.05174311\n","Iteration 5866, loss = 0.05173789\n","Iteration 5867, loss = 0.05173266\n","Iteration 5868, loss = 0.05172744\n","Iteration 5869, loss = 0.05172222\n","Iteration 5870, loss = 0.05171700\n","Iteration 5871, loss = 0.05171187\n","Iteration 5872, loss = 0.05170660\n","Iteration 5873, loss = 0.05170141\n","Iteration 5874, loss = 0.05169622\n","Iteration 5875, loss = 0.05169103\n","Iteration 5876, loss = 0.05168584\n","Iteration 5877, loss = 0.05168066\n","Iteration 5878, loss = 0.05167547\n","Iteration 5879, loss = 0.05167029\n","Iteration 5880, loss = 0.05166511\n","Iteration 5881, loss = 0.05165993\n","Iteration 5882, loss = 0.05165475\n","Iteration 5883, loss = 0.05164957\n","Iteration 5884, loss = 0.05164440\n","Iteration 5885, loss = 0.05163923\n","Iteration 5886, loss = 0.05163406\n","Iteration 5887, loss = 0.05162890\n","Iteration 5888, loss = 0.05162375\n","Iteration 5889, loss = 0.05161860\n","Iteration 5890, loss = 0.05161346\n","Iteration 5891, loss = 0.05160832\n","Iteration 5892, loss = 0.05160318\n","Iteration 5893, loss = 0.05159805\n","Iteration 5894, loss = 0.05159291\n","Iteration 5895, loss = 0.05158778\n","Iteration 5896, loss = 0.05158265\n","Iteration 5897, loss = 0.05157752\n","Iteration 5898, loss = 0.05157239\n","Iteration 5899, loss = 0.05156727\n","Iteration 5900, loss = 0.05156214\n","Iteration 5901, loss = 0.05155702\n","Iteration 5902, loss = 0.05155191\n","Iteration 5903, loss = 0.05154679\n","Iteration 5904, loss = 0.05154168\n","Iteration 5905, loss = 0.05153657\n","Iteration 5906, loss = 0.05153147\n","Iteration 5907, loss = 0.05152636\n","Iteration 5908, loss = 0.05152126\n","Iteration 5909, loss = 0.05151617\n","Iteration 5910, loss = 0.05151107\n","Iteration 5911, loss = 0.05150604\n","Iteration 5912, loss = 0.05150091\n","Iteration 5913, loss = 0.05149583\n","Iteration 5914, loss = 0.05149076\n","Iteration 5915, loss = 0.05148569\n","Iteration 5916, loss = 0.05148062\n","Iteration 5917, loss = 0.05147555\n","Iteration 5918, loss = 0.05147049\n","Iteration 5919, loss = 0.05146542\n","Iteration 5920, loss = 0.05146036\n","Iteration 5921, loss = 0.05145530\n","Iteration 5922, loss = 0.05145025\n","Iteration 5923, loss = 0.05144519\n","Iteration 5924, loss = 0.05144014\n","Iteration 5925, loss = 0.05143509\n","Iteration 5926, loss = 0.05143005\n","Iteration 5927, loss = 0.05142500\n","Iteration 5928, loss = 0.05141996\n","Iteration 5929, loss = 0.05141493\n","Iteration 5930, loss = 0.05140989\n","Iteration 5931, loss = 0.05140486\n","Iteration 5932, loss = 0.05139983\n","Iteration 5933, loss = 0.05139481\n","Iteration 5934, loss = 0.05138978\n","Iteration 5935, loss = 0.05138476\n","Iteration 5936, loss = 0.05137974\n","Iteration 5937, loss = 0.05137473\n","Iteration 5938, loss = 0.05136972\n","Iteration 5939, loss = 0.05136471\n","Iteration 5940, loss = 0.05135970\n","Iteration 5941, loss = 0.05135470\n","Iteration 5942, loss = 0.05134970\n","Iteration 5943, loss = 0.05134470\n","Iteration 5944, loss = 0.05133971\n","Iteration 5945, loss = 0.05133472\n","Iteration 5946, loss = 0.05132973\n","Iteration 5947, loss = 0.05132474\n","Iteration 5948, loss = 0.05131976\n","Iteration 5949, loss = 0.05131478\n","Iteration 5950, loss = 0.05130980\n","Iteration 5951, loss = 0.05130483\n","Iteration 5952, loss = 0.05129986\n","Iteration 5953, loss = 0.05129489\n","Iteration 5954, loss = 0.05128992\n","Iteration 5955, loss = 0.05128497\n","Iteration 5956, loss = 0.05128000\n","Iteration 5957, loss = 0.05127505\n","Iteration 5958, loss = 0.05127009\n","Iteration 5959, loss = 0.05126514\n","Iteration 5960, loss = 0.05126019\n","Iteration 5961, loss = 0.05125524\n","Iteration 5962, loss = 0.05125030\n","Iteration 5963, loss = 0.05124536\n","Iteration 5964, loss = 0.05124042\n","Iteration 5965, loss = 0.05123548\n","Iteration 5966, loss = 0.05123055\n","Iteration 5967, loss = 0.05122562\n","Iteration 5968, loss = 0.05122069\n","Iteration 5969, loss = 0.05121576\n","Iteration 5970, loss = 0.05121084\n","Iteration 5971, loss = 0.05120591\n","Iteration 5972, loss = 0.05120099\n","Iteration 5973, loss = 0.05119608\n","Iteration 5974, loss = 0.05119116\n","Iteration 5975, loss = 0.05118625\n","Iteration 5976, loss = 0.05118134\n","Iteration 5977, loss = 0.05117644\n","Iteration 5978, loss = 0.05117153\n","Iteration 5979, loss = 0.05116663\n","Iteration 5980, loss = 0.05116174\n","Iteration 5981, loss = 0.05115684\n","Iteration 5982, loss = 0.05115195\n","Iteration 5983, loss = 0.05114706\n","Iteration 5984, loss = 0.05114217\n","Iteration 5985, loss = 0.05113728\n","Iteration 5986, loss = 0.05113240\n","Iteration 5987, loss = 0.05112752\n","Iteration 5988, loss = 0.05112264\n","Iteration 5989, loss = 0.05111776\n","Iteration 5990, loss = 0.05111289\n","Iteration 5991, loss = 0.05110802\n","Iteration 5992, loss = 0.05110316\n","Iteration 5993, loss = 0.05109829\n","Iteration 5994, loss = 0.05109343\n","Iteration 5995, loss = 0.05108857\n","Iteration 5996, loss = 0.05108372\n","Iteration 5997, loss = 0.05107887\n","Iteration 5998, loss = 0.05107401\n","Iteration 5999, loss = 0.05106917\n","Iteration 6000, loss = 0.05106432\n","Iteration 6001, loss = 0.05105948\n","Iteration 6002, loss = 0.05105464\n","Iteration 6003, loss = 0.05104981\n","Iteration 6004, loss = 0.05104497\n","Iteration 6005, loss = 0.05104014\n","Iteration 6006, loss = 0.05103531\n","Iteration 6007, loss = 0.05103048\n","Iteration 6008, loss = 0.05102566\n","Iteration 6009, loss = 0.05102084\n","Iteration 6010, loss = 0.05101602\n","Iteration 6011, loss = 0.05101120\n","Iteration 6012, loss = 0.05100639\n","Iteration 6013, loss = 0.05100157\n","Iteration 6014, loss = 0.05099679\n","Iteration 6015, loss = 0.05099196\n","Iteration 6016, loss = 0.05098716\n","Iteration 6017, loss = 0.05098237\n","Iteration 6018, loss = 0.05097758\n","Iteration 6019, loss = 0.05097279\n","Iteration 6020, loss = 0.05096800\n","Iteration 6021, loss = 0.05096321\n","Iteration 6022, loss = 0.05095843\n","Iteration 6023, loss = 0.05095364\n","Iteration 6024, loss = 0.05094886\n","Iteration 6025, loss = 0.05094408\n","Iteration 6026, loss = 0.05093930\n","Iteration 6027, loss = 0.05093452\n","Iteration 6028, loss = 0.05092974\n","Iteration 6029, loss = 0.05092497\n","Iteration 6030, loss = 0.05092020\n","Iteration 6031, loss = 0.05091543\n","Iteration 6032, loss = 0.05091069\n","Iteration 6033, loss = 0.05090593\n","Iteration 6034, loss = 0.05090115\n","Iteration 6035, loss = 0.05089640\n","Iteration 6036, loss = 0.05089166\n","Iteration 6037, loss = 0.05088691\n","Iteration 6038, loss = 0.05088216\n","Iteration 6039, loss = 0.05087742\n","Iteration 6040, loss = 0.05087268\n","Iteration 6041, loss = 0.05086793\n","Iteration 6042, loss = 0.05086319\n","Iteration 6043, loss = 0.05085847\n","Iteration 6044, loss = 0.05085373\n","Iteration 6045, loss = 0.05084901\n","Iteration 6046, loss = 0.05084429\n","Iteration 6047, loss = 0.05083957\n","Iteration 6048, loss = 0.05083485\n","Iteration 6049, loss = 0.05083013\n","Iteration 6050, loss = 0.05082542\n","Iteration 6051, loss = 0.05082070\n","Iteration 6052, loss = 0.05081599\n","Iteration 6053, loss = 0.05081127\n","Iteration 6054, loss = 0.05080656\n","Iteration 6055, loss = 0.05080188\n","Iteration 6056, loss = 0.05079718\n","Iteration 6057, loss = 0.05079246\n","Iteration 6058, loss = 0.05078777\n","Iteration 6059, loss = 0.05078308\n","Iteration 6060, loss = 0.05077839\n","Iteration 6061, loss = 0.05077370\n","Iteration 6062, loss = 0.05076901\n","Iteration 6063, loss = 0.05076433\n","Iteration 6064, loss = 0.05075964\n","Iteration 6065, loss = 0.05075496\n","Iteration 6066, loss = 0.05075028\n","Iteration 6067, loss = 0.05074562\n","Iteration 6068, loss = 0.05074095\n","Iteration 6069, loss = 0.05073628\n","Iteration 6070, loss = 0.05073162\n","Iteration 6071, loss = 0.05072695\n","Iteration 6072, loss = 0.05072229\n","Iteration 6073, loss = 0.05071762\n","Iteration 6074, loss = 0.05071297\n","Iteration 6075, loss = 0.05070832\n","Iteration 6076, loss = 0.05070366\n","Iteration 6077, loss = 0.05069902\n","Iteration 6078, loss = 0.05069437\n","Iteration 6079, loss = 0.05068972\n","Iteration 6080, loss = 0.05068508\n","Iteration 6081, loss = 0.05068043\n","Iteration 6082, loss = 0.05067578\n","Iteration 6083, loss = 0.05067115\n","Iteration 6084, loss = 0.05066650\n","Iteration 6085, loss = 0.05066187\n","Iteration 6086, loss = 0.05065725\n","Iteration 6087, loss = 0.05065260\n","Iteration 6088, loss = 0.05064798\n","Iteration 6089, loss = 0.05064334\n","Iteration 6090, loss = 0.05063872\n","Iteration 6091, loss = 0.05063410\n","Iteration 6092, loss = 0.05062948\n","Iteration 6093, loss = 0.05062485\n","Iteration 6094, loss = 0.05062022\n","Iteration 6095, loss = 0.05061559\n","Iteration 6096, loss = 0.05061098\n","Iteration 6097, loss = 0.05060636\n","Iteration 6098, loss = 0.05060173\n","Iteration 6099, loss = 0.05059712\n","Iteration 6100, loss = 0.05059250\n","Iteration 6101, loss = 0.05058788\n","Iteration 6102, loss = 0.05058327\n","Iteration 6103, loss = 0.05057864\n","Iteration 6104, loss = 0.05057404\n","Iteration 6105, loss = 0.05056944\n","Iteration 6106, loss = 0.05056483\n","Iteration 6107, loss = 0.05056022\n","Iteration 6108, loss = 0.05055560\n","Iteration 6109, loss = 0.05055098\n","Iteration 6110, loss = 0.05054640\n","Iteration 6111, loss = 0.05054180\n","Iteration 6112, loss = 0.05053718\n","Iteration 6113, loss = 0.05053256\n","Iteration 6114, loss = 0.05052796\n","Iteration 6115, loss = 0.05052336\n","Iteration 6116, loss = 0.05051876\n","Iteration 6117, loss = 0.05051416\n","Iteration 6118, loss = 0.05050954\n","Iteration 6119, loss = 0.05050497\n","Iteration 6120, loss = 0.05050038\n","Iteration 6121, loss = 0.05049577\n","Iteration 6122, loss = 0.05049117\n","Iteration 6123, loss = 0.05048659\n","Iteration 6124, loss = 0.05048200\n","Iteration 6125, loss = 0.05047740\n","Iteration 6126, loss = 0.05047281\n","Iteration 6127, loss = 0.05046820\n","Iteration 6128, loss = 0.05046365\n","Iteration 6129, loss = 0.05045908\n","Iteration 6130, loss = 0.05045448\n","Iteration 6131, loss = 0.05044987\n","Iteration 6132, loss = 0.05044531\n","Iteration 6133, loss = 0.05044075\n","Iteration 6134, loss = 0.05043618\n","Iteration 6135, loss = 0.05043161\n","Iteration 6136, loss = 0.05042703\n","Iteration 6137, loss = 0.05042245\n","Iteration 6138, loss = 0.05041786\n","Iteration 6139, loss = 0.05041327\n","Iteration 6140, loss = 0.05040872\n","Iteration 6141, loss = 0.05040415\n","Iteration 6142, loss = 0.05039957\n","Iteration 6143, loss = 0.05039501\n","Iteration 6144, loss = 0.05039045\n","Iteration 6145, loss = 0.05038589\n","Iteration 6146, loss = 0.05038133\n","Iteration 6147, loss = 0.05037678\n","Iteration 6148, loss = 0.05037223\n","Iteration 6149, loss = 0.05036768\n","Iteration 6150, loss = 0.05036312\n","Iteration 6151, loss = 0.05035859\n","Iteration 6152, loss = 0.05035405\n","Iteration 6153, loss = 0.05034949\n","Iteration 6154, loss = 0.05034493\n","Iteration 6155, loss = 0.05034040\n","Iteration 6156, loss = 0.05033586\n","Iteration 6157, loss = 0.05033131\n","Iteration 6158, loss = 0.05032680\n","Iteration 6159, loss = 0.05032227\n","Iteration 6160, loss = 0.05031773\n","Iteration 6161, loss = 0.05031319\n","Iteration 6162, loss = 0.05030867\n","Iteration 6163, loss = 0.05030414\n","Iteration 6164, loss = 0.05029961\n","Iteration 6165, loss = 0.05029510\n","Iteration 6166, loss = 0.05029059\n","Iteration 6167, loss = 0.05028606\n","Iteration 6168, loss = 0.05028153\n","Iteration 6169, loss = 0.05027702\n","Iteration 6170, loss = 0.05027251\n","Iteration 6171, loss = 0.05026800\n","Iteration 6172, loss = 0.05026349\n","Iteration 6173, loss = 0.05025898\n","Iteration 6174, loss = 0.05025448\n","Iteration 6175, loss = 0.05024998\n","Iteration 6176, loss = 0.05024547\n","Iteration 6177, loss = 0.05024099\n","Iteration 6178, loss = 0.05023649\n","Iteration 6179, loss = 0.05023199\n","Iteration 6180, loss = 0.05022751\n","Iteration 6181, loss = 0.05022302\n","Iteration 6182, loss = 0.05021853\n","Iteration 6183, loss = 0.05021404\n","Iteration 6184, loss = 0.05020956\n","Iteration 6185, loss = 0.05020508\n","Iteration 6186, loss = 0.05020060\n","Iteration 6187, loss = 0.05019612\n","Iteration 6188, loss = 0.05019164\n","Iteration 6189, loss = 0.05018718\n","Iteration 6190, loss = 0.05018272\n","Iteration 6191, loss = 0.05017824\n","Iteration 6192, loss = 0.05017376\n","Iteration 6193, loss = 0.05016930\n","Iteration 6194, loss = 0.05016483\n","Iteration 6195, loss = 0.05016039\n","Iteration 6196, loss = 0.05015594\n","Iteration 6197, loss = 0.05015147\n","Iteration 6198, loss = 0.05014701\n","Iteration 6199, loss = 0.05014256\n","Iteration 6200, loss = 0.05013811\n","Iteration 6201, loss = 0.05013367\n","Iteration 6202, loss = 0.05012922\n","Iteration 6203, loss = 0.05012477\n","Iteration 6204, loss = 0.05012035\n","Iteration 6205, loss = 0.05011592\n","Iteration 6206, loss = 0.05011148\n","Iteration 6207, loss = 0.05010703\n","Iteration 6208, loss = 0.05010259\n","Iteration 6209, loss = 0.05009817\n","Iteration 6210, loss = 0.05009374\n","Iteration 6211, loss = 0.05008931\n","Iteration 6212, loss = 0.05008489\n","Iteration 6213, loss = 0.05008046\n","Iteration 6214, loss = 0.05007604\n","Iteration 6215, loss = 0.05007162\n","Iteration 6216, loss = 0.05006721\n","Iteration 6217, loss = 0.05006279\n","Iteration 6218, loss = 0.05005838\n","Iteration 6219, loss = 0.05005397\n","Iteration 6220, loss = 0.05004956\n","Iteration 6221, loss = 0.05004517\n","Iteration 6222, loss = 0.05004076\n","Iteration 6223, loss = 0.05003636\n","Iteration 6224, loss = 0.05003196\n","Iteration 6225, loss = 0.05002757\n","Iteration 6226, loss = 0.05002318\n","Iteration 6227, loss = 0.05001878\n","Iteration 6228, loss = 0.05001438\n","Iteration 6229, loss = 0.05000999\n","Iteration 6230, loss = 0.05000562\n","Iteration 6231, loss = 0.05000124\n","Iteration 6232, loss = 0.04999685\n","Iteration 6233, loss = 0.04999246\n","Iteration 6234, loss = 0.04998808\n","Iteration 6235, loss = 0.04998372\n","Iteration 6236, loss = 0.04997935\n","Iteration 6237, loss = 0.04997497\n","Iteration 6238, loss = 0.04997060\n","Iteration 6239, loss = 0.04996623\n","Iteration 6240, loss = 0.04996187\n","Iteration 6241, loss = 0.04995750\n","Iteration 6242, loss = 0.04995314\n","Iteration 6243, loss = 0.04994879\n","Iteration 6244, loss = 0.04994443\n","Iteration 6245, loss = 0.04994008\n","Iteration 6246, loss = 0.04993574\n","Iteration 6247, loss = 0.04993139\n","Iteration 6248, loss = 0.04992704\n","Iteration 6249, loss = 0.04992268\n","Iteration 6250, loss = 0.04991833\n","Iteration 6251, loss = 0.04991400\n","Iteration 6252, loss = 0.04990965\n","Iteration 6253, loss = 0.04990532\n","Iteration 6254, loss = 0.04990099\n","Iteration 6255, loss = 0.04989666\n","Iteration 6256, loss = 0.04989233\n","Iteration 6257, loss = 0.04988799\n","Iteration 6258, loss = 0.04988368\n","Iteration 6259, loss = 0.04987936\n","Iteration 6260, loss = 0.04987502\n","Iteration 6261, loss = 0.04987070\n","Iteration 6262, loss = 0.04986638\n","Iteration 6263, loss = 0.04986207\n","Iteration 6264, loss = 0.04985775\n","Iteration 6265, loss = 0.04985345\n","Iteration 6266, loss = 0.04984915\n","Iteration 6267, loss = 0.04984485\n","Iteration 6268, loss = 0.04984054\n","Iteration 6269, loss = 0.04983623\n","Iteration 6270, loss = 0.04983191\n","Iteration 6271, loss = 0.04982764\n","Iteration 6272, loss = 0.04982334\n","Iteration 6273, loss = 0.04981903\n","Iteration 6274, loss = 0.04981474\n","Iteration 6275, loss = 0.04981046\n","Iteration 6276, loss = 0.04980618\n","Iteration 6277, loss = 0.04980189\n","Iteration 6278, loss = 0.04979760\n","Iteration 6279, loss = 0.04979331\n","Iteration 6280, loss = 0.04978902\n","Iteration 6281, loss = 0.04978475\n","Iteration 6282, loss = 0.04978048\n","Iteration 6283, loss = 0.04977619\n","Iteration 6284, loss = 0.04977192\n","Iteration 6285, loss = 0.04976765\n","Iteration 6286, loss = 0.04976338\n","Iteration 6287, loss = 0.04975913\n","Iteration 6288, loss = 0.04975486\n","Iteration 6289, loss = 0.04975060\n","Iteration 6290, loss = 0.04974635\n","Iteration 6291, loss = 0.04974210\n","Iteration 6292, loss = 0.04973784\n","Iteration 6293, loss = 0.04973359\n","Iteration 6294, loss = 0.04972933\n","Iteration 6295, loss = 0.04972507\n","Iteration 6296, loss = 0.04972084\n","Iteration 6297, loss = 0.04971660\n","Iteration 6298, loss = 0.04971234\n","Iteration 6299, loss = 0.04970811\n","Iteration 6300, loss = 0.04970387\n","Iteration 6301, loss = 0.04969963\n","Iteration 6302, loss = 0.04969539\n","Iteration 6303, loss = 0.04969116\n","Iteration 6304, loss = 0.04968693\n","Iteration 6305, loss = 0.04968270\n","Iteration 6306, loss = 0.04967848\n","Iteration 6307, loss = 0.04967426\n","Iteration 6308, loss = 0.04967003\n","Iteration 6309, loss = 0.04966582\n","Iteration 6310, loss = 0.04966160\n","Iteration 6311, loss = 0.04965738\n","Iteration 6312, loss = 0.04965318\n","Iteration 6313, loss = 0.04964896\n","Iteration 6314, loss = 0.04964475\n","Iteration 6315, loss = 0.04964054\n","Iteration 6316, loss = 0.04963633\n","Iteration 6317, loss = 0.04963214\n","Iteration 6318, loss = 0.04962793\n","Iteration 6319, loss = 0.04962373\n","Iteration 6320, loss = 0.04961954\n","Iteration 6321, loss = 0.04961534\n","Iteration 6322, loss = 0.04961115\n","Iteration 6323, loss = 0.04960696\n","Iteration 6324, loss = 0.04960277\n","Iteration 6325, loss = 0.04959858\n","Iteration 6326, loss = 0.04959440\n","Iteration 6327, loss = 0.04959021\n","Iteration 6328, loss = 0.04958603\n","Iteration 6329, loss = 0.04958187\n","Iteration 6330, loss = 0.04957768\n","Iteration 6331, loss = 0.04957351\n","Iteration 6332, loss = 0.04956934\n","Iteration 6333, loss = 0.04956517\n","Iteration 6334, loss = 0.04956101\n","Iteration 6335, loss = 0.04955684\n","Iteration 6336, loss = 0.04955268\n","Iteration 6337, loss = 0.04954851\n","Iteration 6338, loss = 0.04954435\n","Iteration 6339, loss = 0.04954019\n","Iteration 6340, loss = 0.04953603\n","Iteration 6341, loss = 0.04953187\n","Iteration 6342, loss = 0.04952771\n","Iteration 6343, loss = 0.04952356\n","Iteration 6344, loss = 0.04951941\n","Iteration 6345, loss = 0.04951526\n","Iteration 6346, loss = 0.04951111\n","Iteration 6347, loss = 0.04950697\n","Iteration 6348, loss = 0.04950283\n","Iteration 6349, loss = 0.04949869\n","Iteration 6350, loss = 0.04949455\n","Iteration 6351, loss = 0.04949042\n","Iteration 6352, loss = 0.04948629\n","Iteration 6353, loss = 0.04948216\n","Iteration 6354, loss = 0.04947803\n","Iteration 6355, loss = 0.04947390\n","Iteration 6356, loss = 0.04946978\n","Iteration 6357, loss = 0.04946565\n","Iteration 6358, loss = 0.04946153\n","Iteration 6359, loss = 0.04945741\n","Iteration 6360, loss = 0.04945329\n","Iteration 6361, loss = 0.04944917\n","Iteration 6362, loss = 0.04944508\n","Iteration 6363, loss = 0.04944095\n","Iteration 6364, loss = 0.04943684\n","Iteration 6365, loss = 0.04943273\n","Iteration 6366, loss = 0.04942863\n","Iteration 6367, loss = 0.04942453\n","Iteration 6368, loss = 0.04942042\n","Iteration 6369, loss = 0.04941632\n","Iteration 6370, loss = 0.04941222\n","Iteration 6371, loss = 0.04940813\n","Iteration 6372, loss = 0.04940403\n","Iteration 6373, loss = 0.04939994\n","Iteration 6374, loss = 0.04939585\n","Iteration 6375, loss = 0.04939176\n","Iteration 6376, loss = 0.04938769\n","Iteration 6377, loss = 0.04938359\n","Iteration 6378, loss = 0.04937951\n","Iteration 6379, loss = 0.04937543\n","Iteration 6380, loss = 0.04937135\n","Iteration 6381, loss = 0.04936727\n","Iteration 6382, loss = 0.04936320\n","Iteration 6383, loss = 0.04935912\n","Iteration 6384, loss = 0.04935505\n","Iteration 6385, loss = 0.04935098\n","Iteration 6386, loss = 0.04934691\n","Iteration 6387, loss = 0.04934285\n","Iteration 6388, loss = 0.04933878\n","Iteration 6389, loss = 0.04933472\n","Iteration 6390, loss = 0.04933066\n","Iteration 6391, loss = 0.04932660\n","Iteration 6392, loss = 0.04932254\n","Iteration 6393, loss = 0.04931849\n","Iteration 6394, loss = 0.04931444\n","Iteration 6395, loss = 0.04931038\n","Iteration 6396, loss = 0.04930633\n","Iteration 6397, loss = 0.04930229\n","Iteration 6398, loss = 0.04929824\n","Iteration 6399, loss = 0.04929420\n","Iteration 6400, loss = 0.04929015\n","Iteration 6401, loss = 0.04928611\n","Iteration 6402, loss = 0.04928207\n","Iteration 6403, loss = 0.04927804\n","Iteration 6404, loss = 0.04927400\n","Iteration 6405, loss = 0.04926997\n","Iteration 6406, loss = 0.04926594\n","Iteration 6407, loss = 0.04926191\n","Iteration 6408, loss = 0.04925788\n","Iteration 6409, loss = 0.04925385\n","Iteration 6410, loss = 0.04924983\n","Iteration 6411, loss = 0.04924580\n","Iteration 6412, loss = 0.04924178\n","Iteration 6413, loss = 0.04923776\n","Iteration 6414, loss = 0.04923374\n","Iteration 6415, loss = 0.04922973\n","Iteration 6416, loss = 0.04922571\n","Iteration 6417, loss = 0.04922170\n","Iteration 6418, loss = 0.04921769\n","Iteration 6419, loss = 0.04921368\n","Iteration 6420, loss = 0.04920968\n","Iteration 6421, loss = 0.04920567\n","Iteration 6422, loss = 0.04920166\n","Iteration 6423, loss = 0.04919766\n","Iteration 6424, loss = 0.04919366\n","Iteration 6425, loss = 0.04918966\n","Iteration 6426, loss = 0.04918566\n","Iteration 6427, loss = 0.04918166\n","Iteration 6428, loss = 0.04917767\n","Iteration 6429, loss = 0.04917368\n","Iteration 6430, loss = 0.04916969\n","Iteration 6431, loss = 0.04916570\n","Iteration 6432, loss = 0.04916171\n","Iteration 6433, loss = 0.04915772\n","Iteration 6434, loss = 0.04915373\n","Iteration 6435, loss = 0.04914975\n","Iteration 6436, loss = 0.04914577\n","Iteration 6437, loss = 0.04914178\n","Iteration 6438, loss = 0.04913780\n","Iteration 6439, loss = 0.04913382\n","Iteration 6440, loss = 0.04912985\n","Iteration 6441, loss = 0.04912587\n","Iteration 6442, loss = 0.04912190\n","Iteration 6443, loss = 0.04911792\n","Iteration 6444, loss = 0.04911395\n","Iteration 6445, loss = 0.04910998\n","Iteration 6446, loss = 0.04910601\n","Iteration 6447, loss = 0.04910204\n","Iteration 6448, loss = 0.04909807\n","Iteration 6449, loss = 0.04909411\n","Iteration 6450, loss = 0.04909014\n","Iteration 6451, loss = 0.04908618\n","Iteration 6452, loss = 0.04908222\n","Iteration 6453, loss = 0.04907826\n","Iteration 6454, loss = 0.04907430\n","Iteration 6455, loss = 0.04907034\n","Iteration 6456, loss = 0.04906638\n","Iteration 6457, loss = 0.04906242\n","Iteration 6458, loss = 0.04905847\n","Iteration 6459, loss = 0.04905452\n","Iteration 6460, loss = 0.04905056\n","Iteration 6461, loss = 0.04904661\n","Iteration 6462, loss = 0.04904266\n","Iteration 6463, loss = 0.04903871\n","Iteration 6464, loss = 0.04903477\n","Iteration 6465, loss = 0.04903082\n","Iteration 6466, loss = 0.04902687\n","Iteration 6467, loss = 0.04902293\n","Iteration 6468, loss = 0.04901898\n","Iteration 6469, loss = 0.04901504\n","Iteration 6470, loss = 0.04901110\n","Iteration 6471, loss = 0.04900716\n","Iteration 6472, loss = 0.04900322\n","Iteration 6473, loss = 0.04899928\n","Iteration 6474, loss = 0.04899535\n","Iteration 6475, loss = 0.04899141\n","Iteration 6476, loss = 0.04898747\n","Iteration 6477, loss = 0.04898354\n","Iteration 6478, loss = 0.04897961\n","Iteration 6479, loss = 0.04897567\n","Iteration 6480, loss = 0.04897174\n","Iteration 6481, loss = 0.04896781\n","Iteration 6482, loss = 0.04896388\n","Iteration 6483, loss = 0.04895995\n","Iteration 6484, loss = 0.04895603\n","Iteration 6485, loss = 0.04895210\n","Iteration 6486, loss = 0.04894818\n","Iteration 6487, loss = 0.04894425\n","Iteration 6488, loss = 0.04894033\n","Iteration 6489, loss = 0.04893641\n","Iteration 6490, loss = 0.04893248\n","Iteration 6491, loss = 0.04892856\n","Iteration 6492, loss = 0.04892464\n","Iteration 6493, loss = 0.04892072\n","Iteration 6494, loss = 0.04891680\n","Iteration 6495, loss = 0.04891289\n","Iteration 6496, loss = 0.04890897\n","Iteration 6497, loss = 0.04890505\n","Iteration 6498, loss = 0.04890114\n","Iteration 6499, loss = 0.04889722\n","Iteration 6500, loss = 0.04889331\n","Iteration 6501, loss = 0.04888940\n","Iteration 6502, loss = 0.04888549\n","Iteration 6503, loss = 0.04888157\n","Iteration 6504, loss = 0.04887766\n","Iteration 6505, loss = 0.04887376\n","Iteration 6506, loss = 0.04886985\n","Iteration 6507, loss = 0.04886594\n","Iteration 6508, loss = 0.04886203\n","Iteration 6509, loss = 0.04885813\n","Iteration 6510, loss = 0.04885422\n","Iteration 6511, loss = 0.04885032\n","Iteration 6512, loss = 0.04884641\n","Iteration 6513, loss = 0.04884251\n","Iteration 6514, loss = 0.04883861\n","Iteration 6515, loss = 0.04883471\n","Iteration 6516, loss = 0.04883080\n","Iteration 6517, loss = 0.04882690\n","Iteration 6518, loss = 0.04882300\n","Iteration 6519, loss = 0.04881911\n","Iteration 6520, loss = 0.04881521\n","Iteration 6521, loss = 0.04881131\n","Iteration 6522, loss = 0.04880741\n","Iteration 6523, loss = 0.04880352\n","Iteration 6524, loss = 0.04879962\n","Iteration 6525, loss = 0.04879573\n","Iteration 6526, loss = 0.04879184\n","Iteration 6527, loss = 0.04878795\n","Iteration 6528, loss = 0.04878415\n","Iteration 6529, loss = 0.04878028\n","Iteration 6530, loss = 0.04877637\n","Iteration 6531, loss = 0.04877253\n","Iteration 6532, loss = 0.04876868\n","Iteration 6533, loss = 0.04876483\n","Iteration 6534, loss = 0.04876098\n","Iteration 6535, loss = 0.04875713\n","Iteration 6536, loss = 0.04875327\n","Iteration 6537, loss = 0.04874941\n","Iteration 6538, loss = 0.04874562\n","Iteration 6539, loss = 0.04874176\n","Iteration 6540, loss = 0.04873789\n","Iteration 6541, loss = 0.04873406\n","Iteration 6542, loss = 0.04873023\n","Iteration 6543, loss = 0.04872639\n","Iteration 6544, loss = 0.04872255\n","Iteration 6545, loss = 0.04871871\n","Iteration 6546, loss = 0.04871487\n","Iteration 6547, loss = 0.04871106\n","Iteration 6548, loss = 0.04870722\n","Iteration 6549, loss = 0.04870339\n","Iteration 6550, loss = 0.04869958\n","Iteration 6551, loss = 0.04869576\n","Iteration 6552, loss = 0.04869194\n","Iteration 6553, loss = 0.04868811\n","Iteration 6554, loss = 0.04868428\n","Iteration 6555, loss = 0.04868045\n","Iteration 6556, loss = 0.04867666\n","Iteration 6557, loss = 0.04867284\n","Iteration 6558, loss = 0.04866900\n","Iteration 6559, loss = 0.04866520\n","Iteration 6560, loss = 0.04866140\n","Iteration 6561, loss = 0.04865759\n","Iteration 6562, loss = 0.04865377\n","Iteration 6563, loss = 0.04864996\n","Iteration 6564, loss = 0.04864615\n","Iteration 6565, loss = 0.04864235\n","Iteration 6566, loss = 0.04863856\n","Iteration 6567, loss = 0.04863476\n","Iteration 6568, loss = 0.04863096\n","Iteration 6569, loss = 0.04862716\n","Iteration 6570, loss = 0.04862337\n","Iteration 6571, loss = 0.04861958\n","Iteration 6572, loss = 0.04861579\n","Iteration 6573, loss = 0.04861199\n","Iteration 6574, loss = 0.04860822\n","Iteration 6575, loss = 0.04860441\n","Iteration 6576, loss = 0.04860063\n","Iteration 6577, loss = 0.04859687\n","Iteration 6578, loss = 0.04859309\n","Iteration 6579, loss = 0.04858932\n","Iteration 6580, loss = 0.04858553\n","Iteration 6581, loss = 0.04858174\n","Iteration 6582, loss = 0.04857799\n","Iteration 6583, loss = 0.04857421\n","Iteration 6584, loss = 0.04857042\n","Iteration 6585, loss = 0.04856666\n","Iteration 6586, loss = 0.04856289\n","Iteration 6587, loss = 0.04855911\n","Iteration 6588, loss = 0.04855535\n","Iteration 6589, loss = 0.04855157\n","Iteration 6590, loss = 0.04854784\n","Iteration 6591, loss = 0.04854409\n","Iteration 6592, loss = 0.04854033\n","Iteration 6593, loss = 0.04853657\n","Iteration 6594, loss = 0.04853279\n","Iteration 6595, loss = 0.04852903\n","Iteration 6596, loss = 0.04852527\n","Iteration 6597, loss = 0.04852153\n","Iteration 6598, loss = 0.04851779\n","Iteration 6599, loss = 0.04851404\n","Iteration 6600, loss = 0.04851028\n","Iteration 6601, loss = 0.04850655\n","Iteration 6602, loss = 0.04850280\n","Iteration 6603, loss = 0.04849905\n","Iteration 6604, loss = 0.04849532\n","Iteration 6605, loss = 0.04849157\n","Iteration 6606, loss = 0.04848782\n","Iteration 6607, loss = 0.04848411\n","Iteration 6608, loss = 0.04848038\n","Iteration 6609, loss = 0.04847662\n","Iteration 6610, loss = 0.04847290\n","Iteration 6611, loss = 0.04846916\n","Iteration 6612, loss = 0.04846543\n","Iteration 6613, loss = 0.04846170\n","Iteration 6614, loss = 0.04845797\n","Iteration 6615, loss = 0.04845426\n","Iteration 6616, loss = 0.04845054\n","Iteration 6617, loss = 0.04844681\n","Iteration 6618, loss = 0.04844310\n","Iteration 6619, loss = 0.04843937\n","Iteration 6620, loss = 0.04843566\n","Iteration 6621, loss = 0.04843196\n","Iteration 6622, loss = 0.04842824\n","Iteration 6623, loss = 0.04842451\n","Iteration 6624, loss = 0.04842083\n","Iteration 6625, loss = 0.04841713\n","Iteration 6626, loss = 0.04841339\n","Iteration 6627, loss = 0.04840970\n","Iteration 6628, loss = 0.04840602\n","Iteration 6629, loss = 0.04840232\n","Iteration 6630, loss = 0.04839861\n","Iteration 6631, loss = 0.04839489\n","Iteration 6632, loss = 0.04839117\n","Iteration 6633, loss = 0.04838749\n","Iteration 6634, loss = 0.04838377\n","Iteration 6635, loss = 0.04838011\n","Iteration 6636, loss = 0.04837644\n","Iteration 6637, loss = 0.04837275\n","Iteration 6638, loss = 0.04836904\n","Iteration 6639, loss = 0.04836532\n","Iteration 6640, loss = 0.04836167\n","Iteration 6641, loss = 0.04835801\n","Iteration 6642, loss = 0.04835431\n","Iteration 6643, loss = 0.04835058\n","Iteration 6644, loss = 0.04834694\n","Iteration 6645, loss = 0.04834329\n","Iteration 6646, loss = 0.04833962\n","Iteration 6647, loss = 0.04833594\n","Iteration 6648, loss = 0.04833224\n","Iteration 6649, loss = 0.04832853\n","Iteration 6650, loss = 0.04832489\n","Iteration 6651, loss = 0.04832125\n","Iteration 6652, loss = 0.04831758\n","Iteration 6653, loss = 0.04831388\n","Iteration 6654, loss = 0.04831017\n","Iteration 6655, loss = 0.04830653\n","Iteration 6656, loss = 0.04830287\n","Iteration 6657, loss = 0.04829920\n","Iteration 6658, loss = 0.04829553\n","Iteration 6659, loss = 0.04829187\n","Iteration 6660, loss = 0.04828819\n","Iteration 6661, loss = 0.04828454\n","Iteration 6662, loss = 0.04828090\n","Iteration 6663, loss = 0.04827725\n","Iteration 6664, loss = 0.04827358\n","Iteration 6665, loss = 0.04826993\n","Iteration 6666, loss = 0.04826629\n","Iteration 6667, loss = 0.04826263\n","Iteration 6668, loss = 0.04825902\n","Iteration 6669, loss = 0.04825538\n","Iteration 6670, loss = 0.04825173\n","Iteration 6671, loss = 0.04824806\n","Iteration 6672, loss = 0.04824442\n","Iteration 6673, loss = 0.04824078\n","Iteration 6674, loss = 0.04823714\n","Iteration 6675, loss = 0.04823352\n","Iteration 6676, loss = 0.04822989\n","Iteration 6677, loss = 0.04822624\n","Iteration 6678, loss = 0.04822260\n","Iteration 6679, loss = 0.04821899\n","Iteration 6680, loss = 0.04821535\n","Iteration 6681, loss = 0.04821172\n","Iteration 6682, loss = 0.04820810\n","Iteration 6683, loss = 0.04820447\n","Iteration 6684, loss = 0.04820084\n","Iteration 6685, loss = 0.04819724\n","Iteration 6686, loss = 0.04819362\n","Iteration 6687, loss = 0.04818998\n","Iteration 6688, loss = 0.04818639\n","Iteration 6689, loss = 0.04818279\n","Iteration 6690, loss = 0.04817917\n","Iteration 6691, loss = 0.04817552\n","Iteration 6692, loss = 0.04817194\n","Iteration 6693, loss = 0.04816835\n","Iteration 6694, loss = 0.04816474\n","Iteration 6695, loss = 0.04816110\n","Iteration 6696, loss = 0.04815748\n","Iteration 6697, loss = 0.04815390\n","Iteration 6698, loss = 0.04815029\n","Iteration 6699, loss = 0.04814666\n","Iteration 6700, loss = 0.04814308\n","Iteration 6701, loss = 0.04813949\n","Iteration 6702, loss = 0.04813588\n","Iteration 6703, loss = 0.04813225\n","Iteration 6704, loss = 0.04812871\n","Iteration 6705, loss = 0.04812514\n","Iteration 6706, loss = 0.04812155\n","Iteration 6707, loss = 0.04811794\n","Iteration 6708, loss = 0.04811431\n","Iteration 6709, loss = 0.04811072\n","Iteration 6710, loss = 0.04810716\n","Iteration 6711, loss = 0.04810357\n","Iteration 6712, loss = 0.04809995\n","Iteration 6713, loss = 0.04809638\n","Iteration 6714, loss = 0.04809282\n","Iteration 6715, loss = 0.04808924\n","Iteration 6716, loss = 0.04808564\n","Iteration 6717, loss = 0.04808203\n","Iteration 6718, loss = 0.04807850\n","Iteration 6719, loss = 0.04807496\n","Iteration 6720, loss = 0.04807137\n","Iteration 6721, loss = 0.04806776\n","Iteration 6722, loss = 0.04806417\n","Iteration 6723, loss = 0.04806063\n","Iteration 6724, loss = 0.04805706\n","Iteration 6725, loss = 0.04805348\n","Iteration 6726, loss = 0.04804989\n","Iteration 6727, loss = 0.04804636\n","Iteration 6728, loss = 0.04804281\n","Iteration 6729, loss = 0.04803924\n","Iteration 6730, loss = 0.04803563\n","Iteration 6731, loss = 0.04803211\n","Iteration 6732, loss = 0.04802859\n","Iteration 6733, loss = 0.04802504\n","Iteration 6734, loss = 0.04802148\n","Iteration 6735, loss = 0.04801790\n","Iteration 6736, loss = 0.04801431\n","Iteration 6737, loss = 0.04801076\n","Iteration 6738, loss = 0.04800724\n","Iteration 6739, loss = 0.04800369\n","Iteration 6740, loss = 0.04800009\n","Iteration 6741, loss = 0.04799658\n","Iteration 6742, loss = 0.04799307\n","Iteration 6743, loss = 0.04798953\n","Iteration 6744, loss = 0.04798599\n","Iteration 6745, loss = 0.04798242\n","Iteration 6746, loss = 0.04797885\n","Iteration 6747, loss = 0.04797531\n","Iteration 6748, loss = 0.04797180\n","Iteration 6749, loss = 0.04796825\n","Iteration 6750, loss = 0.04796468\n","Iteration 6751, loss = 0.04796116\n","Iteration 6752, loss = 0.04795763\n","Iteration 6753, loss = 0.04795408\n","Iteration 6754, loss = 0.04795058\n","Iteration 6755, loss = 0.04794705\n","Iteration 6756, loss = 0.04794349\n","Iteration 6757, loss = 0.04793997\n","Iteration 6758, loss = 0.04793644\n","Iteration 6759, loss = 0.04793295\n","Iteration 6760, loss = 0.04792941\n","Iteration 6761, loss = 0.04792589\n","Iteration 6762, loss = 0.04792239\n","Iteration 6763, loss = 0.04791887\n","Iteration 6764, loss = 0.04791534\n","Iteration 6765, loss = 0.04791182\n","Iteration 6766, loss = 0.04790830\n","Iteration 6767, loss = 0.04790479\n","Iteration 6768, loss = 0.04790129\n","Iteration 6769, loss = 0.04789778\n","Iteration 6770, loss = 0.04789425\n","Iteration 6771, loss = 0.04789076\n","Iteration 6772, loss = 0.04788726\n","Iteration 6773, loss = 0.04788373\n","Iteration 6774, loss = 0.04788024\n","Iteration 6775, loss = 0.04787673\n","Iteration 6776, loss = 0.04787322\n","Iteration 6777, loss = 0.04786975\n","Iteration 6778, loss = 0.04786625\n","Iteration 6779, loss = 0.04786273\n","Iteration 6780, loss = 0.04785924\n","Iteration 6781, loss = 0.04785574\n","Iteration 6782, loss = 0.04785224\n","Iteration 6783, loss = 0.04784876\n","Iteration 6784, loss = 0.04784526\n","Iteration 6785, loss = 0.04784178\n","Iteration 6786, loss = 0.04783830\n","Iteration 6787, loss = 0.04783482\n","Iteration 6788, loss = 0.04783132\n","Iteration 6789, loss = 0.04782782\n","Iteration 6790, loss = 0.04782434\n","Iteration 6791, loss = 0.04782086\n","Iteration 6792, loss = 0.04781737\n","Iteration 6793, loss = 0.04781390\n","Iteration 6794, loss = 0.04781042\n","Iteration 6795, loss = 0.04780694\n","Iteration 6796, loss = 0.04780344\n","Iteration 6797, loss = 0.04780001\n","Iteration 6798, loss = 0.04779654\n","Iteration 6799, loss = 0.04779302\n","Iteration 6800, loss = 0.04778956\n","Iteration 6801, loss = 0.04778609\n","Iteration 6802, loss = 0.04778262\n","Iteration 6803, loss = 0.04777914\n","Iteration 6804, loss = 0.04777568\n","Iteration 6805, loss = 0.04777221\n","Iteration 6806, loss = 0.04776874\n","Iteration 6807, loss = 0.04776531\n","Iteration 6808, loss = 0.04776183\n","Iteration 6809, loss = 0.04775838\n","Iteration 6810, loss = 0.04775493\n","Iteration 6811, loss = 0.04775148\n","Iteration 6812, loss = 0.04774803\n","Iteration 6813, loss = 0.04774456\n","Iteration 6814, loss = 0.04774110\n","Iteration 6815, loss = 0.04773763\n","Iteration 6816, loss = 0.04773419\n","Iteration 6817, loss = 0.04773074\n","Iteration 6818, loss = 0.04772727\n","Iteration 6819, loss = 0.04772383\n","Iteration 6820, loss = 0.04772039\n","Iteration 6821, loss = 0.04771694\n","Iteration 6822, loss = 0.04771348\n","Iteration 6823, loss = 0.04771003\n","Iteration 6824, loss = 0.04770659\n","Iteration 6825, loss = 0.04770315\n","Iteration 6826, loss = 0.04769970\n","Iteration 6827, loss = 0.04769629\n","Iteration 6828, loss = 0.04769283\n","Iteration 6829, loss = 0.04768939\n","Iteration 6830, loss = 0.04768595\n","Iteration 6831, loss = 0.04768253\n","Iteration 6832, loss = 0.04767909\n","Iteration 6833, loss = 0.04767566\n","Iteration 6834, loss = 0.04767223\n","Iteration 6835, loss = 0.04766880\n","Iteration 6836, loss = 0.04766536\n","Iteration 6837, loss = 0.04766194\n","Iteration 6838, loss = 0.04765852\n","Iteration 6839, loss = 0.04765509\n","Iteration 6840, loss = 0.04765166\n","Iteration 6841, loss = 0.04764824\n","Iteration 6842, loss = 0.04764482\n","Iteration 6843, loss = 0.04764140\n","Iteration 6844, loss = 0.04763798\n","Iteration 6845, loss = 0.04763456\n","Iteration 6846, loss = 0.04763114\n","Iteration 6847, loss = 0.04762773\n","Iteration 6848, loss = 0.04762432\n","Iteration 6849, loss = 0.04762091\n","Iteration 6850, loss = 0.04761749\n","Iteration 6851, loss = 0.04761407\n","Iteration 6852, loss = 0.04761068\n","Iteration 6853, loss = 0.04760725\n","Iteration 6854, loss = 0.04760385\n","Iteration 6855, loss = 0.04760044\n","Iteration 6856, loss = 0.04759703\n","Iteration 6857, loss = 0.04759363\n","Iteration 6858, loss = 0.04759023\n","Iteration 6859, loss = 0.04758683\n","Iteration 6860, loss = 0.04758343\n","Iteration 6861, loss = 0.04758003\n","Iteration 6862, loss = 0.04757663\n","Iteration 6863, loss = 0.04757323\n","Iteration 6864, loss = 0.04756984\n","Iteration 6865, loss = 0.04756644\n","Iteration 6866, loss = 0.04756305\n","Iteration 6867, loss = 0.04755965\n","Iteration 6868, loss = 0.04755626\n","Iteration 6869, loss = 0.04755286\n","Iteration 6870, loss = 0.04754947\n","Iteration 6871, loss = 0.04754609\n","Iteration 6872, loss = 0.04754271\n","Iteration 6873, loss = 0.04753932\n","Iteration 6874, loss = 0.04753594\n","Iteration 6875, loss = 0.04753255\n","Iteration 6876, loss = 0.04752917\n","Iteration 6877, loss = 0.04752578\n","Iteration 6878, loss = 0.04752239\n","Iteration 6879, loss = 0.04751906\n","Iteration 6880, loss = 0.04751564\n","Iteration 6881, loss = 0.04751227\n","Iteration 6882, loss = 0.04750891\n","Iteration 6883, loss = 0.04750554\n","Iteration 6884, loss = 0.04750218\n","Iteration 6885, loss = 0.04749881\n","Iteration 6886, loss = 0.04749544\n","Iteration 6887, loss = 0.04749207\n","Iteration 6888, loss = 0.04748870\n","Iteration 6889, loss = 0.04748532\n","Iteration 6890, loss = 0.04748195\n","Iteration 6891, loss = 0.04747858\n","Iteration 6892, loss = 0.04747521\n","Iteration 6893, loss = 0.04747184\n","Iteration 6894, loss = 0.04746848\n","Iteration 6895, loss = 0.04746511\n","Iteration 6896, loss = 0.04746174\n","Iteration 6897, loss = 0.04745837\n","Iteration 6898, loss = 0.04745501\n","Iteration 6899, loss = 0.04745170\n","Iteration 6900, loss = 0.04744831\n","Iteration 6901, loss = 0.04744495\n","Iteration 6902, loss = 0.04744160\n","Iteration 6903, loss = 0.04743825\n","Iteration 6904, loss = 0.04743491\n","Iteration 6905, loss = 0.04743156\n","Iteration 6906, loss = 0.04742821\n","Iteration 6907, loss = 0.04742486\n","Iteration 6908, loss = 0.04742151\n","Iteration 6909, loss = 0.04741817\n","Iteration 6910, loss = 0.04741482\n","Iteration 6911, loss = 0.04741147\n","Iteration 6912, loss = 0.04740813\n","Iteration 6913, loss = 0.04740478\n","Iteration 6914, loss = 0.04740144\n","Iteration 6915, loss = 0.04739810\n","Iteration 6916, loss = 0.04739475\n","Iteration 6917, loss = 0.04739141\n","Iteration 6918, loss = 0.04738807\n","Iteration 6919, loss = 0.04738473\n","Iteration 6920, loss = 0.04738140\n","Iteration 6921, loss = 0.04737806\n","Iteration 6922, loss = 0.04737473\n","Iteration 6923, loss = 0.04737139\n","Iteration 6924, loss = 0.04736806\n","Iteration 6925, loss = 0.04736473\n","Iteration 6926, loss = 0.04736140\n","Iteration 6927, loss = 0.04735807\n","Iteration 6928, loss = 0.04735477\n","Iteration 6929, loss = 0.04735142\n","Iteration 6930, loss = 0.04734809\n","Iteration 6931, loss = 0.04734477\n","Iteration 6932, loss = 0.04734145\n","Iteration 6933, loss = 0.04733813\n","Iteration 6934, loss = 0.04733481\n","Iteration 6935, loss = 0.04733149\n","Iteration 6936, loss = 0.04732817\n","Iteration 6937, loss = 0.04732486\n","Iteration 6938, loss = 0.04732154\n","Iteration 6939, loss = 0.04731822\n","Iteration 6940, loss = 0.04731491\n","Iteration 6941, loss = 0.04731159\n","Iteration 6942, loss = 0.04730828\n","Iteration 6943, loss = 0.04730497\n","Iteration 6944, loss = 0.04730166\n","Iteration 6945, loss = 0.04729835\n","Iteration 6946, loss = 0.04729504\n","Iteration 6947, loss = 0.04729174\n","Iteration 6948, loss = 0.04728843\n","Iteration 6949, loss = 0.04728512\n","Iteration 6950, loss = 0.04728182\n","Iteration 6951, loss = 0.04727852\n","Iteration 6952, loss = 0.04727521\n","Iteration 6953, loss = 0.04727191\n","Iteration 6954, loss = 0.04726861\n","Iteration 6955, loss = 0.04726531\n","Iteration 6956, loss = 0.04726201\n","Iteration 6957, loss = 0.04725872\n","Iteration 6958, loss = 0.04725542\n","Iteration 6959, loss = 0.04725212\n","Iteration 6960, loss = 0.04724883\n","Iteration 6961, loss = 0.04724553\n","Iteration 6962, loss = 0.04724224\n","Iteration 6963, loss = 0.04723895\n","Iteration 6964, loss = 0.04723566\n","Iteration 6965, loss = 0.04723237\n","Iteration 6966, loss = 0.04722908\n","Iteration 6967, loss = 0.04722579\n","Iteration 6968, loss = 0.04722250\n","Iteration 6969, loss = 0.04721921\n","Iteration 6970, loss = 0.04721593\n","Iteration 6971, loss = 0.04721264\n","Iteration 6972, loss = 0.04720935\n","Iteration 6973, loss = 0.04720607\n","Iteration 6974, loss = 0.04720279\n","Iteration 6975, loss = 0.04719950\n","Iteration 6976, loss = 0.04719622\n","Iteration 6977, loss = 0.04719294\n","Iteration 6978, loss = 0.04718966\n","Iteration 6979, loss = 0.04718638\n","Iteration 6980, loss = 0.04718310\n","Iteration 6981, loss = 0.04717982\n","Iteration 6982, loss = 0.04717654\n","Iteration 6983, loss = 0.04717326\n","Iteration 6984, loss = 0.04716999\n","Iteration 6985, loss = 0.04716671\n","Iteration 6986, loss = 0.04716343\n","Iteration 6987, loss = 0.04716016\n","Iteration 6988, loss = 0.04715688\n","Iteration 6989, loss = 0.04715361\n","Iteration 6990, loss = 0.04715033\n","Iteration 6991, loss = 0.04714706\n","Iteration 6992, loss = 0.04714379\n","Iteration 6993, loss = 0.04714051\n","Iteration 6994, loss = 0.04713724\n","Iteration 6995, loss = 0.04713397\n","Iteration 6996, loss = 0.04713070\n","Iteration 6997, loss = 0.04712743\n","Iteration 6998, loss = 0.04712416\n","Iteration 6999, loss = 0.04712089\n","Iteration 7000, loss = 0.04711762\n","Iteration 7001, loss = 0.04711435\n","Iteration 7002, loss = 0.04711108\n","Iteration 7003, loss = 0.04710782\n","Iteration 7004, loss = 0.04710455\n","Iteration 7005, loss = 0.04710128\n","Iteration 7006, loss = 0.04709801\n","Iteration 7007, loss = 0.04709475\n","Iteration 7008, loss = 0.04709148\n","Iteration 7009, loss = 0.04708822\n","Iteration 7010, loss = 0.04708495\n","Iteration 7011, loss = 0.04708169\n","Iteration 7012, loss = 0.04707842\n","Iteration 7013, loss = 0.04707516\n","Iteration 7014, loss = 0.04707189\n","Iteration 7015, loss = 0.04706863\n","Iteration 7016, loss = 0.04706537\n","Iteration 7017, loss = 0.04706210\n","Iteration 7018, loss = 0.04705884\n","Iteration 7019, loss = 0.04705558\n","Iteration 7020, loss = 0.04705232\n","Iteration 7021, loss = 0.04704905\n","Iteration 7022, loss = 0.04704579\n","Iteration 7023, loss = 0.04704253\n","Iteration 7024, loss = 0.04703927\n","Iteration 7025, loss = 0.04703601\n","Iteration 7026, loss = 0.04703275\n","Iteration 7027, loss = 0.04702949\n","Iteration 7028, loss = 0.04702623\n","Iteration 7029, loss = 0.04702297\n","Iteration 7030, loss = 0.04701971\n","Iteration 7031, loss = 0.04701645\n","Iteration 7032, loss = 0.04701319\n","Iteration 7033, loss = 0.04700993\n","Iteration 7034, loss = 0.04700672\n","Iteration 7035, loss = 0.04700345\n","Iteration 7036, loss = 0.04700023\n","Iteration 7037, loss = 0.04699700\n","Iteration 7038, loss = 0.04699377\n","Iteration 7039, loss = 0.04699054\n","Iteration 7040, loss = 0.04698730\n","Iteration 7041, loss = 0.04698407\n","Iteration 7042, loss = 0.04698083\n","Iteration 7043, loss = 0.04697759\n","Iteration 7044, loss = 0.04697435\n","Iteration 7045, loss = 0.04697111\n","Iteration 7046, loss = 0.04696787\n","Iteration 7047, loss = 0.04696463\n","Iteration 7048, loss = 0.04696139\n","Iteration 7049, loss = 0.04695825\n","Iteration 7050, loss = 0.04695494\n","Iteration 7051, loss = 0.04695174\n","Iteration 7052, loss = 0.04694853\n","Iteration 7053, loss = 0.04694531\n","Iteration 7054, loss = 0.04694210\n","Iteration 7055, loss = 0.04693888\n","Iteration 7056, loss = 0.04693566\n","Iteration 7057, loss = 0.04693243\n","Iteration 7058, loss = 0.04692921\n","Iteration 7059, loss = 0.04692598\n","Iteration 7060, loss = 0.04692275\n","Iteration 7061, loss = 0.04691952\n","Iteration 7062, loss = 0.04691628\n","Iteration 7063, loss = 0.04691305\n","Iteration 7064, loss = 0.04691002\n","Iteration 7065, loss = 0.04690663\n","Iteration 7066, loss = 0.04690343\n","Iteration 7067, loss = 0.04690024\n","Iteration 7068, loss = 0.04689704\n","Iteration 7069, loss = 0.04689383\n","Iteration 7070, loss = 0.04689062\n","Iteration 7071, loss = 0.04688741\n","Iteration 7072, loss = 0.04688419\n","Iteration 7073, loss = 0.04688097\n","Iteration 7074, loss = 0.04687775\n","Iteration 7075, loss = 0.04687453\n","Iteration 7076, loss = 0.04687155\n","Iteration 7077, loss = 0.04686813\n","Iteration 7078, loss = 0.04686495\n","Iteration 7079, loss = 0.04686177\n","Iteration 7080, loss = 0.04685858\n","Iteration 7081, loss = 0.04685538\n","Iteration 7082, loss = 0.04685218\n","Iteration 7083, loss = 0.04684897\n","Iteration 7084, loss = 0.04684577\n","Iteration 7085, loss = 0.04684255\n","Iteration 7086, loss = 0.04683934\n","Iteration 7087, loss = 0.04683637\n","Iteration 7088, loss = 0.04683296\n","Iteration 7089, loss = 0.04682979\n","Iteration 7090, loss = 0.04682662\n","Iteration 7091, loss = 0.04682344\n","Iteration 7092, loss = 0.04682025\n","Iteration 7093, loss = 0.04681705\n","Iteration 7094, loss = 0.04681386\n","Iteration 7095, loss = 0.04681065\n","Iteration 7096, loss = 0.04680744\n","Iteration 7097, loss = 0.04680447\n","Iteration 7098, loss = 0.04680108\n","Iteration 7099, loss = 0.04679793\n","Iteration 7100, loss = 0.04679476\n","Iteration 7101, loss = 0.04679159\n","Iteration 7102, loss = 0.04678841\n","Iteration 7103, loss = 0.04678522\n","Iteration 7104, loss = 0.04678203\n","Iteration 7105, loss = 0.04677883\n","Iteration 7106, loss = 0.04677576\n","Iteration 7107, loss = 0.04677249\n","Iteration 7108, loss = 0.04676934\n","Iteration 7109, loss = 0.04676619\n","Iteration 7110, loss = 0.04676302\n","Iteration 7111, loss = 0.04675985\n","Iteration 7112, loss = 0.04675666\n","Iteration 7113, loss = 0.04675348\n","Iteration 7114, loss = 0.04675028\n","Iteration 7115, loss = 0.04674721\n","Iteration 7116, loss = 0.04674395\n","Iteration 7117, loss = 0.04674081\n","Iteration 7118, loss = 0.04673766\n","Iteration 7119, loss = 0.04673450\n","Iteration 7120, loss = 0.04673133\n","Iteration 7121, loss = 0.04672815\n","Iteration 7122, loss = 0.04672497\n","Iteration 7123, loss = 0.04672188\n","Iteration 7124, loss = 0.04671866\n","Iteration 7125, loss = 0.04671553\n","Iteration 7126, loss = 0.04671239\n","Iteration 7127, loss = 0.04670923\n","Iteration 7128, loss = 0.04670607\n","Iteration 7129, loss = 0.04670290\n","Iteration 7130, loss = 0.04669971\n","Iteration 7131, loss = 0.04669662\n","Iteration 7132, loss = 0.04669341\n","Iteration 7133, loss = 0.04669029\n","Iteration 7134, loss = 0.04668715\n","Iteration 7135, loss = 0.04668400\n","Iteration 7136, loss = 0.04668084\n","Iteration 7137, loss = 0.04667767\n","Iteration 7138, loss = 0.04667449\n","Iteration 7139, loss = 0.04667163\n","Iteration 7140, loss = 0.04666829\n","Iteration 7141, loss = 0.04666524\n","Iteration 7142, loss = 0.04666218\n","Iteration 7143, loss = 0.04665910\n","Iteration 7144, loss = 0.04665601\n","Iteration 7145, loss = 0.04665289\n","Iteration 7146, loss = 0.04664976\n","Iteration 7147, loss = 0.04664662\n","Iteration 7148, loss = 0.04664347\n","Iteration 7149, loss = 0.04664030\n","Iteration 7150, loss = 0.04663713\n","Iteration 7151, loss = 0.04663394\n","Iteration 7152, loss = 0.04663075\n","Iteration 7153, loss = 0.04662755\n","Iteration 7154, loss = 0.04662435\n","Iteration 7155, loss = 0.04662128\n","Iteration 7156, loss = 0.04661812\n","Iteration 7157, loss = 0.04661497\n","Iteration 7158, loss = 0.04661190\n","Iteration 7159, loss = 0.04660882\n","Iteration 7160, loss = 0.04660572\n","Iteration 7161, loss = 0.04660260\n","Iteration 7162, loss = 0.04659947\n","Iteration 7163, loss = 0.04659632\n","Iteration 7164, loss = 0.04659316\n","Iteration 7165, loss = 0.04658999\n","Iteration 7166, loss = 0.04658681\n","Iteration 7167, loss = 0.04658400\n","Iteration 7168, loss = 0.04658062\n","Iteration 7169, loss = 0.04657760\n","Iteration 7170, loss = 0.04657454\n","Iteration 7171, loss = 0.04657148\n","Iteration 7172, loss = 0.04656838\n","Iteration 7173, loss = 0.04656527\n","Iteration 7174, loss = 0.04656215\n","Iteration 7175, loss = 0.04655901\n","Iteration 7176, loss = 0.04655585\n","Iteration 7177, loss = 0.04655269\n","Iteration 7178, loss = 0.04654951\n","Iteration 7179, loss = 0.04654632\n","Iteration 7180, loss = 0.04654390\n","Iteration 7181, loss = 0.04654013\n","Iteration 7182, loss = 0.04653710\n","Iteration 7183, loss = 0.04653405\n","Iteration 7184, loss = 0.04653098\n","Iteration 7185, loss = 0.04652789\n","Iteration 7186, loss = 0.04652477\n","Iteration 7187, loss = 0.04652165\n","Iteration 7188, loss = 0.04651850\n","Iteration 7189, loss = 0.04651535\n","Iteration 7190, loss = 0.04651218\n","Iteration 7191, loss = 0.04650985\n","Iteration 7192, loss = 0.04650602\n","Iteration 7193, loss = 0.04650301\n","Iteration 7194, loss = 0.04649997\n","Iteration 7195, loss = 0.04649692\n","Iteration 7196, loss = 0.04649384\n","Iteration 7197, loss = 0.04649074\n","Iteration 7198, loss = 0.04648762\n","Iteration 7199, loss = 0.04648448\n","Iteration 7200, loss = 0.04648133\n","Iteration 7201, loss = 0.04647817\n","Iteration 7202, loss = 0.04647582\n","Iteration 7203, loss = 0.04647202\n","Iteration 7204, loss = 0.04646902\n","Iteration 7205, loss = 0.04646599\n","Iteration 7206, loss = 0.04646294\n","Iteration 7207, loss = 0.04645986\n","Iteration 7208, loss = 0.04645676\n","Iteration 7209, loss = 0.04645365\n","Iteration 7210, loss = 0.04645051\n","Iteration 7211, loss = 0.04644736\n","Iteration 7212, loss = 0.04644469\n","Iteration 7213, loss = 0.04644124\n","Iteration 7214, loss = 0.04643826\n","Iteration 7215, loss = 0.04643524\n","Iteration 7216, loss = 0.04643220\n","Iteration 7217, loss = 0.04642913\n","Iteration 7218, loss = 0.04642604\n","Iteration 7219, loss = 0.04642293\n","Iteration 7220, loss = 0.04641980\n","Iteration 7221, loss = 0.04641665\n","Iteration 7222, loss = 0.04641367\n","Iteration 7223, loss = 0.04641054\n","Iteration 7224, loss = 0.04640756\n","Iteration 7225, loss = 0.04640455\n","Iteration 7226, loss = 0.04640152\n","Iteration 7227, loss = 0.04639845\n","Iteration 7228, loss = 0.04639536\n","Iteration 7229, loss = 0.04639225\n","Iteration 7230, loss = 0.04638912\n","Iteration 7231, loss = 0.04638598\n","Iteration 7232, loss = 0.04638328\n","Iteration 7233, loss = 0.04637987\n","Iteration 7234, loss = 0.04637690\n","Iteration 7235, loss = 0.04637389\n","Iteration 7236, loss = 0.04637085\n","Iteration 7237, loss = 0.04636779\n","Iteration 7238, loss = 0.04636470\n","Iteration 7239, loss = 0.04636159\n","Iteration 7240, loss = 0.04635846\n","Iteration 7241, loss = 0.04635575\n","Iteration 7242, loss = 0.04635239\n","Iteration 7243, loss = 0.04634943\n","Iteration 7244, loss = 0.04634643\n","Iteration 7245, loss = 0.04634340\n","Iteration 7246, loss = 0.04634035\n","Iteration 7247, loss = 0.04633727\n","Iteration 7248, loss = 0.04633416\n","Iteration 7249, loss = 0.04633104\n","Iteration 7250, loss = 0.04632817\n","Iteration 7251, loss = 0.04632511\n","Iteration 7252, loss = 0.04632192\n","Iteration 7253, loss = 0.04631893\n","Iteration 7254, loss = 0.04631592\n","Iteration 7255, loss = 0.04631288\n","Iteration 7256, loss = 0.04630981\n","Iteration 7257, loss = 0.04630671\n","Iteration 7258, loss = 0.04630378\n","Iteration 7259, loss = 0.04630066\n","Iteration 7260, loss = 0.04629766\n","Iteration 7261, loss = 0.04629470\n","Iteration 7262, loss = 0.04629171\n","Iteration 7263, loss = 0.04628868\n","Iteration 7264, loss = 0.04628562\n","Iteration 7265, loss = 0.04628254\n","Iteration 7266, loss = 0.04627943\n","Iteration 7267, loss = 0.04627646\n","Iteration 7268, loss = 0.04627340\n","Iteration 7269, loss = 0.04627035\n","Iteration 7270, loss = 0.04626739\n","Iteration 7271, loss = 0.04626438\n","Iteration 7272, loss = 0.04626135\n","Iteration 7273, loss = 0.04625829\n","Iteration 7274, loss = 0.04625519\n","Iteration 7275, loss = 0.04625227\n","Iteration 7276, loss = 0.04624920\n","Iteration 7277, loss = 0.04624616\n","Iteration 7278, loss = 0.04624321\n","Iteration 7279, loss = 0.04624022\n","Iteration 7280, loss = 0.04623720\n","Iteration 7281, loss = 0.04623414\n","Iteration 7282, loss = 0.04623105\n","Iteration 7283, loss = 0.04622804\n","Iteration 7284, loss = 0.04622498\n","Iteration 7285, loss = 0.04622204\n","Iteration 7286, loss = 0.04621909\n","Iteration 7287, loss = 0.04621611\n","Iteration 7288, loss = 0.04621309\n","Iteration 7289, loss = 0.04621003\n","Iteration 7290, loss = 0.04620695\n","Iteration 7291, loss = 0.04620393\n","Iteration 7292, loss = 0.04620089\n","Iteration 7293, loss = 0.04619794\n","Iteration 7294, loss = 0.04619499\n","Iteration 7295, loss = 0.04619201\n","Iteration 7296, loss = 0.04618899\n","Iteration 7297, loss = 0.04618593\n","Iteration 7298, loss = 0.04618285\n","Iteration 7299, loss = 0.04618000\n","Iteration 7300, loss = 0.04617698\n","Iteration 7301, loss = 0.04617384\n","Iteration 7302, loss = 0.04617089\n","Iteration 7303, loss = 0.04616791\n","Iteration 7304, loss = 0.04616489\n","Iteration 7305, loss = 0.04616183\n","Iteration 7306, loss = 0.04615895\n","Iteration 7307, loss = 0.04615589\n","Iteration 7308, loss = 0.04615289\n","Iteration 7309, loss = 0.04614997\n","Iteration 7310, loss = 0.04614701\n","Iteration 7311, loss = 0.04614400\n","Iteration 7312, loss = 0.04614095\n","Iteration 7313, loss = 0.04613787\n","Iteration 7314, loss = 0.04613502\n","Iteration 7315, loss = 0.04613203\n","Iteration 7316, loss = 0.04612889\n","Iteration 7317, loss = 0.04612595\n","Iteration 7318, loss = 0.04612298\n","Iteration 7319, loss = 0.04611996\n","Iteration 7320, loss = 0.04611690\n","Iteration 7321, loss = 0.04611396\n","Iteration 7322, loss = 0.04611097\n","Iteration 7323, loss = 0.04610794\n","Iteration 7324, loss = 0.04610503\n","Iteration 7325, loss = 0.04610206\n","Iteration 7326, loss = 0.04609906\n","Iteration 7327, loss = 0.04609601\n","Iteration 7328, loss = 0.04609328\n","Iteration 7329, loss = 0.04609025\n","Iteration 7330, loss = 0.04608711\n","Iteration 7331, loss = 0.04608420\n","Iteration 7332, loss = 0.04608124\n","Iteration 7333, loss = 0.04607824\n","Iteration 7334, loss = 0.04607519\n","Iteration 7335, loss = 0.04607235\n","Iteration 7336, loss = 0.04606934\n","Iteration 7337, loss = 0.04606630\n","Iteration 7338, loss = 0.04606339\n","Iteration 7339, loss = 0.04606043\n","Iteration 7340, loss = 0.04605743\n","Iteration 7341, loss = 0.04605439\n","Iteration 7342, loss = 0.04605154\n","Iteration 7343, loss = 0.04604855\n","Iteration 7344, loss = 0.04604549\n","Iteration 7345, loss = 0.04604258\n","Iteration 7346, loss = 0.04603963\n","Iteration 7347, loss = 0.04603662\n","Iteration 7348, loss = 0.04603357\n","Iteration 7349, loss = 0.04603087\n","Iteration 7350, loss = 0.04602790\n","Iteration 7351, loss = 0.04602467\n","Iteration 7352, loss = 0.04602177\n","Iteration 7353, loss = 0.04601881\n","Iteration 7354, loss = 0.04601580\n","Iteration 7355, loss = 0.04601301\n","Iteration 7356, loss = 0.04600999\n","Iteration 7357, loss = 0.04600700\n","Iteration 7358, loss = 0.04600412\n","Iteration 7359, loss = 0.04600118\n","Iteration 7360, loss = 0.04599819\n","Iteration 7361, loss = 0.04599516\n","Iteration 7362, loss = 0.04599222\n","Iteration 7363, loss = 0.04598926\n","Iteration 7364, loss = 0.04598630\n","Iteration 7365, loss = 0.04598340\n","Iteration 7366, loss = 0.04598045\n","Iteration 7367, loss = 0.04597745\n","Iteration 7368, loss = 0.04597445\n","Iteration 7369, loss = 0.04597147\n","Iteration 7370, loss = 0.04596856\n","Iteration 7371, loss = 0.04596563\n","Iteration 7372, loss = 0.04596272\n","Iteration 7373, loss = 0.04595974\n","Iteration 7374, loss = 0.04595675\n","Iteration 7375, loss = 0.04595382\n","Iteration 7376, loss = 0.04595086\n","Iteration 7377, loss = 0.04594799\n","Iteration 7378, loss = 0.04594497\n","Iteration 7379, loss = 0.04594202\n","Iteration 7380, loss = 0.04593917\n","Iteration 7381, loss = 0.04593615\n","Iteration 7382, loss = 0.04593321\n","Iteration 7383, loss = 0.04593032\n","Iteration 7384, loss = 0.04592735\n","Iteration 7385, loss = 0.04592442\n","Iteration 7386, loss = 0.04592145\n","Iteration 7387, loss = 0.04591857\n","Iteration 7388, loss = 0.04591565\n","Iteration 7389, loss = 0.04591266\n","Iteration 7390, loss = 0.04590984\n","Iteration 7391, loss = 0.04590686\n","Iteration 7392, loss = 0.04590393\n","Iteration 7393, loss = 0.04590107\n","Iteration 7394, loss = 0.04589815\n","Iteration 7395, loss = 0.04589517\n","Iteration 7396, loss = 0.04589213\n","Iteration 7397, loss = 0.04588946\n","Iteration 7398, loss = 0.04588657\n","Iteration 7399, loss = 0.04588345\n","Iteration 7400, loss = 0.04588055\n","Iteration 7401, loss = 0.04587775\n","Iteration 7402, loss = 0.04587488\n","Iteration 7403, loss = 0.04587195\n","Iteration 7404, loss = 0.04586896\n","Iteration 7405, loss = 0.04586592\n","Iteration 7406, loss = 0.04586293\n","Iteration 7407, loss = 0.04586008\n","Iteration 7408, loss = 0.04585705\n","Iteration 7409, loss = 0.04585414\n","Iteration 7410, loss = 0.04585121\n","Iteration 7411, loss = 0.04584834\n","Iteration 7412, loss = 0.04584543\n","Iteration 7413, loss = 0.04584246\n","Iteration 7414, loss = 0.04583968\n","Iteration 7415, loss = 0.04583673\n","Iteration 7416, loss = 0.04583376\n","Iteration 7417, loss = 0.04583091\n","Iteration 7418, loss = 0.04582799\n","Iteration 7419, loss = 0.04582501\n","Iteration 7420, loss = 0.04582218\n","Iteration 7421, loss = 0.04581926\n","Iteration 7422, loss = 0.04581628\n","Iteration 7423, loss = 0.04581341\n","Iteration 7424, loss = 0.04581049\n","Iteration 7425, loss = 0.04580751\n","Iteration 7426, loss = 0.04580463\n","Iteration 7427, loss = 0.04580171\n","Iteration 7428, loss = 0.04579891\n","Iteration 7429, loss = 0.04579593\n","Iteration 7430, loss = 0.04579310\n","Iteration 7431, loss = 0.04579027\n","Iteration 7432, loss = 0.04578737\n","Iteration 7433, loss = 0.04578440\n","Iteration 7434, loss = 0.04578138\n","Iteration 7435, loss = 0.04577876\n","Iteration 7436, loss = 0.04577593\n","Iteration 7437, loss = 0.04577289\n","Iteration 7438, loss = 0.04576984\n","Iteration 7439, loss = 0.04576705\n","Iteration 7440, loss = 0.04576419\n","Iteration 7441, loss = 0.04576125\n","Iteration 7442, loss = 0.04575825\n","Iteration 7443, loss = 0.04575547\n","Iteration 7444, loss = 0.04575262\n","Iteration 7445, loss = 0.04574956\n","Iteration 7446, loss = 0.04574679\n","Iteration 7447, loss = 0.04574401\n","Iteration 7448, loss = 0.04574116\n","Iteration 7449, loss = 0.04573823\n","Iteration 7450, loss = 0.04573524\n","Iteration 7451, loss = 0.04573219\n","Iteration 7452, loss = 0.04572961\n","Iteration 7453, loss = 0.04572685\n","Iteration 7454, loss = 0.04572387\n","Iteration 7455, loss = 0.04572070\n","Iteration 7456, loss = 0.04571796\n","Iteration 7457, loss = 0.04571525\n","Iteration 7458, loss = 0.04571245\n","Iteration 7459, loss = 0.04570957\n","Iteration 7460, loss = 0.04570662\n","Iteration 7461, loss = 0.04570361\n","Iteration 7462, loss = 0.04570054\n","Iteration 7463, loss = 0.04569783\n","Iteration 7464, loss = 0.04569512\n","Iteration 7465, loss = 0.04569219\n","Iteration 7466, loss = 0.04568908\n","Iteration 7467, loss = 0.04568623\n","Iteration 7468, loss = 0.04568351\n","Iteration 7469, loss = 0.04568070\n","Iteration 7470, loss = 0.04567781\n","Iteration 7471, loss = 0.04567484\n","Iteration 7472, loss = 0.04567182\n","Iteration 7473, loss = 0.04566896\n","Iteration 7474, loss = 0.04566620\n","Iteration 7475, loss = 0.04566324\n","Iteration 7476, loss = 0.04566027\n","Iteration 7477, loss = 0.04565748\n","Iteration 7478, loss = 0.04565461\n","Iteration 7479, loss = 0.04565166\n","Iteration 7480, loss = 0.04564888\n","Iteration 7481, loss = 0.04564604\n","Iteration 7482, loss = 0.04564301\n","Iteration 7483, loss = 0.04564016\n","Iteration 7484, loss = 0.04563733\n","Iteration 7485, loss = 0.04563444\n","Iteration 7486, loss = 0.04563156\n","Iteration 7487, loss = 0.04562881\n","Iteration 7488, loss = 0.04562589\n","Iteration 7489, loss = 0.04562308\n","Iteration 7490, loss = 0.04562028\n","Iteration 7491, loss = 0.04561740\n","Iteration 7492, loss = 0.04561444\n","Iteration 7493, loss = 0.04561171\n","Iteration 7494, loss = 0.04560891\n","Iteration 7495, loss = 0.04560591\n","Iteration 7496, loss = 0.04560310\n","Iteration 7497, loss = 0.04560035\n","Iteration 7498, loss = 0.04559751\n","Iteration 7499, loss = 0.04559459\n","Iteration 7500, loss = 0.04559159\n","Iteration 7501, loss = 0.04558895\n","Iteration 7502, loss = 0.04558620\n","Iteration 7503, loss = 0.04558326\n","Iteration 7504, loss = 0.04558015\n","Iteration 7505, loss = 0.04557758\n","Iteration 7506, loss = 0.04557490\n","Iteration 7507, loss = 0.04557212\n","Iteration 7508, loss = 0.04556925\n","Iteration 7509, loss = 0.04556631\n","Iteration 7510, loss = 0.04556328\n","Iteration 7511, loss = 0.04556025\n","Iteration 7512, loss = 0.04555755\n","Iteration 7513, loss = 0.04555465\n","Iteration 7514, loss = 0.04555176\n","Iteration 7515, loss = 0.04554897\n","Iteration 7516, loss = 0.04554609\n","Iteration 7517, loss = 0.04554322\n","Iteration 7518, loss = 0.04554036\n","Iteration 7519, loss = 0.04553760\n","Iteration 7520, loss = 0.04553480\n","Iteration 7521, loss = 0.04553191\n","Iteration 7522, loss = 0.04552903\n","Iteration 7523, loss = 0.04552619\n","Iteration 7524, loss = 0.04552339\n","Iteration 7525, loss = 0.04552058\n","Iteration 7526, loss = 0.04551768\n","Iteration 7527, loss = 0.04551496\n","Iteration 7528, loss = 0.04551214\n","Iteration 7529, loss = 0.04550915\n","Iteration 7530, loss = 0.04550652\n","Iteration 7531, loss = 0.04550380\n","Iteration 7532, loss = 0.04550099\n","Iteration 7533, loss = 0.04549808\n","Iteration 7534, loss = 0.04549509\n","Iteration 7535, loss = 0.04549235\n","Iteration 7536, loss = 0.04548964\n","Iteration 7537, loss = 0.04548676\n","Iteration 7538, loss = 0.04548372\n","Iteration 7539, loss = 0.04548110\n","Iteration 7540, loss = 0.04547843\n","Iteration 7541, loss = 0.04547565\n","Iteration 7542, loss = 0.04547278\n","Iteration 7543, loss = 0.04546981\n","Iteration 7544, loss = 0.04546677\n","Iteration 7545, loss = 0.04546428\n","Iteration 7546, loss = 0.04546165\n","Iteration 7547, loss = 0.04545883\n","Iteration 7548, loss = 0.04545585\n","Iteration 7549, loss = 0.04545273\n","Iteration 7550, loss = 0.04545012\n","Iteration 7551, loss = 0.04544751\n","Iteration 7552, loss = 0.04544478\n","Iteration 7553, loss = 0.04544195\n","Iteration 7554, loss = 0.04543903\n","Iteration 7555, loss = 0.04543603\n","Iteration 7556, loss = 0.04543296\n","Iteration 7557, loss = 0.04543030\n","Iteration 7558, loss = 0.04542747\n","Iteration 7559, loss = 0.04542454\n","Iteration 7560, loss = 0.04542176\n","Iteration 7561, loss = 0.04541893\n","Iteration 7562, loss = 0.04541613\n","Iteration 7563, loss = 0.04541330\n","Iteration 7564, loss = 0.04541055\n","Iteration 7565, loss = 0.04540772\n","Iteration 7566, loss = 0.04540495\n","Iteration 7567, loss = 0.04540213\n","Iteration 7568, loss = 0.04539934\n","Iteration 7569, loss = 0.04539656\n","Iteration 7570, loss = 0.04539367\n","Iteration 7571, loss = 0.04539102\n","Iteration 7572, loss = 0.04538826\n","Iteration 7573, loss = 0.04538534\n","Iteration 7574, loss = 0.04538258\n","Iteration 7575, loss = 0.04537987\n","Iteration 7576, loss = 0.04537705\n","Iteration 7577, loss = 0.04537413\n","Iteration 7578, loss = 0.04537140\n","Iteration 7579, loss = 0.04536868\n","Iteration 7580, loss = 0.04536581\n","Iteration 7581, loss = 0.04536292\n","Iteration 7582, loss = 0.04536019\n","Iteration 7583, loss = 0.04535734\n","Iteration 7584, loss = 0.04535457\n","Iteration 7585, loss = 0.04535178\n","Iteration 7586, loss = 0.04534893\n","Iteration 7587, loss = 0.04534614\n","Iteration 7588, loss = 0.04534340\n","Iteration 7589, loss = 0.04534057\n","Iteration 7590, loss = 0.04533785\n","Iteration 7591, loss = 0.04533509\n","Iteration 7592, loss = 0.04533222\n","Iteration 7593, loss = 0.04532950\n","Iteration 7594, loss = 0.04532675\n","Iteration 7595, loss = 0.04532386\n","Iteration 7596, loss = 0.04532117\n","Iteration 7597, loss = 0.04531846\n","Iteration 7598, loss = 0.04531564\n","Iteration 7599, loss = 0.04531272\n","Iteration 7600, loss = 0.04531008\n","Iteration 7601, loss = 0.04530740\n","Iteration 7602, loss = 0.04530456\n","Iteration 7603, loss = 0.04530159\n","Iteration 7604, loss = 0.04529898\n","Iteration 7605, loss = 0.04529633\n","Iteration 7606, loss = 0.04529357\n","Iteration 7607, loss = 0.04529070\n","Iteration 7608, loss = 0.04528772\n","Iteration 7609, loss = 0.04528510\n","Iteration 7610, loss = 0.04528247\n","Iteration 7611, loss = 0.04527970\n","Iteration 7612, loss = 0.04527678\n","Iteration 7613, loss = 0.04527378\n","Iteration 7614, loss = 0.04527111\n","Iteration 7615, loss = 0.04526832\n","Iteration 7616, loss = 0.04526548\n","Iteration 7617, loss = 0.04526270\n","Iteration 7618, loss = 0.04526002\n","Iteration 7619, loss = 0.04525725\n","Iteration 7620, loss = 0.04525437\n","Iteration 7621, loss = 0.04525162\n","Iteration 7622, loss = 0.04524891\n","Iteration 7623, loss = 0.04524610\n","Iteration 7624, loss = 0.04524343\n","Iteration 7625, loss = 0.04524070\n","Iteration 7626, loss = 0.04523785\n","Iteration 7627, loss = 0.04523513\n","Iteration 7628, loss = 0.04523242\n","Iteration 7629, loss = 0.04522958\n","Iteration 7630, loss = 0.04522682\n","Iteration 7631, loss = 0.04522412\n","Iteration 7632, loss = 0.04522129\n","Iteration 7633, loss = 0.04521852\n","Iteration 7634, loss = 0.04521580\n","Iteration 7635, loss = 0.04521294\n","Iteration 7636, loss = 0.04521035\n","Iteration 7637, loss = 0.04520766\n","Iteration 7638, loss = 0.04520485\n","Iteration 7639, loss = 0.04520192\n","Iteration 7640, loss = 0.04519938\n","Iteration 7641, loss = 0.04519675\n","Iteration 7642, loss = 0.04519398\n","Iteration 7643, loss = 0.04519108\n","Iteration 7644, loss = 0.04518816\n","Iteration 7645, loss = 0.04518551\n","Iteration 7646, loss = 0.04518272\n","Iteration 7647, loss = 0.04517989\n","Iteration 7648, loss = 0.04517715\n","Iteration 7649, loss = 0.04517444\n","Iteration 7650, loss = 0.04517167\n","Iteration 7651, loss = 0.04516895\n","Iteration 7652, loss = 0.04516620\n","Iteration 7653, loss = 0.04516341\n","Iteration 7654, loss = 0.04516065\n","Iteration 7655, loss = 0.04515798\n","Iteration 7656, loss = 0.04515524\n","Iteration 7657, loss = 0.04515241\n","Iteration 7658, loss = 0.04514966\n","Iteration 7659, loss = 0.04514702\n","Iteration 7660, loss = 0.04514428\n","Iteration 7661, loss = 0.04514143\n","Iteration 7662, loss = 0.04513869\n","Iteration 7663, loss = 0.04513604\n","Iteration 7664, loss = 0.04513328\n","Iteration 7665, loss = 0.04513053\n","Iteration 7666, loss = 0.04512780\n","Iteration 7667, loss = 0.04512502\n","Iteration 7668, loss = 0.04512226\n","Iteration 7669, loss = 0.04511965\n","Iteration 7670, loss = 0.04511692\n","Iteration 7671, loss = 0.04511408\n","Iteration 7672, loss = 0.04511150\n","Iteration 7673, loss = 0.04510883\n","Iteration 7674, loss = 0.04510604\n","Iteration 7675, loss = 0.04510313\n","Iteration 7676, loss = 0.04510064\n","Iteration 7677, loss = 0.04509805\n","Iteration 7678, loss = 0.04509532\n","Iteration 7679, loss = 0.04509248\n","Iteration 7680, loss = 0.04508954\n","Iteration 7681, loss = 0.04508697\n","Iteration 7682, loss = 0.04508441\n","Iteration 7683, loss = 0.04508170\n","Iteration 7684, loss = 0.04507886\n","Iteration 7685, loss = 0.04507590\n","Iteration 7686, loss = 0.04507334\n","Iteration 7687, loss = 0.04507079\n","Iteration 7688, loss = 0.04506811\n","Iteration 7689, loss = 0.04506531\n","Iteration 7690, loss = 0.04506241\n","Iteration 7691, loss = 0.04505955\n","Iteration 7692, loss = 0.04505697\n","Iteration 7693, loss = 0.04505423\n","Iteration 7694, loss = 0.04505137\n","Iteration 7695, loss = 0.04504880\n","Iteration 7696, loss = 0.04504618\n","Iteration 7697, loss = 0.04504345\n","Iteration 7698, loss = 0.04504061\n","Iteration 7699, loss = 0.04503780\n","Iteration 7700, loss = 0.04503517\n","Iteration 7701, loss = 0.04503239\n","Iteration 7702, loss = 0.04502967\n","Iteration 7703, loss = 0.04502700\n","Iteration 7704, loss = 0.04502422\n","Iteration 7705, loss = 0.04502157\n","Iteration 7706, loss = 0.04501889\n","Iteration 7707, loss = 0.04501607\n","Iteration 7708, loss = 0.04501347\n","Iteration 7709, loss = 0.04501084\n","Iteration 7710, loss = 0.04500810\n","Iteration 7711, loss = 0.04500525\n","Iteration 7712, loss = 0.04500267\n","Iteration 7713, loss = 0.04500006\n","Iteration 7714, loss = 0.04499730\n","Iteration 7715, loss = 0.04499441\n","Iteration 7716, loss = 0.04499187\n","Iteration 7717, loss = 0.04498930\n","Iteration 7718, loss = 0.04498661\n","Iteration 7719, loss = 0.04498382\n","Iteration 7720, loss = 0.04498093\n","Iteration 7721, loss = 0.04497833\n","Iteration 7722, loss = 0.04497577\n","Iteration 7723, loss = 0.04497306\n","Iteration 7724, loss = 0.04497020\n","Iteration 7725, loss = 0.04496743\n","Iteration 7726, loss = 0.04496484\n","Iteration 7727, loss = 0.04496215\n","Iteration 7728, loss = 0.04495935\n","Iteration 7729, loss = 0.04495664\n","Iteration 7730, loss = 0.04495400\n","Iteration 7731, loss = 0.04495122\n","Iteration 7732, loss = 0.04494859\n","Iteration 7733, loss = 0.04494596\n","Iteration 7734, loss = 0.04494323\n","Iteration 7735, loss = 0.04494040\n","Iteration 7736, loss = 0.04493791\n","Iteration 7737, loss = 0.04493531\n","Iteration 7738, loss = 0.04493256\n","Iteration 7739, loss = 0.04492967\n","Iteration 7740, loss = 0.04492714\n","Iteration 7741, loss = 0.04492460\n","Iteration 7742, loss = 0.04492194\n","Iteration 7743, loss = 0.04491919\n","Iteration 7744, loss = 0.04491634\n","Iteration 7745, loss = 0.04491356\n","Iteration 7746, loss = 0.04491099\n","Iteration 7747, loss = 0.04490827\n","Iteration 7748, loss = 0.04490545\n","Iteration 7749, loss = 0.04490281\n","Iteration 7750, loss = 0.04490007\n","Iteration 7751, loss = 0.04489755\n","Iteration 7752, loss = 0.04489489\n","Iteration 7753, loss = 0.04489207\n","Iteration 7754, loss = 0.04488951\n","Iteration 7755, loss = 0.04488693\n","Iteration 7756, loss = 0.04488424\n","Iteration 7757, loss = 0.04488147\n","Iteration 7758, loss = 0.04487862\n","Iteration 7759, loss = 0.04487600\n","Iteration 7760, loss = 0.04487330\n","Iteration 7761, loss = 0.04487060\n","Iteration 7762, loss = 0.04486804\n","Iteration 7763, loss = 0.04486533\n","Iteration 7764, loss = 0.04486263\n","Iteration 7765, loss = 0.04485998\n","Iteration 7766, loss = 0.04485725\n","Iteration 7767, loss = 0.04485469\n","Iteration 7768, loss = 0.04485204\n","Iteration 7769, loss = 0.04484923\n","Iteration 7770, loss = 0.04484673\n","Iteration 7771, loss = 0.04484416\n","Iteration 7772, loss = 0.04484150\n","Iteration 7773, loss = 0.04483874\n","Iteration 7774, loss = 0.04483591\n","Iteration 7775, loss = 0.04483344\n","Iteration 7776, loss = 0.04483090\n","Iteration 7777, loss = 0.04482819\n","Iteration 7778, loss = 0.04482533\n","Iteration 7779, loss = 0.04482268\n","Iteration 7780, loss = 0.04482015\n","Iteration 7781, loss = 0.04481752\n","Iteration 7782, loss = 0.04481481\n","Iteration 7783, loss = 0.04481201\n","Iteration 7784, loss = 0.04480932\n","Iteration 7785, loss = 0.04480675\n","Iteration 7786, loss = 0.04480402\n","Iteration 7787, loss = 0.04480131\n","Iteration 7788, loss = 0.04479872\n","Iteration 7789, loss = 0.04479603\n","Iteration 7790, loss = 0.04479327\n","Iteration 7791, loss = 0.04479085\n","Iteration 7792, loss = 0.04478825\n","Iteration 7793, loss = 0.04478549\n","Iteration 7794, loss = 0.04478268\n","Iteration 7795, loss = 0.04478011\n","Iteration 7796, loss = 0.04477744\n","Iteration 7797, loss = 0.04477470\n","Iteration 7798, loss = 0.04477222\n","Iteration 7799, loss = 0.04476962\n","Iteration 7800, loss = 0.04476684\n","Iteration 7801, loss = 0.04476418\n","Iteration 7802, loss = 0.04476163\n","Iteration 7803, loss = 0.04475898\n","Iteration 7804, loss = 0.04475626\n","Iteration 7805, loss = 0.04475350\n","Iteration 7806, loss = 0.04475088\n","Iteration 7807, loss = 0.04474824\n","Iteration 7808, loss = 0.04474560\n","Iteration 7809, loss = 0.04474290\n","Iteration 7810, loss = 0.04474029\n","Iteration 7811, loss = 0.04473761\n","Iteration 7812, loss = 0.04473510\n","Iteration 7813, loss = 0.04473243\n","Iteration 7814, loss = 0.04472972\n","Iteration 7815, loss = 0.04472712\n","Iteration 7816, loss = 0.04472443\n","Iteration 7817, loss = 0.04472186\n","Iteration 7818, loss = 0.04471920\n","Iteration 7819, loss = 0.04471653\n","Iteration 7820, loss = 0.04471393\n","Iteration 7821, loss = 0.04471124\n","Iteration 7822, loss = 0.04470866\n","Iteration 7823, loss = 0.04470601\n","Iteration 7824, loss = 0.04470335\n","Iteration 7825, loss = 0.04470074\n","Iteration 7826, loss = 0.04469807\n","Iteration 7827, loss = 0.04469548\n","Iteration 7828, loss = 0.04469284\n","Iteration 7829, loss = 0.04469018\n","Iteration 7830, loss = 0.04468758\n","Iteration 7831, loss = 0.04468491\n","Iteration 7832, loss = 0.04468231\n","Iteration 7833, loss = 0.04467966\n","Iteration 7834, loss = 0.04467705\n","Iteration 7835, loss = 0.04467445\n","Iteration 7836, loss = 0.04467179\n","Iteration 7837, loss = 0.04466912\n","Iteration 7838, loss = 0.04466647\n","Iteration 7839, loss = 0.04466395\n","Iteration 7840, loss = 0.04466136\n","Iteration 7841, loss = 0.04465870\n","Iteration 7842, loss = 0.04465597\n","Iteration 7843, loss = 0.04465355\n","Iteration 7844, loss = 0.04465099\n","Iteration 7845, loss = 0.04464823\n","Iteration 7846, loss = 0.04464555\n","Iteration 7847, loss = 0.04464303\n","Iteration 7848, loss = 0.04464042\n","Iteration 7849, loss = 0.04463774\n","Iteration 7850, loss = 0.04463500\n","Iteration 7851, loss = 0.04463261\n","Iteration 7852, loss = 0.04463007\n","Iteration 7853, loss = 0.04462734\n","Iteration 7854, loss = 0.04462455\n","Iteration 7855, loss = 0.04462202\n","Iteration 7856, loss = 0.04461941\n","Iteration 7857, loss = 0.04461674\n","Iteration 7858, loss = 0.04461412\n","Iteration 7859, loss = 0.04461151\n","Iteration 7860, loss = 0.04460889\n","Iteration 7861, loss = 0.04460631\n","Iteration 7862, loss = 0.04460366\n","Iteration 7863, loss = 0.04460105\n","Iteration 7864, loss = 0.04459840\n","Iteration 7865, loss = 0.04459588\n","Iteration 7866, loss = 0.04459331\n","Iteration 7867, loss = 0.04459068\n","Iteration 7868, loss = 0.04458798\n","Iteration 7869, loss = 0.04458549\n","Iteration 7870, loss = 0.04458292\n","Iteration 7871, loss = 0.04458015\n","Iteration 7872, loss = 0.04457769\n","Iteration 7873, loss = 0.04457520\n","Iteration 7874, loss = 0.04457262\n","Iteration 7875, loss = 0.04456998\n","Iteration 7876, loss = 0.04456728\n","Iteration 7877, loss = 0.04456452\n","Iteration 7878, loss = 0.04456219\n","Iteration 7879, loss = 0.04455971\n","Iteration 7880, loss = 0.04455702\n","Iteration 7881, loss = 0.04455416\n","Iteration 7882, loss = 0.04455170\n","Iteration 7883, loss = 0.04454927\n","Iteration 7884, loss = 0.04454675\n","Iteration 7885, loss = 0.04454416\n","Iteration 7886, loss = 0.04454150\n","Iteration 7887, loss = 0.04453879\n","Iteration 7888, loss = 0.04453602\n","Iteration 7889, loss = 0.04453348\n","Iteration 7890, loss = 0.04453103\n","Iteration 7891, loss = 0.04452837\n","Iteration 7892, loss = 0.04452554\n","Iteration 7893, loss = 0.04452301\n","Iteration 7894, loss = 0.04452042\n","Iteration 7895, loss = 0.04451777\n","Iteration 7896, loss = 0.04451536\n","Iteration 7897, loss = 0.04451276\n","Iteration 7898, loss = 0.04451000\n","Iteration 7899, loss = 0.04450745\n","Iteration 7900, loss = 0.04450484\n","Iteration 7901, loss = 0.04450232\n","Iteration 7902, loss = 0.04449967\n","Iteration 7903, loss = 0.04449718\n","Iteration 7904, loss = 0.04449466\n","Iteration 7905, loss = 0.04449208\n","Iteration 7906, loss = 0.04448944\n","Iteration 7907, loss = 0.04448674\n","Iteration 7908, loss = 0.04448440\n","Iteration 7909, loss = 0.04448188\n","Iteration 7910, loss = 0.04447916\n","Iteration 7911, loss = 0.04447647\n","Iteration 7912, loss = 0.04447400\n","Iteration 7913, loss = 0.04447145\n","Iteration 7914, loss = 0.04446885\n","Iteration 7915, loss = 0.04446618\n","Iteration 7916, loss = 0.04446356\n","Iteration 7917, loss = 0.04446100\n","Iteration 7918, loss = 0.04445841\n","Iteration 7919, loss = 0.04445586\n","Iteration 7920, loss = 0.04445326\n","Iteration 7921, loss = 0.04445067\n","Iteration 7922, loss = 0.04444806\n","Iteration 7923, loss = 0.04444551\n","Iteration 7924, loss = 0.04444297\n","Iteration 7925, loss = 0.04444042\n","Iteration 7926, loss = 0.04443781\n","Iteration 7927, loss = 0.04443528\n","Iteration 7928, loss = 0.04443266\n","Iteration 7929, loss = 0.04443017\n","Iteration 7930, loss = 0.04442766\n","Iteration 7931, loss = 0.04442510\n","Iteration 7932, loss = 0.04442247\n","Iteration 7933, loss = 0.04441980\n","Iteration 7934, loss = 0.04441747\n","Iteration 7935, loss = 0.04441496\n","Iteration 7936, loss = 0.04441223\n","Iteration 7937, loss = 0.04440963\n","Iteration 7938, loss = 0.04440718\n","Iteration 7939, loss = 0.04440466\n","Iteration 7940, loss = 0.04440209\n","Iteration 7941, loss = 0.04439946\n","Iteration 7942, loss = 0.04439678\n","Iteration 7943, loss = 0.04439431\n","Iteration 7944, loss = 0.04439182\n","Iteration 7945, loss = 0.04438910\n","Iteration 7946, loss = 0.04438662\n","Iteration 7947, loss = 0.04438416\n","Iteration 7948, loss = 0.04438165\n","Iteration 7949, loss = 0.04437908\n","Iteration 7950, loss = 0.04437646\n","Iteration 7951, loss = 0.04437379\n","Iteration 7952, loss = 0.04437124\n","Iteration 7953, loss = 0.04436874\n","Iteration 7954, loss = 0.04436602\n","Iteration 7955, loss = 0.04436349\n","Iteration 7956, loss = 0.04436094\n","Iteration 7957, loss = 0.04435843\n","Iteration 7958, loss = 0.04435590\n","Iteration 7959, loss = 0.04435331\n","Iteration 7960, loss = 0.04435078\n","Iteration 7961, loss = 0.04434817\n","Iteration 7962, loss = 0.04434575\n","Iteration 7963, loss = 0.04434327\n","Iteration 7964, loss = 0.04434074\n","Iteration 7965, loss = 0.04433815\n","Iteration 7966, loss = 0.04433552\n","Iteration 7967, loss = 0.04433294\n","Iteration 7968, loss = 0.04433041\n","Iteration 7969, loss = 0.04432786\n","Iteration 7970, loss = 0.04432535\n","Iteration 7971, loss = 0.04432280\n","Iteration 7972, loss = 0.04432019\n","Iteration 7973, loss = 0.04431777\n","Iteration 7974, loss = 0.04431521\n","Iteration 7975, loss = 0.04431260\n","Iteration 7976, loss = 0.04431011\n","Iteration 7977, loss = 0.04430758\n","Iteration 7978, loss = 0.04430499\n","Iteration 7979, loss = 0.04430242\n","Iteration 7980, loss = 0.04429985\n","Iteration 7981, loss = 0.04429734\n","Iteration 7982, loss = 0.04429484\n","Iteration 7983, loss = 0.04429233\n","Iteration 7984, loss = 0.04428977\n","Iteration 7985, loss = 0.04428717\n","Iteration 7986, loss = 0.04428487\n","Iteration 7987, loss = 0.04428231\n","Iteration 7988, loss = 0.04427958\n","Iteration 7989, loss = 0.04427710\n","Iteration 7990, loss = 0.04427457\n","Iteration 7991, loss = 0.04427200\n","Iteration 7992, loss = 0.04426957\n","Iteration 7993, loss = 0.04426698\n","Iteration 7994, loss = 0.04426448\n","Iteration 7995, loss = 0.04426202\n","Iteration 7996, loss = 0.04425951\n","Iteration 7997, loss = 0.04425695\n","Iteration 7998, loss = 0.04425435\n","Iteration 7999, loss = 0.04425181\n","Iteration 8000, loss = 0.04424927\n","Iteration 8001, loss = 0.04424678\n","Iteration 8002, loss = 0.04424431\n","Iteration 8003, loss = 0.04424179\n","Iteration 8004, loss = 0.04423923\n","Iteration 8005, loss = 0.04423662\n","Iteration 8006, loss = 0.04423430\n","Iteration 8007, loss = 0.04423179\n","Iteration 8008, loss = 0.04422904\n","Iteration 8009, loss = 0.04422657\n","Iteration 8010, loss = 0.04422405\n","Iteration 8011, loss = 0.04422149\n","Iteration 8012, loss = 0.04421914\n","Iteration 8013, loss = 0.04421655\n","Iteration 8014, loss = 0.04421401\n","Iteration 8015, loss = 0.04421157\n","Iteration 8016, loss = 0.04420908\n","Iteration 8017, loss = 0.04420654\n","Iteration 8018, loss = 0.04420397\n","Iteration 8019, loss = 0.04420136\n","Iteration 8020, loss = 0.04419886\n","Iteration 8021, loss = 0.04419637\n","Iteration 8022, loss = 0.04419388\n","Iteration 8023, loss = 0.04419139\n","Iteration 8024, loss = 0.04418887\n","Iteration 8025, loss = 0.04418630\n","Iteration 8026, loss = 0.04418397\n","Iteration 8027, loss = 0.04418141\n","Iteration 8028, loss = 0.04417882\n","Iteration 8029, loss = 0.04417638\n","Iteration 8030, loss = 0.04417389\n","Iteration 8031, loss = 0.04417136\n","Iteration 8032, loss = 0.04416879\n","Iteration 8033, loss = 0.04416632\n","Iteration 8034, loss = 0.04416377\n","Iteration 8035, loss = 0.04416131\n","Iteration 8036, loss = 0.04415887\n","Iteration 8037, loss = 0.04415639\n","Iteration 8038, loss = 0.04415386\n","Iteration 8039, loss = 0.04415130\n","Iteration 8040, loss = 0.04414872\n","Iteration 8041, loss = 0.04414622\n","Iteration 8042, loss = 0.04414374\n","Iteration 8043, loss = 0.04414128\n","Iteration 8044, loss = 0.04413881\n","Iteration 8045, loss = 0.04413631\n","Iteration 8046, loss = 0.04413376\n","Iteration 8047, loss = 0.04413132\n","Iteration 8048, loss = 0.04412876\n","Iteration 8049, loss = 0.04412635\n","Iteration 8050, loss = 0.04412392\n","Iteration 8051, loss = 0.04412146\n","Iteration 8052, loss = 0.04411895\n","Iteration 8053, loss = 0.04411641\n","Iteration 8054, loss = 0.04411384\n","Iteration 8055, loss = 0.04411137\n","Iteration 8056, loss = 0.04410887\n","Iteration 8057, loss = 0.04410636\n","Iteration 8058, loss = 0.04410392\n","Iteration 8059, loss = 0.04410145\n","Iteration 8060, loss = 0.04409893\n","Iteration 8061, loss = 0.04409638\n","Iteration 8062, loss = 0.04409398\n","Iteration 8063, loss = 0.04409144\n","Iteration 8064, loss = 0.04408897\n","Iteration 8065, loss = 0.04408655\n","Iteration 8066, loss = 0.04408408\n","Iteration 8067, loss = 0.04408159\n","Iteration 8068, loss = 0.04407906\n","Iteration 8069, loss = 0.04407650\n","Iteration 8070, loss = 0.04407417\n","Iteration 8071, loss = 0.04407168\n","Iteration 8072, loss = 0.04406905\n","Iteration 8073, loss = 0.04406662\n","Iteration 8074, loss = 0.04406416\n","Iteration 8075, loss = 0.04406166\n","Iteration 8076, loss = 0.04405913\n","Iteration 8077, loss = 0.04405677\n","Iteration 8078, loss = 0.04405422\n","Iteration 8079, loss = 0.04405176\n","Iteration 8080, loss = 0.04404935\n","Iteration 8081, loss = 0.04404691\n","Iteration 8082, loss = 0.04404442\n","Iteration 8083, loss = 0.04404191\n","Iteration 8084, loss = 0.04403937\n","Iteration 8085, loss = 0.04403686\n","Iteration 8086, loss = 0.04403436\n","Iteration 8087, loss = 0.04403198\n","Iteration 8088, loss = 0.04402957\n","Iteration 8089, loss = 0.04402712\n","Iteration 8090, loss = 0.04402464\n","Iteration 8091, loss = 0.04402213\n","Iteration 8092, loss = 0.04401959\n","Iteration 8093, loss = 0.04401716\n","Iteration 8094, loss = 0.04401466\n","Iteration 8095, loss = 0.04401220\n","Iteration 8096, loss = 0.04400980\n","Iteration 8097, loss = 0.04400735\n","Iteration 8098, loss = 0.04400488\n","Iteration 8099, loss = 0.04400237\n","Iteration 8100, loss = 0.04399984\n","Iteration 8101, loss = 0.04399748\n","Iteration 8102, loss = 0.04399499\n","Iteration 8103, loss = 0.04399248\n","Iteration 8104, loss = 0.04399008\n","Iteration 8105, loss = 0.04398764\n","Iteration 8106, loss = 0.04398517\n","Iteration 8107, loss = 0.04398268\n","Iteration 8108, loss = 0.04398016\n","Iteration 8109, loss = 0.04397778\n","Iteration 8110, loss = 0.04397527\n","Iteration 8111, loss = 0.04397282\n","Iteration 8112, loss = 0.04397043\n","Iteration 8113, loss = 0.04396800\n","Iteration 8114, loss = 0.04396554\n","Iteration 8115, loss = 0.04396305\n","Iteration 8116, loss = 0.04396054\n","Iteration 8117, loss = 0.04395801\n","Iteration 8118, loss = 0.04395587\n","Iteration 8119, loss = 0.04395341\n","Iteration 8120, loss = 0.04395067\n","Iteration 8121, loss = 0.04394837\n","Iteration 8122, loss = 0.04394604\n","Iteration 8123, loss = 0.04394368\n","Iteration 8124, loss = 0.04394128\n","Iteration 8125, loss = 0.04393885\n","Iteration 8126, loss = 0.04393638\n","Iteration 8127, loss = 0.04393389\n","Iteration 8128, loss = 0.04393138\n","Iteration 8129, loss = 0.04392885\n","Iteration 8130, loss = 0.04392630\n","Iteration 8131, loss = 0.04392374\n","Iteration 8132, loss = 0.04392169\n","Iteration 8133, loss = 0.04391935\n","Iteration 8134, loss = 0.04391670\n","Iteration 8135, loss = 0.04391400\n","Iteration 8136, loss = 0.04391166\n","Iteration 8137, loss = 0.04390929\n","Iteration 8138, loss = 0.04390688\n","Iteration 8139, loss = 0.04390444\n","Iteration 8140, loss = 0.04390198\n","Iteration 8141, loss = 0.04389949\n","Iteration 8142, loss = 0.04389699\n","Iteration 8143, loss = 0.04389446\n","Iteration 8144, loss = 0.04389226\n","Iteration 8145, loss = 0.04388985\n","Iteration 8146, loss = 0.04388713\n","Iteration 8147, loss = 0.04388474\n","Iteration 8148, loss = 0.04388232\n","Iteration 8149, loss = 0.04387988\n","Iteration 8150, loss = 0.04387742\n","Iteration 8151, loss = 0.04387505\n","Iteration 8152, loss = 0.04387254\n","Iteration 8153, loss = 0.04387012\n","Iteration 8154, loss = 0.04386767\n","Iteration 8155, loss = 0.04386534\n","Iteration 8156, loss = 0.04386283\n","Iteration 8157, loss = 0.04386042\n","Iteration 8158, loss = 0.04385799\n","Iteration 8159, loss = 0.04385553\n","Iteration 8160, loss = 0.04385321\n","Iteration 8161, loss = 0.04385068\n","Iteration 8162, loss = 0.04384826\n","Iteration 8163, loss = 0.04384583\n","Iteration 8164, loss = 0.04384346\n","Iteration 8165, loss = 0.04384100\n","Iteration 8166, loss = 0.04383861\n","Iteration 8167, loss = 0.04383619\n","Iteration 8168, loss = 0.04383374\n","Iteration 8169, loss = 0.04383128\n","Iteration 8170, loss = 0.04382908\n","Iteration 8171, loss = 0.04382655\n","Iteration 8172, loss = 0.04382410\n","Iteration 8173, loss = 0.04382175\n","Iteration 8174, loss = 0.04381938\n","Iteration 8175, loss = 0.04381698\n","Iteration 8176, loss = 0.04381456\n","Iteration 8177, loss = 0.04381212\n","Iteration 8178, loss = 0.04380966\n","Iteration 8179, loss = 0.04380718\n","Iteration 8180, loss = 0.04380468\n","Iteration 8181, loss = 0.04380261\n","Iteration 8182, loss = 0.04380019\n","Iteration 8183, loss = 0.04379746\n","Iteration 8184, loss = 0.04379518\n","Iteration 8185, loss = 0.04379289\n","Iteration 8186, loss = 0.04379057\n","Iteration 8187, loss = 0.04378821\n","Iteration 8188, loss = 0.04378583\n","Iteration 8189, loss = 0.04378343\n","Iteration 8190, loss = 0.04378100\n","Iteration 8191, loss = 0.04377855\n","Iteration 8192, loss = 0.04377609\n","Iteration 8193, loss = 0.04377362\n","Iteration 8194, loss = 0.04377113\n","Iteration 8195, loss = 0.04376863\n","Iteration 8196, loss = 0.04376616\n","Iteration 8197, loss = 0.04376381\n","Iteration 8198, loss = 0.04376137\n","Iteration 8199, loss = 0.04375900\n","Iteration 8200, loss = 0.04375662\n","Iteration 8201, loss = 0.04375421\n","Iteration 8202, loss = 0.04375179\n","Iteration 8203, loss = 0.04374935\n","Iteration 8204, loss = 0.04374695\n","Iteration 8205, loss = 0.04374453\n","Iteration 8206, loss = 0.04374214\n","Iteration 8207, loss = 0.04373973\n","Iteration 8208, loss = 0.04373736\n","Iteration 8209, loss = 0.04373495\n","Iteration 8210, loss = 0.04373259\n","Iteration 8211, loss = 0.04373020\n","Iteration 8212, loss = 0.04372779\n","Iteration 8213, loss = 0.04372537\n","Iteration 8214, loss = 0.04372298\n","Iteration 8215, loss = 0.04372057\n","Iteration 8216, loss = 0.04371820\n","Iteration 8217, loss = 0.04371580\n","Iteration 8218, loss = 0.04371339\n","Iteration 8219, loss = 0.04371105\n","Iteration 8220, loss = 0.04370861\n","Iteration 8221, loss = 0.04370625\n","Iteration 8222, loss = 0.04370386\n","Iteration 8223, loss = 0.04370145\n","Iteration 8224, loss = 0.04369903\n","Iteration 8225, loss = 0.04369683\n","Iteration 8226, loss = 0.04369428\n","Iteration 8227, loss = 0.04369197\n","Iteration 8228, loss = 0.04368967\n","Iteration 8229, loss = 0.04368734\n","Iteration 8230, loss = 0.04368499\n","Iteration 8231, loss = 0.04368262\n","Iteration 8232, loss = 0.04368023\n","Iteration 8233, loss = 0.04367782\n","Iteration 8234, loss = 0.04367540\n","Iteration 8235, loss = 0.04367297\n","Iteration 8236, loss = 0.04367053\n","Iteration 8237, loss = 0.04366808\n","Iteration 8238, loss = 0.04366589\n","Iteration 8239, loss = 0.04366349\n","Iteration 8240, loss = 0.04366094\n","Iteration 8241, loss = 0.04365862\n","Iteration 8242, loss = 0.04365627\n","Iteration 8243, loss = 0.04365391\n","Iteration 8244, loss = 0.04365153\n","Iteration 8245, loss = 0.04364913\n","Iteration 8246, loss = 0.04364673\n","Iteration 8247, loss = 0.04364431\n","Iteration 8248, loss = 0.04364203\n","Iteration 8249, loss = 0.04363954\n","Iteration 8250, loss = 0.04363725\n","Iteration 8251, loss = 0.04363495\n","Iteration 8252, loss = 0.04363263\n","Iteration 8253, loss = 0.04363028\n","Iteration 8254, loss = 0.04362792\n","Iteration 8255, loss = 0.04362555\n","Iteration 8256, loss = 0.04362316\n","Iteration 8257, loss = 0.04362075\n","Iteration 8258, loss = 0.04361834\n","Iteration 8259, loss = 0.04361592\n","Iteration 8260, loss = 0.04361349\n","Iteration 8261, loss = 0.04361137\n","Iteration 8262, loss = 0.04360896\n","Iteration 8263, loss = 0.04360641\n","Iteration 8264, loss = 0.04360410\n","Iteration 8265, loss = 0.04360178\n","Iteration 8266, loss = 0.04359943\n","Iteration 8267, loss = 0.04359708\n","Iteration 8268, loss = 0.04359470\n","Iteration 8269, loss = 0.04359232\n","Iteration 8270, loss = 0.04358992\n","Iteration 8271, loss = 0.04358752\n","Iteration 8272, loss = 0.04358523\n","Iteration 8273, loss = 0.04358277\n","Iteration 8274, loss = 0.04358042\n","Iteration 8275, loss = 0.04357806\n","Iteration 8276, loss = 0.04357579\n","Iteration 8277, loss = 0.04357338\n","Iteration 8278, loss = 0.04357105\n","Iteration 8279, loss = 0.04356872\n","Iteration 8280, loss = 0.04356637\n","Iteration 8281, loss = 0.04356400\n","Iteration 8282, loss = 0.04356163\n","Iteration 8283, loss = 0.04355924\n","Iteration 8284, loss = 0.04355699\n","Iteration 8285, loss = 0.04355453\n","Iteration 8286, loss = 0.04355220\n","Iteration 8287, loss = 0.04354985\n","Iteration 8288, loss = 0.04354749\n","Iteration 8289, loss = 0.04354516\n","Iteration 8290, loss = 0.04354282\n","Iteration 8291, loss = 0.04354050\n","Iteration 8292, loss = 0.04353817\n","Iteration 8293, loss = 0.04353583\n","Iteration 8294, loss = 0.04353347\n","Iteration 8295, loss = 0.04353111\n","Iteration 8296, loss = 0.04352873\n","Iteration 8297, loss = 0.04352641\n","Iteration 8298, loss = 0.04352404\n","Iteration 8299, loss = 0.04352172\n","Iteration 8300, loss = 0.04351938\n","Iteration 8301, loss = 0.04351703\n","Iteration 8302, loss = 0.04351467\n","Iteration 8303, loss = 0.04351237\n","Iteration 8304, loss = 0.04351001\n","Iteration 8305, loss = 0.04350769\n","Iteration 8306, loss = 0.04350537\n","Iteration 8307, loss = 0.04350303\n","Iteration 8308, loss = 0.04350068\n","Iteration 8309, loss = 0.04349833\n","Iteration 8310, loss = 0.04349596\n","Iteration 8311, loss = 0.04349380\n","Iteration 8312, loss = 0.04349129\n","Iteration 8313, loss = 0.04348897\n","Iteration 8314, loss = 0.04348665\n","Iteration 8315, loss = 0.04348431\n","Iteration 8316, loss = 0.04348196\n","Iteration 8317, loss = 0.04347975\n","Iteration 8318, loss = 0.04347732\n","Iteration 8319, loss = 0.04347502\n","Iteration 8320, loss = 0.04347270\n","Iteration 8321, loss = 0.04347038\n","Iteration 8322, loss = 0.04346804\n","Iteration 8323, loss = 0.04346570\n","Iteration 8324, loss = 0.04346335\n","Iteration 8325, loss = 0.04346107\n","Iteration 8326, loss = 0.04345870\n","Iteration 8327, loss = 0.04345640\n","Iteration 8328, loss = 0.04345408\n","Iteration 8329, loss = 0.04345176\n","Iteration 8330, loss = 0.04344942\n","Iteration 8331, loss = 0.04344708\n","Iteration 8332, loss = 0.04344475\n","Iteration 8333, loss = 0.04344245\n","Iteration 8334, loss = 0.04344015\n","Iteration 8335, loss = 0.04343785\n","Iteration 8336, loss = 0.04343553\n","Iteration 8337, loss = 0.04343320\n","Iteration 8338, loss = 0.04343087\n","Iteration 8339, loss = 0.04342853\n","Iteration 8340, loss = 0.04342619\n","Iteration 8341, loss = 0.04342408\n","Iteration 8342, loss = 0.04342156\n","Iteration 8343, loss = 0.04341932\n","Iteration 8344, loss = 0.04341707\n","Iteration 8345, loss = 0.04341481\n","Iteration 8346, loss = 0.04341254\n","Iteration 8347, loss = 0.04341025\n","Iteration 8348, loss = 0.04340795\n","Iteration 8349, loss = 0.04340564\n","Iteration 8350, loss = 0.04340333\n","Iteration 8351, loss = 0.04340100\n","Iteration 8352, loss = 0.04339867\n","Iteration 8353, loss = 0.04339634\n","Iteration 8354, loss = 0.04339400\n","Iteration 8355, loss = 0.04339165\n","Iteration 8356, loss = 0.04338931\n","Iteration 8357, loss = 0.04338696\n","Iteration 8358, loss = 0.04338460\n","Iteration 8359, loss = 0.04338246\n","Iteration 8360, loss = 0.04338006\n","Iteration 8361, loss = 0.04337772\n","Iteration 8362, loss = 0.04337547\n","Iteration 8363, loss = 0.04337321\n","Iteration 8364, loss = 0.04337093\n","Iteration 8365, loss = 0.04336865\n","Iteration 8366, loss = 0.04336635\n","Iteration 8367, loss = 0.04336405\n","Iteration 8368, loss = 0.04336175\n","Iteration 8369, loss = 0.04335943\n","Iteration 8370, loss = 0.04335712\n","Iteration 8371, loss = 0.04335479\n","Iteration 8372, loss = 0.04335247\n","Iteration 8373, loss = 0.04335014\n","Iteration 8374, loss = 0.04334780\n","Iteration 8375, loss = 0.04334547\n","Iteration 8376, loss = 0.04334348\n","Iteration 8377, loss = 0.04334105\n","Iteration 8378, loss = 0.04333863\n","Iteration 8379, loss = 0.04333639\n","Iteration 8380, loss = 0.04333414\n","Iteration 8381, loss = 0.04333188\n","Iteration 8382, loss = 0.04332961\n","Iteration 8383, loss = 0.04332733\n","Iteration 8384, loss = 0.04332505\n","Iteration 8385, loss = 0.04332275\n","Iteration 8386, loss = 0.04332046\n","Iteration 8387, loss = 0.04331815\n","Iteration 8388, loss = 0.04331585\n","Iteration 8389, loss = 0.04331354\n","Iteration 8390, loss = 0.04331123\n","Iteration 8391, loss = 0.04330891\n","Iteration 8392, loss = 0.04330659\n","Iteration 8393, loss = 0.04330427\n","Iteration 8394, loss = 0.04330204\n","Iteration 8395, loss = 0.04329969\n","Iteration 8396, loss = 0.04329741\n","Iteration 8397, loss = 0.04329514\n","Iteration 8398, loss = 0.04329285\n","Iteration 8399, loss = 0.04329056\n","Iteration 8400, loss = 0.04328827\n","Iteration 8401, loss = 0.04328611\n","Iteration 8402, loss = 0.04328373\n","Iteration 8403, loss = 0.04328148\n","Iteration 8404, loss = 0.04327922\n","Iteration 8405, loss = 0.04327695\n","Iteration 8406, loss = 0.04327468\n","Iteration 8407, loss = 0.04327240\n","Iteration 8408, loss = 0.04327012\n","Iteration 8409, loss = 0.04326784\n","Iteration 8410, loss = 0.04326555\n","Iteration 8411, loss = 0.04326326\n","Iteration 8412, loss = 0.04326096\n","Iteration 8413, loss = 0.04325881\n","Iteration 8414, loss = 0.04325642\n","Iteration 8415, loss = 0.04325417\n","Iteration 8416, loss = 0.04325191\n","Iteration 8417, loss = 0.04324965\n","Iteration 8418, loss = 0.04324738\n","Iteration 8419, loss = 0.04324511\n","Iteration 8420, loss = 0.04324283\n","Iteration 8421, loss = 0.04324055\n","Iteration 8422, loss = 0.04323827\n","Iteration 8423, loss = 0.04323603\n","Iteration 8424, loss = 0.04323375\n","Iteration 8425, loss = 0.04323151\n","Iteration 8426, loss = 0.04322926\n","Iteration 8427, loss = 0.04322701\n","Iteration 8428, loss = 0.04322475\n","Iteration 8429, loss = 0.04322249\n","Iteration 8430, loss = 0.04322022\n","Iteration 8431, loss = 0.04321795\n","Iteration 8432, loss = 0.04321568\n","Iteration 8433, loss = 0.04321340\n","Iteration 8434, loss = 0.04321113\n","Iteration 8435, loss = 0.04320885\n","Iteration 8436, loss = 0.04320674\n","Iteration 8437, loss = 0.04320434\n","Iteration 8438, loss = 0.04320210\n","Iteration 8439, loss = 0.04319986\n","Iteration 8440, loss = 0.04319761\n","Iteration 8441, loss = 0.04319536\n","Iteration 8442, loss = 0.04319310\n","Iteration 8443, loss = 0.04319084\n","Iteration 8444, loss = 0.04318858\n","Iteration 8445, loss = 0.04318632\n","Iteration 8446, loss = 0.04318406\n","Iteration 8447, loss = 0.04318179\n","Iteration 8448, loss = 0.04317967\n","Iteration 8449, loss = 0.04317730\n","Iteration 8450, loss = 0.04317507\n","Iteration 8451, loss = 0.04317284\n","Iteration 8452, loss = 0.04317060\n","Iteration 8453, loss = 0.04316836\n","Iteration 8454, loss = 0.04316611\n","Iteration 8455, loss = 0.04316386\n","Iteration 8456, loss = 0.04316161\n","Iteration 8457, loss = 0.04315936\n","Iteration 8458, loss = 0.04315711\n","Iteration 8459, loss = 0.04315485\n","Iteration 8460, loss = 0.04315260\n","Iteration 8461, loss = 0.04315034\n","Iteration 8462, loss = 0.04314820\n","Iteration 8463, loss = 0.04314586\n","Iteration 8464, loss = 0.04314364\n","Iteration 8465, loss = 0.04314141\n","Iteration 8466, loss = 0.04313918\n","Iteration 8467, loss = 0.04313695\n","Iteration 8468, loss = 0.04313471\n","Iteration 8469, loss = 0.04313247\n","Iteration 8470, loss = 0.04313023\n","Iteration 8471, loss = 0.04312799\n","Iteration 8472, loss = 0.04312575\n","Iteration 8473, loss = 0.04312350\n","Iteration 8474, loss = 0.04312126\n","Iteration 8475, loss = 0.04311901\n","Iteration 8476, loss = 0.04311677\n","Iteration 8477, loss = 0.04311462\n","Iteration 8478, loss = 0.04311231\n","Iteration 8479, loss = 0.04311010\n","Iteration 8480, loss = 0.04310788\n","Iteration 8481, loss = 0.04310566\n","Iteration 8482, loss = 0.04310343\n","Iteration 8483, loss = 0.04310121\n","Iteration 8484, loss = 0.04309898\n","Iteration 8485, loss = 0.04309675\n","Iteration 8486, loss = 0.04309452\n","Iteration 8487, loss = 0.04309229\n","Iteration 8488, loss = 0.04309005\n","Iteration 8489, loss = 0.04308782\n","Iteration 8490, loss = 0.04308559\n","Iteration 8491, loss = 0.04308335\n","Iteration 8492, loss = 0.04308112\n","Iteration 8493, loss = 0.04307889\n","Iteration 8494, loss = 0.04307673\n","Iteration 8495, loss = 0.04307445\n","Iteration 8496, loss = 0.04307224\n","Iteration 8497, loss = 0.04307004\n","Iteration 8498, loss = 0.04306783\n","Iteration 8499, loss = 0.04306561\n","Iteration 8500, loss = 0.04306340\n","Iteration 8501, loss = 0.04306118\n","Iteration 8502, loss = 0.04305896\n","Iteration 8503, loss = 0.04305674\n","Iteration 8504, loss = 0.04305453\n","Iteration 8505, loss = 0.04305231\n","Iteration 8506, loss = 0.04305009\n","Iteration 8507, loss = 0.04304786\n","Iteration 8508, loss = 0.04304564\n","Iteration 8509, loss = 0.04304342\n","Iteration 8510, loss = 0.04304120\n","Iteration 8511, loss = 0.04303898\n","Iteration 8512, loss = 0.04303676\n","Iteration 8513, loss = 0.04303454\n","Iteration 8514, loss = 0.04303245\n","Iteration 8515, loss = 0.04303013\n","Iteration 8516, loss = 0.04302793\n","Iteration 8517, loss = 0.04302574\n","Iteration 8518, loss = 0.04302354\n","Iteration 8519, loss = 0.04302134\n","Iteration 8520, loss = 0.04301914\n","Iteration 8521, loss = 0.04301693\n","Iteration 8522, loss = 0.04301473\n","Iteration 8523, loss = 0.04301252\n","Iteration 8524, loss = 0.04301032\n","Iteration 8525, loss = 0.04300811\n","Iteration 8526, loss = 0.04300591\n","Iteration 8527, loss = 0.04300370\n","Iteration 8528, loss = 0.04300149\n","Iteration 8529, loss = 0.04299929\n","Iteration 8530, loss = 0.04299708\n","Iteration 8531, loss = 0.04299488\n","Iteration 8532, loss = 0.04299267\n","Iteration 8533, loss = 0.04299047\n","Iteration 8534, loss = 0.04298826\n","Iteration 8535, loss = 0.04298606\n","Iteration 8536, loss = 0.04298386\n","Iteration 8537, loss = 0.04298166\n","Iteration 8538, loss = 0.04297952\n","Iteration 8539, loss = 0.04297727\n","Iteration 8540, loss = 0.04297509\n","Iteration 8541, loss = 0.04297291\n","Iteration 8542, loss = 0.04297072\n","Iteration 8543, loss = 0.04296853\n","Iteration 8544, loss = 0.04296635\n","Iteration 8545, loss = 0.04296416\n","Iteration 8546, loss = 0.04296197\n","Iteration 8547, loss = 0.04295978\n","Iteration 8548, loss = 0.04295759\n","Iteration 8549, loss = 0.04295540\n","Iteration 8550, loss = 0.04295321\n","Iteration 8551, loss = 0.04295102\n","Iteration 8552, loss = 0.04294883\n","Iteration 8553, loss = 0.04294664\n","Iteration 8554, loss = 0.04294445\n","Iteration 8555, loss = 0.04294227\n","Iteration 8556, loss = 0.04294008\n","Iteration 8557, loss = 0.04293789\n","Iteration 8558, loss = 0.04293570\n","Iteration 8559, loss = 0.04293352\n","Iteration 8560, loss = 0.04293133\n","Iteration 8561, loss = 0.04292915\n","Iteration 8562, loss = 0.04292696\n","Iteration 8563, loss = 0.04292478\n","Iteration 8564, loss = 0.04292260\n","Iteration 8565, loss = 0.04292041\n","Iteration 8566, loss = 0.04291823\n","Iteration 8567, loss = 0.04291605\n","Iteration 8568, loss = 0.04291387\n","Iteration 8569, loss = 0.04291169\n","Iteration 8570, loss = 0.04290951\n","Iteration 8571, loss = 0.04290734\n","Iteration 8572, loss = 0.04290516\n","Iteration 8573, loss = 0.04290302\n","Iteration 8574, loss = 0.04290082\n","Iteration 8575, loss = 0.04289865\n","Iteration 8576, loss = 0.04289649\n","Iteration 8577, loss = 0.04289432\n","Iteration 8578, loss = 0.04289215\n","Iteration 8579, loss = 0.04288999\n","Iteration 8580, loss = 0.04288782\n","Iteration 8581, loss = 0.04288565\n","Iteration 8582, loss = 0.04288348\n","Iteration 8583, loss = 0.04288132\n","Iteration 8584, loss = 0.04287915\n","Iteration 8585, loss = 0.04287698\n","Iteration 8586, loss = 0.04287481\n","Iteration 8587, loss = 0.04287265\n","Iteration 8588, loss = 0.04287048\n","Iteration 8589, loss = 0.04286832\n","Iteration 8590, loss = 0.04286615\n","Iteration 8591, loss = 0.04286398\n","Iteration 8592, loss = 0.04286182\n","Iteration 8593, loss = 0.04285966\n","Iteration 8594, loss = 0.04285749\n","Iteration 8595, loss = 0.04285533\n","Iteration 8596, loss = 0.04285317\n","Iteration 8597, loss = 0.04285100\n","Iteration 8598, loss = 0.04284884\n","Iteration 8599, loss = 0.04284668\n","Iteration 8600, loss = 0.04284452\n","Iteration 8601, loss = 0.04284236\n","Iteration 8602, loss = 0.04284020\n","Iteration 8603, loss = 0.04283804\n","Iteration 8604, loss = 0.04283589\n","Iteration 8605, loss = 0.04283373\n","Iteration 8606, loss = 0.04283157\n","Iteration 8607, loss = 0.04282942\n","Iteration 8608, loss = 0.04282726\n","Iteration 8609, loss = 0.04282511\n","Iteration 8610, loss = 0.04282295\n","Iteration 8611, loss = 0.04282080\n","Iteration 8612, loss = 0.04281865\n","Iteration 8613, loss = 0.04281650\n","Iteration 8614, loss = 0.04281435\n","Iteration 8615, loss = 0.04281220\n","Iteration 8616, loss = 0.04281005\n","Iteration 8617, loss = 0.04280790\n","Iteration 8618, loss = 0.04280575\n","Iteration 8619, loss = 0.04280360\n","Iteration 8620, loss = 0.04280145\n","Iteration 8621, loss = 0.04279930\n","Iteration 8622, loss = 0.04279716\n","Iteration 8623, loss = 0.04279501\n","Iteration 8624, loss = 0.04279287\n","Iteration 8625, loss = 0.04279072\n","Iteration 8626, loss = 0.04278858\n","Iteration 8627, loss = 0.04278644\n","Iteration 8628, loss = 0.04278429\n","Iteration 8629, loss = 0.04278215\n","Iteration 8630, loss = 0.04278001\n","Iteration 8631, loss = 0.04277787\n","Iteration 8632, loss = 0.04277573\n","Iteration 8633, loss = 0.04277359\n","Iteration 8634, loss = 0.04277145\n","Iteration 8635, loss = 0.04276931\n","Iteration 8636, loss = 0.04276717\n","Iteration 8637, loss = 0.04276504\n","Iteration 8638, loss = 0.04276290\n","Iteration 8639, loss = 0.04276076\n","Iteration 8640, loss = 0.04275863\n","Iteration 8641, loss = 0.04275649\n","Iteration 8642, loss = 0.04275436\n","Iteration 8643, loss = 0.04275222\n","Iteration 8644, loss = 0.04275009\n","Iteration 8645, loss = 0.04274795\n","Iteration 8646, loss = 0.04274582\n","Iteration 8647, loss = 0.04274369\n","Iteration 8648, loss = 0.04274156\n","Iteration 8649, loss = 0.04273943\n","Iteration 8650, loss = 0.04273730\n","Iteration 8651, loss = 0.04273517\n","Iteration 8652, loss = 0.04273304\n","Iteration 8653, loss = 0.04273091\n","Iteration 8654, loss = 0.04272878\n","Iteration 8655, loss = 0.04272665\n","Iteration 8656, loss = 0.04272452\n","Iteration 8657, loss = 0.04272239\n","Iteration 8658, loss = 0.04272027\n","Iteration 8659, loss = 0.04271814\n","Iteration 8660, loss = 0.04271601\n","Iteration 8661, loss = 0.04271389\n","Iteration 8662, loss = 0.04271176\n","Iteration 8663, loss = 0.04270964\n","Iteration 8664, loss = 0.04270751\n","Iteration 8665, loss = 0.04270548\n","Iteration 8666, loss = 0.04270328\n","Iteration 8667, loss = 0.04270117\n","Iteration 8668, loss = 0.04269906\n","Iteration 8669, loss = 0.04269695\n","Iteration 8670, loss = 0.04269484\n","Iteration 8671, loss = 0.04269273\n","Iteration 8672, loss = 0.04269062\n","Iteration 8673, loss = 0.04268850\n","Iteration 8674, loss = 0.04268639\n","Iteration 8675, loss = 0.04268428\n","Iteration 8676, loss = 0.04268217\n","Iteration 8677, loss = 0.04268006\n","Iteration 8678, loss = 0.04267795\n","Iteration 8679, loss = 0.04267584\n","Iteration 8680, loss = 0.04267373\n","Iteration 8681, loss = 0.04267161\n","Iteration 8682, loss = 0.04266950\n","Iteration 8683, loss = 0.04266739\n","Iteration 8684, loss = 0.04266528\n","Iteration 8685, loss = 0.04266317\n","Iteration 8686, loss = 0.04266106\n","Iteration 8687, loss = 0.04265895\n","Iteration 8688, loss = 0.04265684\n","Iteration 8689, loss = 0.04265473\n","Iteration 8690, loss = 0.04265262\n","Iteration 8691, loss = 0.04265051\n","Iteration 8692, loss = 0.04264840\n","Iteration 8693, loss = 0.04264629\n","Iteration 8694, loss = 0.04264418\n","Iteration 8695, loss = 0.04264207\n","Iteration 8696, loss = 0.04263996\n","Iteration 8697, loss = 0.04263786\n","Iteration 8698, loss = 0.04263575\n","Iteration 8699, loss = 0.04263364\n","Iteration 8700, loss = 0.04263153\n","Iteration 8701, loss = 0.04262955\n","Iteration 8702, loss = 0.04262734\n","Iteration 8703, loss = 0.04262526\n","Iteration 8704, loss = 0.04262317\n","Iteration 8705, loss = 0.04262109\n","Iteration 8706, loss = 0.04261900\n","Iteration 8707, loss = 0.04261691\n","Iteration 8708, loss = 0.04261482\n","Iteration 8709, loss = 0.04261273\n","Iteration 8710, loss = 0.04261064\n","Iteration 8711, loss = 0.04260854\n","Iteration 8712, loss = 0.04260645\n","Iteration 8713, loss = 0.04260436\n","Iteration 8714, loss = 0.04260226\n","Iteration 8715, loss = 0.04260017\n","Iteration 8716, loss = 0.04259807\n","Iteration 8717, loss = 0.04259598\n","Iteration 8718, loss = 0.04259388\n","Iteration 8719, loss = 0.04259179\n","Iteration 8720, loss = 0.04258969\n","Iteration 8721, loss = 0.04258759\n","Iteration 8722, loss = 0.04258550\n","Iteration 8723, loss = 0.04258340\n","Iteration 8724, loss = 0.04258142\n","Iteration 8725, loss = 0.04257924\n","Iteration 8726, loss = 0.04257717\n","Iteration 8727, loss = 0.04257510\n","Iteration 8728, loss = 0.04257303\n","Iteration 8729, loss = 0.04257096\n","Iteration 8730, loss = 0.04256888\n","Iteration 8731, loss = 0.04256680\n","Iteration 8732, loss = 0.04256472\n","Iteration 8733, loss = 0.04256264\n","Iteration 8734, loss = 0.04256056\n","Iteration 8735, loss = 0.04255848\n","Iteration 8736, loss = 0.04255640\n","Iteration 8737, loss = 0.04255431\n","Iteration 8738, loss = 0.04255223\n","Iteration 8739, loss = 0.04255014\n","Iteration 8740, loss = 0.04254806\n","Iteration 8741, loss = 0.04254597\n","Iteration 8742, loss = 0.04254388\n","Iteration 8743, loss = 0.04254195\n","Iteration 8744, loss = 0.04253974\n","Iteration 8745, loss = 0.04253769\n","Iteration 8746, loss = 0.04253563\n","Iteration 8747, loss = 0.04253357\n","Iteration 8748, loss = 0.04253151\n","Iteration 8749, loss = 0.04252944\n","Iteration 8750, loss = 0.04252738\n","Iteration 8751, loss = 0.04252531\n","Iteration 8752, loss = 0.04252323\n","Iteration 8753, loss = 0.04252116\n","Iteration 8754, loss = 0.04251909\n","Iteration 8755, loss = 0.04251701\n","Iteration 8756, loss = 0.04251493\n","Iteration 8757, loss = 0.04251286\n","Iteration 8758, loss = 0.04251078\n","Iteration 8759, loss = 0.04250881\n","Iteration 8760, loss = 0.04250666\n","Iteration 8761, loss = 0.04250462\n","Iteration 8762, loss = 0.04250257\n","Iteration 8763, loss = 0.04250052\n","Iteration 8764, loss = 0.04249847\n","Iteration 8765, loss = 0.04249641\n","Iteration 8766, loss = 0.04249435\n","Iteration 8767, loss = 0.04249229\n","Iteration 8768, loss = 0.04249022\n","Iteration 8769, loss = 0.04248816\n","Iteration 8770, loss = 0.04248609\n","Iteration 8771, loss = 0.04248402\n","Iteration 8772, loss = 0.04248195\n","Iteration 8773, loss = 0.04247988\n","Iteration 8774, loss = 0.04247802\n","Iteration 8775, loss = 0.04247577\n","Iteration 8776, loss = 0.04247374\n","Iteration 8777, loss = 0.04247170\n","Iteration 8778, loss = 0.04246966\n","Iteration 8779, loss = 0.04246762\n","Iteration 8780, loss = 0.04246557\n","Iteration 8781, loss = 0.04246351\n","Iteration 8782, loss = 0.04246146\n","Iteration 8783, loss = 0.04245940\n","Iteration 8784, loss = 0.04245734\n","Iteration 8785, loss = 0.04245528\n","Iteration 8786, loss = 0.04245321\n","Iteration 8787, loss = 0.04245136\n","Iteration 8788, loss = 0.04244913\n","Iteration 8789, loss = 0.04244710\n","Iteration 8790, loss = 0.04244508\n","Iteration 8791, loss = 0.04244304\n","Iteration 8792, loss = 0.04244101\n","Iteration 8793, loss = 0.04243896\n","Iteration 8794, loss = 0.04243692\n","Iteration 8795, loss = 0.04243487\n","Iteration 8796, loss = 0.04243281\n","Iteration 8797, loss = 0.04243076\n","Iteration 8798, loss = 0.04242870\n","Iteration 8799, loss = 0.04242675\n","Iteration 8800, loss = 0.04242463\n","Iteration 8801, loss = 0.04242262\n","Iteration 8802, loss = 0.04242060\n","Iteration 8803, loss = 0.04241857\n","Iteration 8804, loss = 0.04241654\n","Iteration 8805, loss = 0.04241450\n","Iteration 8806, loss = 0.04241246\n","Iteration 8807, loss = 0.04241042\n","Iteration 8808, loss = 0.04240837\n","Iteration 8809, loss = 0.04240632\n","Iteration 8810, loss = 0.04240427\n","Iteration 8811, loss = 0.04240240\n","Iteration 8812, loss = 0.04240021\n","Iteration 8813, loss = 0.04239820\n","Iteration 8814, loss = 0.04239619\n","Iteration 8815, loss = 0.04239417\n","Iteration 8816, loss = 0.04239214\n","Iteration 8817, loss = 0.04239011\n","Iteration 8818, loss = 0.04238807\n","Iteration 8819, loss = 0.04238603\n","Iteration 8820, loss = 0.04238399\n","Iteration 8821, loss = 0.04238199\n","Iteration 8822, loss = 0.04237995\n","Iteration 8823, loss = 0.04237795\n","Iteration 8824, loss = 0.04237595\n","Iteration 8825, loss = 0.04237394\n","Iteration 8826, loss = 0.04237192\n","Iteration 8827, loss = 0.04236989\n","Iteration 8828, loss = 0.04236786\n","Iteration 8829, loss = 0.04236583\n","Iteration 8830, loss = 0.04236379\n","Iteration 8831, loss = 0.04236174\n","Iteration 8832, loss = 0.04235979\n","Iteration 8833, loss = 0.04235771\n","Iteration 8834, loss = 0.04235572\n","Iteration 8835, loss = 0.04235371\n","Iteration 8836, loss = 0.04235171\n","Iteration 8837, loss = 0.04234969\n","Iteration 8838, loss = 0.04234767\n","Iteration 8839, loss = 0.04234564\n","Iteration 8840, loss = 0.04234360\n","Iteration 8841, loss = 0.04234157\n","Iteration 8842, loss = 0.04233951\n","Iteration 8843, loss = 0.04233713\n","Iteration 8844, loss = 0.04233458\n","Iteration 8845, loss = 0.04233188\n","Iteration 8846, loss = 0.04232906\n","Iteration 8847, loss = 0.04232612\n","Iteration 8848, loss = 0.04232334\n","Iteration 8849, loss = 0.04232113\n","Iteration 8850, loss = 0.04231989\n","Iteration 8851, loss = 0.04231846\n","Iteration 8852, loss = 0.04231678\n","Iteration 8853, loss = 0.04231489\n","Iteration 8854, loss = 0.04231280\n","Iteration 8855, loss = 0.04231052\n","Iteration 8856, loss = 0.04230809\n","Iteration 8857, loss = 0.04230551\n","Iteration 8858, loss = 0.04230280\n","Iteration 8859, loss = 0.04230274\n","Iteration 8860, loss = 0.04229983\n","Iteration 8861, loss = 0.04229701\n","Iteration 8862, loss = 0.04229566\n","Iteration 8863, loss = 0.04229407\n","Iteration 8864, loss = 0.04229225\n","Iteration 8865, loss = 0.04229025\n","Iteration 8866, loss = 0.04228806\n","Iteration 8867, loss = 0.04228571\n","Iteration 8868, loss = 0.04228321\n","Iteration 8869, loss = 0.04228059\n","Iteration 8870, loss = 0.04227785\n","Iteration 8871, loss = 0.04227929\n","Iteration 8872, loss = 0.04227670\n","Iteration 8873, loss = 0.04227190\n","Iteration 8874, loss = 0.04227047\n","Iteration 8875, loss = 0.04226882\n","Iteration 8876, loss = 0.04226696\n","Iteration 8877, loss = 0.04226493\n","Iteration 8878, loss = 0.04226271\n","Iteration 8879, loss = 0.04226036\n","Iteration 8880, loss = 0.04225786\n","Iteration 8881, loss = 0.04225529\n","Iteration 8882, loss = 0.04225347\n","Iteration 8883, loss = 0.04225150\n","Iteration 8884, loss = 0.04224936\n","Iteration 8885, loss = 0.04224712\n","Iteration 8886, loss = 0.04224556\n","Iteration 8887, loss = 0.04224384\n","Iteration 8888, loss = 0.04224193\n","Iteration 8889, loss = 0.04223985\n","Iteration 8890, loss = 0.04223760\n","Iteration 8891, loss = 0.04223522\n","Iteration 8892, loss = 0.04223329\n","Iteration 8893, loss = 0.04223100\n","Iteration 8894, loss = 0.04222909\n","Iteration 8895, loss = 0.04222702\n","Iteration 8896, loss = 0.04222479\n","Iteration 8897, loss = 0.04222369\n","Iteration 8898, loss = 0.04222083\n","Iteration 8899, loss = 0.04221903\n","Iteration 8900, loss = 0.04221705\n","Iteration 8901, loss = 0.04221491\n","Iteration 8902, loss = 0.04221263\n","Iteration 8903, loss = 0.04221177\n","Iteration 8904, loss = 0.04220855\n","Iteration 8905, loss = 0.04220671\n","Iteration 8906, loss = 0.04220469\n","Iteration 8907, loss = 0.04220252\n","Iteration 8908, loss = 0.04220115\n","Iteration 8909, loss = 0.04219864\n","Iteration 8910, loss = 0.04219687\n","Iteration 8911, loss = 0.04219492\n","Iteration 8912, loss = 0.04219281\n","Iteration 8913, loss = 0.04219056\n","Iteration 8914, loss = 0.04218874\n","Iteration 8915, loss = 0.04218653\n","Iteration 8916, loss = 0.04218470\n","Iteration 8917, loss = 0.04218270\n","Iteration 8918, loss = 0.04218054\n","Iteration 8919, loss = 0.04217825\n","Iteration 8920, loss = 0.04217793\n","Iteration 8921, loss = 0.04217444\n","Iteration 8922, loss = 0.04217311\n","Iteration 8923, loss = 0.04217183\n","Iteration 8924, loss = 0.04217033\n","Iteration 8925, loss = 0.04216863\n","Iteration 8926, loss = 0.04216675\n","Iteration 8927, loss = 0.04216470\n","Iteration 8928, loss = 0.04216250\n","Iteration 8929, loss = 0.04216017\n","Iteration 8930, loss = 0.04215772\n","Iteration 8931, loss = 0.04215517\n","Iteration 8932, loss = 0.04215252\n","Iteration 8933, loss = 0.04215203\n","Iteration 8934, loss = 0.04214996\n","Iteration 8935, loss = 0.04214649\n","Iteration 8936, loss = 0.04214496\n","Iteration 8937, loss = 0.04214324\n","Iteration 8938, loss = 0.04214134\n","Iteration 8939, loss = 0.04213929\n","Iteration 8940, loss = 0.04213709\n","Iteration 8941, loss = 0.04213476\n","Iteration 8942, loss = 0.04213232\n","Iteration 8943, loss = 0.04213254\n","Iteration 8944, loss = 0.04212983\n","Iteration 8945, loss = 0.04212676\n","Iteration 8946, loss = 0.04212535\n","Iteration 8947, loss = 0.04212373\n","Iteration 8948, loss = 0.04212193\n","Iteration 8949, loss = 0.04211997\n","Iteration 8950, loss = 0.04211786\n","Iteration 8951, loss = 0.04211561\n","Iteration 8952, loss = 0.04211324\n","Iteration 8953, loss = 0.04211076\n","Iteration 8954, loss = 0.04210979\n","Iteration 8955, loss = 0.04210731\n","Iteration 8956, loss = 0.04210509\n","Iteration 8957, loss = 0.04210364\n","Iteration 8958, loss = 0.04210199\n","Iteration 8959, loss = 0.04210016\n","Iteration 8960, loss = 0.04209818\n","Iteration 8961, loss = 0.04209605\n","Iteration 8962, loss = 0.04209379\n","Iteration 8963, loss = 0.04209141\n","Iteration 8964, loss = 0.04208892\n","Iteration 8965, loss = 0.04208874\n","Iteration 8966, loss = 0.04208637\n","Iteration 8967, loss = 0.04208321\n","Iteration 8968, loss = 0.04208174\n","Iteration 8969, loss = 0.04208008\n","Iteration 8970, loss = 0.04207824\n","Iteration 8971, loss = 0.04207625\n","Iteration 8972, loss = 0.04207412\n","Iteration 8973, loss = 0.04207185\n","Iteration 8974, loss = 0.04206948\n","Iteration 8975, loss = 0.04206786\n","Iteration 8976, loss = 0.04206521\n","Iteration 8977, loss = 0.04206400\n","Iteration 8978, loss = 0.04206259\n","Iteration 8979, loss = 0.04206098\n","Iteration 8980, loss = 0.04205919\n","Iteration 8981, loss = 0.04205725\n","Iteration 8982, loss = 0.04205515\n","Iteration 8983, loss = 0.04205293\n","Iteration 8984, loss = 0.04205059\n","Iteration 8985, loss = 0.04204814\n","Iteration 8986, loss = 0.04204592\n","Iteration 8987, loss = 0.04204375\n","Iteration 8988, loss = 0.04204190\n","Iteration 8989, loss = 0.04204034\n","Iteration 8990, loss = 0.04203875\n","Iteration 8991, loss = 0.04203698\n","Iteration 8992, loss = 0.04203506\n","Iteration 8993, loss = 0.04203298\n","Iteration 8994, loss = 0.04203078\n","Iteration 8995, loss = 0.04202846\n","Iteration 8996, loss = 0.04202693\n","Iteration 8997, loss = 0.04202428\n","Iteration 8998, loss = 0.04202235\n","Iteration 8999, loss = 0.04202083\n","Iteration 9000, loss = 0.04201883\n","Iteration 9001, loss = 0.04201719\n","Iteration 9002, loss = 0.04201538\n","Iteration 9003, loss = 0.04201342\n","Iteration 9004, loss = 0.04201132\n","Iteration 9005, loss = 0.04200909\n","Iteration 9006, loss = 0.04200721\n","Iteration 9007, loss = 0.04200505\n","Iteration 9008, loss = 0.04200318\n","Iteration 9009, loss = 0.04200117\n","Iteration 9010, loss = 0.04199943\n","Iteration 9011, loss = 0.04199751\n","Iteration 9012, loss = 0.04199580\n","Iteration 9013, loss = 0.04199393\n","Iteration 9014, loss = 0.04199191\n","Iteration 9015, loss = 0.04198977\n","Iteration 9016, loss = 0.04198771\n","Iteration 9017, loss = 0.04198586\n","Iteration 9018, loss = 0.04198405\n","Iteration 9019, loss = 0.04198209\n","Iteration 9020, loss = 0.04197999\n","Iteration 9021, loss = 0.04197853\n","Iteration 9022, loss = 0.04197617\n","Iteration 9023, loss = 0.04197440\n","Iteration 9024, loss = 0.04197248\n","Iteration 9025, loss = 0.04197041\n","Iteration 9026, loss = 0.04196876\n","Iteration 9027, loss = 0.04196664\n","Iteration 9028, loss = 0.04196489\n","Iteration 9029, loss = 0.04196298\n","Iteration 9030, loss = 0.04196093\n","Iteration 9031, loss = 0.04195876\n","Iteration 9032, loss = 0.04195834\n","Iteration 9033, loss = 0.04195541\n","Iteration 9034, loss = 0.04195369\n","Iteration 9035, loss = 0.04195276\n","Iteration 9036, loss = 0.04195128\n","Iteration 9037, loss = 0.04194881\n","Iteration 9038, loss = 0.04194601\n","Iteration 9039, loss = 0.04194362\n","Iteration 9040, loss = 0.04194177\n","Iteration 9041, loss = 0.04194020\n","Iteration 9042, loss = 0.04193867\n","Iteration 9043, loss = 0.04193722\n","Iteration 9044, loss = 0.04193487\n","Iteration 9045, loss = 0.04193267\n","Iteration 9046, loss = 0.04193036\n","Iteration 9047, loss = 0.04192980\n","Iteration 9048, loss = 0.04192748\n","Iteration 9049, loss = 0.04192492\n","Iteration 9050, loss = 0.04192354\n","Iteration 9051, loss = 0.04192180\n","Iteration 9052, loss = 0.04191944\n","Iteration 9053, loss = 0.04191713\n","Iteration 9054, loss = 0.04191649\n","Iteration 9055, loss = 0.04191420\n","Iteration 9056, loss = 0.04191169\n","Iteration 9057, loss = 0.04191043\n","Iteration 9058, loss = 0.04190868\n","Iteration 9059, loss = 0.04190621\n","Iteration 9060, loss = 0.04190392\n","Iteration 9061, loss = 0.04190338\n","Iteration 9062, loss = 0.04190114\n","Iteration 9063, loss = 0.04189848\n","Iteration 9064, loss = 0.04189727\n","Iteration 9065, loss = 0.04189551\n","Iteration 9066, loss = 0.04189300\n","Iteration 9067, loss = 0.04189072\n","Iteration 9068, loss = 0.04189047\n","Iteration 9069, loss = 0.04188826\n","Iteration 9070, loss = 0.04188527\n","Iteration 9071, loss = 0.04188406\n","Iteration 9072, loss = 0.04188229\n","Iteration 9073, loss = 0.04187980\n","Iteration 9074, loss = 0.04187759\n","Iteration 9075, loss = 0.04187581\n","Iteration 9076, loss = 0.04187395\n","Iteration 9077, loss = 0.04187196\n","Iteration 9078, loss = 0.04187090\n","Iteration 9079, loss = 0.04186829\n","Iteration 9080, loss = 0.04186657\n","Iteration 9081, loss = 0.04186470\n","Iteration 9082, loss = 0.04186271\n","Iteration 9083, loss = 0.04186126\n","Iteration 9084, loss = 0.04185902\n","Iteration 9085, loss = 0.04185729\n","Iteration 9086, loss = 0.04185542\n","Iteration 9087, loss = 0.04185341\n","Iteration 9088, loss = 0.04185178\n","Iteration 9089, loss = 0.04184971\n","Iteration 9090, loss = 0.04184806\n","Iteration 9091, loss = 0.04184589\n","Iteration 9092, loss = 0.04184478\n","Iteration 9093, loss = 0.04184204\n","Iteration 9094, loss = 0.04184023\n","Iteration 9095, loss = 0.04183828\n","Iteration 9096, loss = 0.04183709\n","Iteration 9097, loss = 0.04183465\n","Iteration 9098, loss = 0.04183322\n","Iteration 9099, loss = 0.04183089\n","Iteration 9100, loss = 0.04183000\n","Iteration 9101, loss = 0.04182778\n","Iteration 9102, loss = 0.04182562\n","Iteration 9103, loss = 0.04182419\n","Iteration 9104, loss = 0.04182185\n","Iteration 9105, loss = 0.04181944\n","Iteration 9106, loss = 0.04181714\n","Iteration 9107, loss = 0.04181685\n","Iteration 9108, loss = 0.04181512\n","Iteration 9109, loss = 0.04181290\n","Iteration 9110, loss = 0.04180989\n","Iteration 9111, loss = 0.04180998\n","Iteration 9112, loss = 0.04180875\n","Iteration 9113, loss = 0.04180550\n","Iteration 9114, loss = 0.04180309\n","Iteration 9115, loss = 0.04180223\n","Iteration 9116, loss = 0.04180045\n","Iteration 9117, loss = 0.04179783\n","Iteration 9118, loss = 0.04179488\n","Iteration 9119, loss = 0.04179579\n","Iteration 9120, loss = 0.04179497\n","Iteration 9121, loss = 0.04179214\n","Iteration 9122, loss = 0.04178752\n","Iteration 9123, loss = 0.04178790\n","Iteration 9124, loss = 0.04178780\n","Iteration 9125, loss = 0.04178673\n","Iteration 9126, loss = 0.04178477\n","Iteration 9127, loss = 0.04178201\n","Iteration 9128, loss = 0.04177855\n","Iteration 9129, loss = 0.04177457\n","Iteration 9130, loss = 0.04177579\n","Iteration 9131, loss = 0.04177595\n","Iteration 9132, loss = 0.04177405\n","Iteration 9133, loss = 0.04177033\n","Iteration 9134, loss = 0.04176523\n","Iteration 9135, loss = 0.04176592\n","Iteration 9136, loss = 0.04176580\n","Iteration 9137, loss = 0.04176472\n","Iteration 9138, loss = 0.04176278\n","Iteration 9139, loss = 0.04176007\n","Iteration 9140, loss = 0.04175666\n","Iteration 9141, loss = 0.04175300\n","Iteration 9142, loss = 0.04175308\n","Iteration 9143, loss = 0.04175319\n","Iteration 9144, loss = 0.04175132\n","Iteration 9145, loss = 0.04174767\n","Iteration 9146, loss = 0.04174323\n","Iteration 9147, loss = 0.04174265\n","Iteration 9148, loss = 0.04174118\n","Iteration 9149, loss = 0.04173891\n","Iteration 9150, loss = 0.04173592\n","Iteration 9151, loss = 0.04173574\n","Iteration 9152, loss = 0.04173479\n","Iteration 9153, loss = 0.04173166\n","Iteration 9154, loss = 0.04172898\n","Iteration 9155, loss = 0.04172808\n","Iteration 9156, loss = 0.04172633\n","Iteration 9157, loss = 0.04172382\n","Iteration 9158, loss = 0.04172196\n","Iteration 9159, loss = 0.04172076\n","Iteration 9160, loss = 0.04171825\n","Iteration 9161, loss = 0.04171642\n","Iteration 9162, loss = 0.04171494\n","Iteration 9163, loss = 0.04171268\n","Iteration 9164, loss = 0.04171114\n","Iteration 9165, loss = 0.04170926\n","Iteration 9166, loss = 0.04170715\n","Iteration 9167, loss = 0.04170560\n","Iteration 9168, loss = 0.04170402\n","Iteration 9169, loss = 0.04170167\n","Iteration 9170, loss = 0.04170054\n","Iteration 9171, loss = 0.04169922\n","Iteration 9172, loss = 0.04169665\n","Iteration 9173, loss = 0.04169474\n","Iteration 9174, loss = 0.04169334\n","Iteration 9175, loss = 0.04169137\n","Iteration 9176, loss = 0.04168903\n","Iteration 9177, loss = 0.04168753\n","Iteration 9178, loss = 0.04168539\n","Iteration 9179, loss = 0.04168443\n","Iteration 9180, loss = 0.04168288\n","Iteration 9181, loss = 0.04168057\n","Iteration 9182, loss = 0.04167866\n","Iteration 9183, loss = 0.04167722\n","Iteration 9184, loss = 0.04167513\n","Iteration 9185, loss = 0.04167290\n","Iteration 9186, loss = 0.04167117\n","Iteration 9187, loss = 0.04166952\n","Iteration 9188, loss = 0.04166746\n","Iteration 9189, loss = 0.04166610\n","Iteration 9190, loss = 0.04166431\n","Iteration 9191, loss = 0.04166232\n","Iteration 9192, loss = 0.04166058\n","Iteration 9193, loss = 0.04165883\n","Iteration 9194, loss = 0.04165688\n","Iteration 9195, loss = 0.04165556\n","Iteration 9196, loss = 0.04165386\n","Iteration 9197, loss = 0.04165154\n","Iteration 9198, loss = 0.04165030\n","Iteration 9199, loss = 0.04164958\n","Iteration 9200, loss = 0.04164663\n","Iteration 9201, loss = 0.04164453\n","Iteration 9202, loss = 0.04164311\n","Iteration 9203, loss = 0.04164105\n","Iteration 9204, loss = 0.04163947\n","Iteration 9205, loss = 0.04163783\n","Iteration 9206, loss = 0.04163545\n","Iteration 9207, loss = 0.04163458\n","Iteration 9208, loss = 0.04163334\n","Iteration 9209, loss = 0.04163133\n","Iteration 9210, loss = 0.04162887\n","Iteration 9211, loss = 0.04162754\n","Iteration 9212, loss = 0.04162636\n","Iteration 9213, loss = 0.04162441\n","Iteration 9214, loss = 0.04162174\n","Iteration 9215, loss = 0.04162080\n","Iteration 9216, loss = 0.04161973\n","Iteration 9217, loss = 0.04161753\n","Iteration 9218, loss = 0.04161482\n","Iteration 9219, loss = 0.04161349\n","Iteration 9220, loss = 0.04161236\n","Iteration 9221, loss = 0.04161046\n","Iteration 9222, loss = 0.04160796\n","Iteration 9223, loss = 0.04160608\n","Iteration 9224, loss = 0.04160495\n","Iteration 9225, loss = 0.04160317\n","Iteration 9226, loss = 0.04160081\n","Iteration 9227, loss = 0.04159927\n","Iteration 9228, loss = 0.04159793\n","Iteration 9229, loss = 0.04159582\n","Iteration 9230, loss = 0.04159339\n","Iteration 9231, loss = 0.04159184\n","Iteration 9232, loss = 0.04158967\n","Iteration 9233, loss = 0.04158942\n","Iteration 9234, loss = 0.04158727\n","Iteration 9235, loss = 0.04158505\n","Iteration 9236, loss = 0.04158331\n","Iteration 9237, loss = 0.04158198\n","Iteration 9238, loss = 0.04158004\n","Iteration 9239, loss = 0.04157761\n","Iteration 9240, loss = 0.04157591\n","Iteration 9241, loss = 0.04157454\n","Iteration 9242, loss = 0.04157272\n","Iteration 9243, loss = 0.04157064\n","Iteration 9244, loss = 0.04156917\n","Iteration 9245, loss = 0.04156769\n","Iteration 9246, loss = 0.04156610\n","Iteration 9247, loss = 0.04156392\n","Iteration 9248, loss = 0.04156284\n","Iteration 9249, loss = 0.04156144\n","Iteration 9250, loss = 0.04155928\n","Iteration 9251, loss = 0.04155708\n","Iteration 9252, loss = 0.04155564\n","Iteration 9253, loss = 0.04155359\n","Iteration 9254, loss = 0.04155203\n","Iteration 9255, loss = 0.04155036\n","Iteration 9256, loss = 0.04154831\n","Iteration 9257, loss = 0.04154732\n","Iteration 9258, loss = 0.04154610\n","Iteration 9259, loss = 0.04154425\n","Iteration 9260, loss = 0.04154185\n","Iteration 9261, loss = 0.04154016\n","Iteration 9262, loss = 0.04153894\n","Iteration 9263, loss = 0.04153695\n","Iteration 9264, loss = 0.04153433\n","Iteration 9265, loss = 0.04153276\n","Iteration 9266, loss = 0.04153097\n","Iteration 9267, loss = 0.04152911\n","Iteration 9268, loss = 0.04152807\n","Iteration 9269, loss = 0.04152573\n","Iteration 9270, loss = 0.04152403\n","Iteration 9271, loss = 0.04152257\n","Iteration 9272, loss = 0.04152070\n","Iteration 9273, loss = 0.04151953\n","Iteration 9274, loss = 0.04151785\n","Iteration 9275, loss = 0.04151544\n","Iteration 9276, loss = 0.04151482\n","Iteration 9277, loss = 0.04151356\n","Iteration 9278, loss = 0.04151170\n","Iteration 9279, loss = 0.04150951\n","Iteration 9280, loss = 0.04150706\n","Iteration 9281, loss = 0.04150587\n","Iteration 9282, loss = 0.04150392\n","Iteration 9283, loss = 0.04150229\n","Iteration 9284, loss = 0.04150082\n","Iteration 9285, loss = 0.04149877\n","Iteration 9286, loss = 0.04149728\n","Iteration 9287, loss = 0.04149572\n","Iteration 9288, loss = 0.04149344\n","Iteration 9289, loss = 0.04149235\n","Iteration 9290, loss = 0.04149099\n","Iteration 9291, loss = 0.04148906\n","Iteration 9292, loss = 0.04148673\n","Iteration 9293, loss = 0.04148565\n","Iteration 9294, loss = 0.04148451\n","Iteration 9295, loss = 0.04148261\n","Iteration 9296, loss = 0.04148001\n","Iteration 9297, loss = 0.04147915\n","Iteration 9298, loss = 0.04147810\n","Iteration 9299, loss = 0.04147644\n","Iteration 9300, loss = 0.04147422\n","Iteration 9301, loss = 0.04147151\n","Iteration 9302, loss = 0.04147062\n","Iteration 9303, loss = 0.04146962\n","Iteration 9304, loss = 0.04146832\n","Iteration 9305, loss = 0.04146552\n","Iteration 9306, loss = 0.04146274\n","Iteration 9307, loss = 0.04146162\n","Iteration 9308, loss = 0.04145989\n","Iteration 9309, loss = 0.04145773\n","Iteration 9310, loss = 0.04145600\n","Iteration 9311, loss = 0.04145479\n","Iteration 9312, loss = 0.04145285\n","Iteration 9313, loss = 0.04145135\n","Iteration 9314, loss = 0.04144979\n","Iteration 9315, loss = 0.04144802\n","Iteration 9316, loss = 0.04144642\n","Iteration 9317, loss = 0.04144501\n","Iteration 9318, loss = 0.04144287\n","Iteration 9319, loss = 0.04144158\n","Iteration 9320, loss = 0.04144029\n","Iteration 9321, loss = 0.04143843\n","Iteration 9322, loss = 0.04143603\n","Iteration 9323, loss = 0.04143526\n","Iteration 9324, loss = 0.04143405\n","Iteration 9325, loss = 0.04143209\n","Iteration 9326, loss = 0.04142945\n","Iteration 9327, loss = 0.04142835\n","Iteration 9328, loss = 0.04142724\n","Iteration 9329, loss = 0.04142571\n","Iteration 9330, loss = 0.04142363\n","Iteration 9331, loss = 0.04142105\n","Iteration 9332, loss = 0.04142047\n","Iteration 9333, loss = 0.04141954\n","Iteration 9334, loss = 0.04141782\n","Iteration 9335, loss = 0.04141540\n","Iteration 9336, loss = 0.04141248\n","Iteration 9337, loss = 0.04141130\n","Iteration 9338, loss = 0.04140954\n","Iteration 9339, loss = 0.04140728\n","Iteration 9340, loss = 0.04140620\n","Iteration 9341, loss = 0.04140436\n","Iteration 9342, loss = 0.04140252\n","Iteration 9343, loss = 0.04140137\n","Iteration 9344, loss = 0.04139992\n","Iteration 9345, loss = 0.04139792\n","Iteration 9346, loss = 0.04139620\n","Iteration 9347, loss = 0.04139470\n","Iteration 9348, loss = 0.04139248\n","Iteration 9349, loss = 0.04139168\n","Iteration 9350, loss = 0.04139036\n","Iteration 9351, loss = 0.04138889\n","Iteration 9352, loss = 0.04138626\n","Iteration 9353, loss = 0.04138484\n","Iteration 9354, loss = 0.04138371\n","Iteration 9355, loss = 0.04138182\n","Iteration 9356, loss = 0.04137934\n","Iteration 9357, loss = 0.04137790\n","Iteration 9358, loss = 0.04137607\n","Iteration 9359, loss = 0.04137453\n","Iteration 9360, loss = 0.04137264\n","Iteration 9361, loss = 0.04137129\n","Iteration 9362, loss = 0.04136941\n","Iteration 9363, loss = 0.04136823\n","Iteration 9364, loss = 0.04136653\n","Iteration 9365, loss = 0.04136449\n","Iteration 9366, loss = 0.04136292\n","Iteration 9367, loss = 0.04136163\n","Iteration 9368, loss = 0.04135984\n","Iteration 9369, loss = 0.04135843\n","Iteration 9370, loss = 0.04135692\n","Iteration 9371, loss = 0.04135487\n","Iteration 9372, loss = 0.04135363\n","Iteration 9373, loss = 0.04135215\n","Iteration 9374, loss = 0.04134995\n","Iteration 9375, loss = 0.04134851\n","Iteration 9376, loss = 0.04134766\n","Iteration 9377, loss = 0.04134546\n","Iteration 9378, loss = 0.04134322\n","Iteration 9379, loss = 0.04134250\n","Iteration 9380, loss = 0.04134135\n","Iteration 9381, loss = 0.04133946\n","Iteration 9382, loss = 0.04133689\n","Iteration 9383, loss = 0.04133595\n","Iteration 9384, loss = 0.04133497\n","Iteration 9385, loss = 0.04133339\n","Iteration 9386, loss = 0.04133130\n","Iteration 9387, loss = 0.04132894\n","Iteration 9388, loss = 0.04132762\n","Iteration 9389, loss = 0.04132674\n","Iteration 9390, loss = 0.04132509\n","Iteration 9391, loss = 0.04132274\n","Iteration 9392, loss = 0.04132092\n","Iteration 9393, loss = 0.04131986\n","Iteration 9394, loss = 0.04131822\n","Iteration 9395, loss = 0.04131607\n","Iteration 9396, loss = 0.04131427\n","Iteration 9397, loss = 0.04131293\n","Iteration 9398, loss = 0.04131085\n","Iteration 9399, loss = 0.04130941\n","Iteration 9400, loss = 0.04130811\n","Iteration 9401, loss = 0.04130627\n","Iteration 9402, loss = 0.04130410\n","Iteration 9403, loss = 0.04130258\n","Iteration 9404, loss = 0.04130137\n","Iteration 9405, loss = 0.04129976\n","Iteration 9406, loss = 0.04129775\n","Iteration 9407, loss = 0.04129615\n","Iteration 9408, loss = 0.04129478\n","Iteration 9409, loss = 0.04129285\n","Iteration 9410, loss = 0.04129186\n","Iteration 9411, loss = 0.04129042\n","Iteration 9412, loss = 0.04128845\n","Iteration 9413, loss = 0.04128693\n","Iteration 9414, loss = 0.04128479\n","Iteration 9415, loss = 0.04128333\n","Iteration 9416, loss = 0.04128172\n","Iteration 9417, loss = 0.04128022\n","Iteration 9418, loss = 0.04127851\n","Iteration 9419, loss = 0.04127716\n","Iteration 9420, loss = 0.04127565\n","Iteration 9421, loss = 0.04127362\n","Iteration 9422, loss = 0.04127254\n","Iteration 9423, loss = 0.04127110\n","Iteration 9424, loss = 0.04126945\n","Iteration 9425, loss = 0.04126751\n","Iteration 9426, loss = 0.04126636\n","Iteration 9427, loss = 0.04126466\n","Iteration 9428, loss = 0.04126246\n","Iteration 9429, loss = 0.04126187\n","Iteration 9430, loss = 0.04126084\n","Iteration 9431, loss = 0.04125842\n","Iteration 9432, loss = 0.04125634\n","Iteration 9433, loss = 0.04125523\n","Iteration 9434, loss = 0.04125356\n","Iteration 9435, loss = 0.04125140\n","Iteration 9436, loss = 0.04125011\n","Iteration 9437, loss = 0.04124908\n","Iteration 9438, loss = 0.04124689\n","Iteration 9439, loss = 0.04124504\n","Iteration 9440, loss = 0.04124380\n","Iteration 9441, loss = 0.04124203\n","Iteration 9442, loss = 0.04124038\n","Iteration 9443, loss = 0.04123883\n","Iteration 9444, loss = 0.04123710\n","Iteration 9445, loss = 0.04123550\n","Iteration 9446, loss = 0.04123392\n","Iteration 9447, loss = 0.04123211\n","Iteration 9448, loss = 0.04123098\n","Iteration 9449, loss = 0.04122948\n","Iteration 9450, loss = 0.04122835\n","Iteration 9451, loss = 0.04122602\n","Iteration 9452, loss = 0.04122467\n","Iteration 9453, loss = 0.04122259\n","Iteration 9454, loss = 0.04122187\n","Iteration 9455, loss = 0.04122070\n","Iteration 9456, loss = 0.04121899\n","Iteration 9457, loss = 0.04121681\n","Iteration 9458, loss = 0.04121511\n","Iteration 9459, loss = 0.04121390\n","Iteration 9460, loss = 0.04121195\n","Iteration 9461, loss = 0.04121061\n","Iteration 9462, loss = 0.04120884\n","Iteration 9463, loss = 0.04120710\n","Iteration 9464, loss = 0.04120570\n","Iteration 9465, loss = 0.04120424\n","Iteration 9466, loss = 0.04120226\n","Iteration 9467, loss = 0.04120069\n","Iteration 9468, loss = 0.04119953\n","Iteration 9469, loss = 0.04119778\n","Iteration 9470, loss = 0.04119626\n","Iteration 9471, loss = 0.04119479\n","Iteration 9472, loss = 0.04119283\n","Iteration 9473, loss = 0.04119168\n","Iteration 9474, loss = 0.04119057\n","Iteration 9475, loss = 0.04118795\n","Iteration 9476, loss = 0.04118669\n","Iteration 9477, loss = 0.04118492\n","Iteration 9478, loss = 0.04118430\n","Iteration 9479, loss = 0.04118233\n","Iteration 9480, loss = 0.04118064\n","Iteration 9481, loss = 0.04117932\n","Iteration 9482, loss = 0.04117749\n","Iteration 9483, loss = 0.04117589\n","Iteration 9484, loss = 0.04117435\n","Iteration 9485, loss = 0.04117244\n","Iteration 9486, loss = 0.04117082\n","Iteration 9487, loss = 0.04117019\n","Iteration 9488, loss = 0.04116783\n","Iteration 9489, loss = 0.04116660\n","Iteration 9490, loss = 0.04116525\n","Iteration 9491, loss = 0.04116340\n","Iteration 9492, loss = 0.04116218\n","Iteration 9493, loss = 0.04116031\n","Iteration 9494, loss = 0.04115894\n","Iteration 9495, loss = 0.04115757\n","Iteration 9496, loss = 0.04115570\n","Iteration 9497, loss = 0.04115405\n","Iteration 9498, loss = 0.04115261\n","Iteration 9499, loss = 0.04115137\n","Iteration 9500, loss = 0.04114974\n","Iteration 9501, loss = 0.04114805\n","Iteration 9502, loss = 0.04114629\n","Iteration 9503, loss = 0.04114483\n","Iteration 9504, loss = 0.04114336\n","Iteration 9505, loss = 0.04114184\n","Iteration 9506, loss = 0.04114011\n","Iteration 9507, loss = 0.04113843\n","Iteration 9508, loss = 0.04113726\n","Iteration 9509, loss = 0.04113554\n","Iteration 9510, loss = 0.04113403\n","Iteration 9511, loss = 0.04113207\n","Iteration 9512, loss = 0.04113113\n","Iteration 9513, loss = 0.04112910\n","Iteration 9514, loss = 0.04112777\n","Iteration 9515, loss = 0.04112610\n","Iteration 9516, loss = 0.04112560\n","Iteration 9517, loss = 0.04112346\n","Iteration 9518, loss = 0.04112244\n","Iteration 9519, loss = 0.04112150\n","Iteration 9520, loss = 0.04112002\n","Iteration 9521, loss = 0.04111807\n","Iteration 9522, loss = 0.04111569\n","Iteration 9523, loss = 0.04111516\n","Iteration 9524, loss = 0.04111400\n","Iteration 9525, loss = 0.04111113\n","Iteration 9526, loss = 0.04111052\n","Iteration 9527, loss = 0.04110997\n","Iteration 9528, loss = 0.04110885\n","Iteration 9529, loss = 0.04110722\n","Iteration 9530, loss = 0.04110513\n","Iteration 9531, loss = 0.04110263\n","Iteration 9532, loss = 0.04110103\n","Iteration 9533, loss = 0.04110009\n","Iteration 9534, loss = 0.04109739\n","Iteration 9535, loss = 0.04109676\n","Iteration 9536, loss = 0.04109600\n","Iteration 9537, loss = 0.04109470\n","Iteration 9538, loss = 0.04109307\n","Iteration 9539, loss = 0.04109100\n","Iteration 9540, loss = 0.04108852\n","Iteration 9541, loss = 0.04108829\n","Iteration 9542, loss = 0.04108749\n","Iteration 9543, loss = 0.04108492\n","Iteration 9544, loss = 0.04108269\n","Iteration 9545, loss = 0.04108193\n","Iteration 9546, loss = 0.04108063\n","Iteration 9547, loss = 0.04107886\n","Iteration 9548, loss = 0.04107664\n","Iteration 9549, loss = 0.04107473\n","Iteration 9550, loss = 0.04107369\n","Iteration 9551, loss = 0.04107180\n","Iteration 9552, loss = 0.04107065\n","Iteration 9553, loss = 0.04106901\n","Iteration 9554, loss = 0.04106705\n","Iteration 9555, loss = 0.04106682\n","Iteration 9556, loss = 0.04106484\n","Iteration 9557, loss = 0.04106307\n","Iteration 9558, loss = 0.04106208\n","Iteration 9559, loss = 0.04106058\n","Iteration 9560, loss = 0.04105863\n","Iteration 9561, loss = 0.04105642\n","Iteration 9562, loss = 0.04105647\n","Iteration 9563, loss = 0.04105564\n","Iteration 9564, loss = 0.04105194\n","Iteration 9565, loss = 0.04105119\n","Iteration 9566, loss = 0.04104995\n","Iteration 9567, loss = 0.04104824\n","Iteration 9568, loss = 0.04104616\n","Iteration 9569, loss = 0.04104568\n","Iteration 9570, loss = 0.04104380\n","Iteration 9571, loss = 0.04104208\n","Iteration 9572, loss = 0.04104105\n","Iteration 9573, loss = 0.04103951\n","Iteration 9574, loss = 0.04103753\n","Iteration 9575, loss = 0.04103611\n","Iteration 9576, loss = 0.04103409\n","Iteration 9577, loss = 0.04103269\n","Iteration 9578, loss = 0.04103184\n","Iteration 9579, loss = 0.04103070\n","Iteration 9580, loss = 0.04102907\n","Iteration 9581, loss = 0.04102701\n","Iteration 9582, loss = 0.04102651\n","Iteration 9583, loss = 0.04102504\n","Iteration 9584, loss = 0.04102245\n","Iteration 9585, loss = 0.04102148\n","Iteration 9586, loss = 0.04102008\n","Iteration 9587, loss = 0.04101822\n","Iteration 9588, loss = 0.04101660\n","Iteration 9589, loss = 0.04101492\n","Iteration 9590, loss = 0.04101354\n","Iteration 9591, loss = 0.04101210\n","Iteration 9592, loss = 0.04101065\n","Iteration 9593, loss = 0.04100954\n","Iteration 9594, loss = 0.04100825\n","Iteration 9595, loss = 0.04100649\n","Iteration 9596, loss = 0.04100494\n","Iteration 9597, loss = 0.04100325\n","Iteration 9598, loss = 0.04100176\n","Iteration 9599, loss = 0.04100023\n","Iteration 9600, loss = 0.04099865\n","Iteration 9601, loss = 0.04099820\n","Iteration 9602, loss = 0.04099584\n","Iteration 9603, loss = 0.04099482\n","Iteration 9604, loss = 0.04099335\n","Iteration 9605, loss = 0.04099158\n","Iteration 9606, loss = 0.04099069\n","Iteration 9607, loss = 0.04098861\n","Iteration 9608, loss = 0.04098720\n","Iteration 9609, loss = 0.04098572\n","Iteration 9610, loss = 0.04098421\n","Iteration 9611, loss = 0.04098266\n","Iteration 9612, loss = 0.04098149\n","Iteration 9613, loss = 0.04098016\n","Iteration 9614, loss = 0.04097852\n","Iteration 9615, loss = 0.04097709\n","Iteration 9616, loss = 0.04097552\n","Iteration 9617, loss = 0.04097413\n","Iteration 9618, loss = 0.04097269\n","Iteration 9619, loss = 0.04097120\n","Iteration 9620, loss = 0.04097021\n","Iteration 9621, loss = 0.04096836\n","Iteration 9622, loss = 0.04096725\n","Iteration 9623, loss = 0.04096571\n","Iteration 9624, loss = 0.04096385\n","Iteration 9625, loss = 0.04096281\n","Iteration 9626, loss = 0.04096077\n","Iteration 9627, loss = 0.04096000\n","Iteration 9628, loss = 0.04095796\n","Iteration 9629, loss = 0.04095656\n","Iteration 9630, loss = 0.04095511\n","Iteration 9631, loss = 0.04095411\n","Iteration 9632, loss = 0.04095236\n","Iteration 9633, loss = 0.04095127\n","Iteration 9634, loss = 0.04094975\n","Iteration 9635, loss = 0.04094794\n","Iteration 9636, loss = 0.04094706\n","Iteration 9637, loss = 0.04094491\n","Iteration 9638, loss = 0.04094347\n","Iteration 9639, loss = 0.04094249\n","Iteration 9640, loss = 0.04094062\n","Iteration 9641, loss = 0.04093926\n","Iteration 9642, loss = 0.04093818\n","Iteration 9643, loss = 0.04093696\n","Iteration 9644, loss = 0.04093528\n","Iteration 9645, loss = 0.04093380\n","Iteration 9646, loss = 0.04093219\n","Iteration 9647, loss = 0.04093076\n","Iteration 9648, loss = 0.04092929\n","Iteration 9649, loss = 0.04092777\n","Iteration 9650, loss = 0.04092665\n","Iteration 9651, loss = 0.04092489\n","Iteration 9652, loss = 0.04092409\n","Iteration 9653, loss = 0.04092246\n","Iteration 9654, loss = 0.04092070\n","Iteration 9655, loss = 0.04091955\n","Iteration 9656, loss = 0.04091788\n","Iteration 9657, loss = 0.04091654\n","Iteration 9658, loss = 0.04091516\n","Iteration 9659, loss = 0.04091359\n","Iteration 9660, loss = 0.04091278\n","Iteration 9661, loss = 0.04091068\n","Iteration 9662, loss = 0.04090929\n","Iteration 9663, loss = 0.04090791\n","Iteration 9664, loss = 0.04090628\n","Iteration 9665, loss = 0.04090548\n","Iteration 9666, loss = 0.04090349\n","Iteration 9667, loss = 0.04090236\n","Iteration 9668, loss = 0.04090086\n","Iteration 9669, loss = 0.04089946\n","Iteration 9670, loss = 0.04089800\n","Iteration 9671, loss = 0.04089667\n","Iteration 9672, loss = 0.04089514\n","Iteration 9673, loss = 0.04089387\n","Iteration 9674, loss = 0.04089231\n","Iteration 9675, loss = 0.04089120\n","Iteration 9676, loss = 0.04088963\n","Iteration 9677, loss = 0.04088784\n","Iteration 9678, loss = 0.04088763\n","Iteration 9679, loss = 0.04088514\n","Iteration 9680, loss = 0.04088438\n","Iteration 9681, loss = 0.04088363\n","Iteration 9682, loss = 0.04088236\n","Iteration 9683, loss = 0.04088065\n","Iteration 9684, loss = 0.04087854\n","Iteration 9685, loss = 0.04087736\n","Iteration 9686, loss = 0.04087616\n","Iteration 9687, loss = 0.04087393\n","Iteration 9688, loss = 0.04087290\n","Iteration 9689, loss = 0.04087151\n","Iteration 9690, loss = 0.04086968\n","Iteration 9691, loss = 0.04086903\n","Iteration 9692, loss = 0.04086670\n","Iteration 9693, loss = 0.04086539\n","Iteration 9694, loss = 0.04086412\n","Iteration 9695, loss = 0.04086302\n","Iteration 9696, loss = 0.04086190\n","Iteration 9697, loss = 0.04086033\n","Iteration 9698, loss = 0.04085855\n","Iteration 9699, loss = 0.04085787\n","Iteration 9700, loss = 0.04085591\n","Iteration 9701, loss = 0.04085474\n","Iteration 9702, loss = 0.04085383\n","Iteration 9703, loss = 0.04085245\n","Iteration 9704, loss = 0.04085143\n","Iteration 9705, loss = 0.04084866\n","Iteration 9706, loss = 0.04084781\n","Iteration 9707, loss = 0.04084619\n","Iteration 9708, loss = 0.04084492\n","Iteration 9709, loss = 0.04084399\n","Iteration 9710, loss = 0.04084259\n","Iteration 9711, loss = 0.04084076\n","Iteration 9712, loss = 0.04083896\n","Iteration 9713, loss = 0.04083920\n","Iteration 9714, loss = 0.04083760\n","Iteration 9715, loss = 0.04083471\n","Iteration 9716, loss = 0.04083364\n","Iteration 9717, loss = 0.04083327\n","Iteration 9718, loss = 0.04083089\n","Iteration 9719, loss = 0.04082924\n","Iteration 9720, loss = 0.04082870\n","Iteration 9721, loss = 0.04082689\n","Iteration 9722, loss = 0.04082554\n","Iteration 9723, loss = 0.04082468\n","Iteration 9724, loss = 0.04082334\n","Iteration 9725, loss = 0.04082158\n","Iteration 9726, loss = 0.04081965\n","Iteration 9727, loss = 0.04081905\n","Iteration 9728, loss = 0.04081736\n","Iteration 9729, loss = 0.04081544\n","Iteration 9730, loss = 0.04081561\n","Iteration 9731, loss = 0.04081368\n","Iteration 9732, loss = 0.04081220\n","Iteration 9733, loss = 0.04081030\n","Iteration 9734, loss = 0.04080877\n","Iteration 9735, loss = 0.04080744\n","Iteration 9736, loss = 0.04080612\n","Iteration 9737, loss = 0.04080506\n","Iteration 9738, loss = 0.04080355\n","Iteration 9739, loss = 0.04080183\n","Iteration 9740, loss = 0.04080060\n","Iteration 9741, loss = 0.04079892\n","Iteration 9742, loss = 0.04079753\n","Iteration 9743, loss = 0.04079701\n","Iteration 9744, loss = 0.04079482\n","Iteration 9745, loss = 0.04079348\n","Iteration 9746, loss = 0.04079254\n","Iteration 9747, loss = 0.04079093\n","Iteration 9748, loss = 0.04078974\n","Iteration 9749, loss = 0.04078834\n","Iteration 9750, loss = 0.04078683\n","Iteration 9751, loss = 0.04078583\n","Iteration 9752, loss = 0.04078401\n","Iteration 9753, loss = 0.04078266\n","Iteration 9754, loss = 0.04078127\n","Iteration 9755, loss = 0.04077984\n","Iteration 9756, loss = 0.04077922\n","Iteration 9757, loss = 0.04077709\n","Iteration 9758, loss = 0.04077593\n","Iteration 9759, loss = 0.04077496\n","Iteration 9760, loss = 0.04077363\n","Iteration 9761, loss = 0.04077198\n","Iteration 9762, loss = 0.04077049\n","Iteration 9763, loss = 0.04077010\n","Iteration 9764, loss = 0.04076807\n","Iteration 9765, loss = 0.04076678\n","Iteration 9766, loss = 0.04076598\n","Iteration 9767, loss = 0.04076470\n","Iteration 9768, loss = 0.04076300\n","Iteration 9769, loss = 0.04076168\n","Iteration 9770, loss = 0.04075948\n","Iteration 9771, loss = 0.04075970\n","Iteration 9772, loss = 0.04075811\n","Iteration 9773, loss = 0.04075571\n","Iteration 9774, loss = 0.04075487\n","Iteration 9775, loss = 0.04075380\n","Iteration 9776, loss = 0.04075228\n","Iteration 9777, loss = 0.04075041\n","Iteration 9778, loss = 0.04074887\n","Iteration 9779, loss = 0.04074866\n","Iteration 9780, loss = 0.04074679\n","Iteration 9781, loss = 0.04074485\n","Iteration 9782, loss = 0.04074482\n","Iteration 9783, loss = 0.04074329\n","Iteration 9784, loss = 0.04074193\n","Iteration 9785, loss = 0.04074015\n","Iteration 9786, loss = 0.04073828\n","Iteration 9787, loss = 0.04073792\n","Iteration 9788, loss = 0.04073652\n","Iteration 9789, loss = 0.04073430\n","Iteration 9790, loss = 0.04073330\n","Iteration 9791, loss = 0.04073212\n","Iteration 9792, loss = 0.04073050\n","Iteration 9793, loss = 0.04072881\n","Iteration 9794, loss = 0.04072793\n","Iteration 9795, loss = 0.04072650\n","Iteration 9796, loss = 0.04072506\n","Iteration 9797, loss = 0.04072433\n","Iteration 9798, loss = 0.04072312\n","Iteration 9799, loss = 0.04072149\n","Iteration 9800, loss = 0.04071971\n","Iteration 9801, loss = 0.04071880\n","Iteration 9802, loss = 0.04071716\n","Iteration 9803, loss = 0.04071581\n","Iteration 9804, loss = 0.04071490\n","Iteration 9805, loss = 0.04071354\n","Iteration 9806, loss = 0.04071177\n","Iteration 9807, loss = 0.04071013\n","Iteration 9808, loss = 0.04071020\n","Iteration 9809, loss = 0.04070855\n","Iteration 9810, loss = 0.04070635\n","Iteration 9811, loss = 0.04070547\n","Iteration 9812, loss = 0.04070443\n","Iteration 9813, loss = 0.04070295\n","Iteration 9814, loss = 0.04070126\n","Iteration 9815, loss = 0.04069977\n","Iteration 9816, loss = 0.04069975\n","Iteration 9817, loss = 0.04069794\n","Iteration 9818, loss = 0.04069588\n","Iteration 9819, loss = 0.04069511\n","Iteration 9820, loss = 0.04069406\n","Iteration 9821, loss = 0.04069258\n","Iteration 9822, loss = 0.04069164\n","Iteration 9823, loss = 0.04068908\n","Iteration 9824, loss = 0.04068890\n","Iteration 9825, loss = 0.04068756\n","Iteration 9826, loss = 0.04068532\n","Iteration 9827, loss = 0.04068427\n","Iteration 9828, loss = 0.04068316\n","Iteration 9829, loss = 0.04068162\n","Iteration 9830, loss = 0.04068009\n","Iteration 9831, loss = 0.04067918\n","Iteration 9832, loss = 0.04067734\n","Iteration 9833, loss = 0.04067626\n","Iteration 9834, loss = 0.04067570\n","Iteration 9835, loss = 0.04067430\n","Iteration 9836, loss = 0.04067276\n","Iteration 9837, loss = 0.04067108\n","Iteration 9838, loss = 0.04066991\n","Iteration 9839, loss = 0.04066839\n","Iteration 9840, loss = 0.04066711\n","Iteration 9841, loss = 0.04066579\n","Iteration 9842, loss = 0.04066480\n","Iteration 9843, loss = 0.04066328\n","Iteration 9844, loss = 0.04066209\n","Iteration 9845, loss = 0.04066078\n","Iteration 9846, loss = 0.04065928\n","Iteration 9847, loss = 0.04065780\n","Iteration 9848, loss = 0.04065728\n","Iteration 9849, loss = 0.04065521\n","Iteration 9850, loss = 0.04065405\n","Iteration 9851, loss = 0.04065284\n","Iteration 9852, loss = 0.04065158\n","Iteration 9853, loss = 0.04065028\n","Iteration 9854, loss = 0.04064893\n","Iteration 9855, loss = 0.04064802\n","Iteration 9856, loss = 0.04064638\n","Iteration 9857, loss = 0.04064516\n","Iteration 9858, loss = 0.04064390\n","Iteration 9859, loss = 0.04064250\n","Iteration 9860, loss = 0.04064108\n","Iteration 9861, loss = 0.04064012\n","Iteration 9862, loss = 0.04063892\n","Iteration 9863, loss = 0.04063725\n","Iteration 9864, loss = 0.04063610\n","Iteration 9865, loss = 0.04063490\n","Iteration 9866, loss = 0.04063365\n","Iteration 9867, loss = 0.04063235\n","Iteration 9868, loss = 0.04063101\n","Iteration 9869, loss = 0.04062964\n","Iteration 9870, loss = 0.04062871\n","Iteration 9871, loss = 0.04062704\n","Iteration 9872, loss = 0.04062580\n","Iteration 9873, loss = 0.04062452\n","Iteration 9874, loss = 0.04062337\n","Iteration 9875, loss = 0.04062194\n","Iteration 9876, loss = 0.04062064\n","Iteration 9877, loss = 0.04061984\n","Iteration 9878, loss = 0.04061817\n","Iteration 9879, loss = 0.04061699\n","Iteration 9880, loss = 0.04061576\n","Iteration 9881, loss = 0.04061448\n","Iteration 9882, loss = 0.04061316\n","Iteration 9883, loss = 0.04061180\n","Iteration 9884, loss = 0.04061044\n","Iteration 9885, loss = 0.04060924\n","Iteration 9886, loss = 0.04060806\n","Iteration 9887, loss = 0.04060670\n","Iteration 9888, loss = 0.04060590\n","Iteration 9889, loss = 0.04060392\n","Iteration 9890, loss = 0.04060382\n","Iteration 9891, loss = 0.04060191\n","Iteration 9892, loss = 0.04060056\n","Iteration 9893, loss = 0.04059993\n","Iteration 9894, loss = 0.04059883\n","Iteration 9895, loss = 0.04059730\n","Iteration 9896, loss = 0.04059544\n","Iteration 9897, loss = 0.04059397\n","Iteration 9898, loss = 0.04059374\n","Iteration 9899, loss = 0.04059203\n","Iteration 9900, loss = 0.04059015\n","Iteration 9901, loss = 0.04059017\n","Iteration 9902, loss = 0.04058857\n","Iteration 9903, loss = 0.04058729\n","Iteration 9904, loss = 0.04058560\n","Iteration 9905, loss = 0.04058399\n","Iteration 9906, loss = 0.04058384\n","Iteration 9907, loss = 0.04058249\n","Iteration 9908, loss = 0.04058026\n","Iteration 9909, loss = 0.04057924\n","Iteration 9910, loss = 0.04057817\n","Iteration 9911, loss = 0.04057667\n","Iteration 9912, loss = 0.04057513\n","Iteration 9913, loss = 0.04057401\n","Iteration 9914, loss = 0.04057271\n","Iteration 9915, loss = 0.04057130\n","Iteration 9916, loss = 0.04057013\n","Iteration 9917, loss = 0.04056892\n","Iteration 9918, loss = 0.04056773\n","Iteration 9919, loss = 0.04056662\n","Iteration 9920, loss = 0.04056563\n","Iteration 9921, loss = 0.04056442\n","Iteration 9922, loss = 0.04056291\n","Iteration 9923, loss = 0.04056152\n","Iteration 9924, loss = 0.04056036\n","Iteration 9925, loss = 0.04055891\n","Iteration 9926, loss = 0.04055767\n","Iteration 9927, loss = 0.04055639\n","Iteration 9928, loss = 0.04055578\n","Iteration 9929, loss = 0.04055391\n","Iteration 9930, loss = 0.04055269\n","Iteration 9931, loss = 0.04055143\n","Iteration 9932, loss = 0.04055089\n","Iteration 9933, loss = 0.04054905\n","Iteration 9934, loss = 0.04054791\n","Iteration 9935, loss = 0.04054672\n","Iteration 9936, loss = 0.04054548\n","Iteration 9937, loss = 0.04054420\n","Iteration 9938, loss = 0.04054289\n","Iteration 9939, loss = 0.04054154\n","Iteration 9940, loss = 0.04054016\n","Iteration 9941, loss = 0.04054000\n","Iteration 9942, loss = 0.04053776\n","Iteration 9943, loss = 0.04053670\n","Iteration 9944, loss = 0.04053558\n","Iteration 9945, loss = 0.04053441\n","Iteration 9946, loss = 0.04053320\n","Iteration 9947, loss = 0.04053194\n","Iteration 9948, loss = 0.04053064\n","Iteration 9949, loss = 0.04052931\n","Iteration 9950, loss = 0.04052862\n","Iteration 9951, loss = 0.04052681\n","Iteration 9952, loss = 0.04052562\n","Iteration 9953, loss = 0.04052438\n","Iteration 9954, loss = 0.04052313\n","Iteration 9955, loss = 0.04052198\n","Iteration 9956, loss = 0.04052080\n","Iteration 9957, loss = 0.04051958\n","Iteration 9958, loss = 0.04051832\n","Iteration 9959, loss = 0.04051779\n","Iteration 9960, loss = 0.04051594\n","Iteration 9961, loss = 0.04051480\n","Iteration 9962, loss = 0.04051361\n","Iteration 9963, loss = 0.04051238\n","Iteration 9964, loss = 0.04051111\n","Iteration 9965, loss = 0.04050980\n","Iteration 9966, loss = 0.04050846\n","Iteration 9967, loss = 0.04050710\n","Iteration 9968, loss = 0.04050682\n","Iteration 9969, loss = 0.04050472\n","Iteration 9970, loss = 0.04050368\n","Iteration 9971, loss = 0.04050257\n","Iteration 9972, loss = 0.04050142\n","Iteration 9973, loss = 0.04050022\n","Iteration 9974, loss = 0.04049898\n","Iteration 9975, loss = 0.04049769\n","Iteration 9976, loss = 0.04049638\n","Iteration 9977, loss = 0.04049590\n","Iteration 9978, loss = 0.04049391\n","Iteration 9979, loss = 0.04049274\n","Iteration 9980, loss = 0.04049152\n","Iteration 9981, loss = 0.04049032\n","Iteration 9982, loss = 0.04048916\n","Iteration 9983, loss = 0.04048800\n","Iteration 9984, loss = 0.04048680\n","Iteration 9985, loss = 0.04048556\n","Iteration 9986, loss = 0.04048509\n","Iteration 9987, loss = 0.04048321\n","Iteration 9988, loss = 0.04048210\n","Iteration 9989, loss = 0.04048093\n","Iteration 9990, loss = 0.04047976\n","Iteration 9991, loss = 0.04047839\n","Iteration 9992, loss = 0.04047703\n","Iteration 9993, loss = 0.04047660\n","Iteration 9994, loss = 0.04047450\n","Iteration 9995, loss = 0.04047362\n","Iteration 9996, loss = 0.04047225\n","Iteration 9997, loss = 0.04047114\n","Iteration 9998, loss = 0.04046998\n","Iteration 9999, loss = 0.04046878\n","Iteration 10000, loss = 0.04046757\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10000) reached and the optimization hasn't converged yet.\n","  ConvergenceWarning,\n"]},{"output_type":"execute_result","data":{"text/plain":["MLPClassifier(learning_rate_init=0.0001, max_iter=10000, tol=1e-06,\n","              verbose=True)"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["redeneural.predict([[6.7,3.0,5.2,2.3]])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ROiI9uhZ9P_g","executionInfo":{"status":"ok","timestamp":1651533836899,"user_tz":180,"elapsed":437,"user":{"displayName":"luis henrique caldas altero","userId":"05313197258994103975"}},"outputId":"71006a4f-0498-4785-bddd-c29e9e33790b"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([2])"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["from sklearn.neural_network import MLPClassifier"],"metadata":{"id":"8DJb1aFjDy6q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"iGrFnWDQDy_A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"nD4Q0jGr9QC4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"JpjLjN8Hnvr7","executionInfo":{"status":"ok","timestamp":1651531279896,"user_tz":180,"elapsed":7,"user":{"displayName":"luis henrique caldas altero","userId":"05313197258994103975"}}},"execution_count":23,"outputs":[]}]}